{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f89d4322",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.font_manager as fm\n",
    "import seaborn as sns\n",
    "\n",
    "plt.rcParams['font.family'] = 'Malgun Gothic'  # Windowsì˜ ê¸°ë³¸ í•œê¸€ í°íŠ¸\n",
    "plt.rcParams['axes.unicode_minus'] = False     # ìŒìˆ˜ ê¸°í˜¸ ê¹¨ì§ ë°©ì§€\n",
    "\n",
    "df = pd.read_csv(\"ê°ì/ê°ì(EDAìš©)_ìŠ¤ì¼€ì¼ë§ë§Œ.csv\", encoding='cp949', parse_dates=[\"week_start\"])\n",
    "df['year'] = df['week_start'].dt.year\n",
    "df['month'] = df['week_start'].dt.month\n",
    "df['week'] = df['week_start'].dt.isocalendar().week\n",
    "\n",
    "def get_season(month):\n",
    "    if month in [3, 4, 5]:\n",
    "        return 'ë´„'\n",
    "    elif month in [6, 7, 8]:\n",
    "        return 'ì—¬ë¦„'\n",
    "    elif month in [9, 10, 11]:\n",
    "        return 'ê°€ì„'\n",
    "    else:\n",
    "        return 'ê²¨ìš¸'\n",
    "\n",
    "df['season'] = df['month'].apply(get_season)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54432727",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered = df[df['year'].between(2020, 2024)]\n",
    "\n",
    "weekly_avg = df_filtered.groupby(['week', 'year'])['í‰ê· ë‹¨ê°€(ì›)'].mean().unstack()\n",
    "\n",
    "weekly_avg.plot(figsize=(12, 5), title = \"ì—°ë„ë³„ ì£¼ì°¨ í‰ê· ë‹¨ê°€ (2020~2024ë…„)\")\n",
    "plt.xlabel(\"ì£¼ì°¨ (1~52)\")\n",
    "plt.ylabel(\"í‰ê· ë‹¨ê°€\")\n",
    "plt.legend(title='ì—°ë„', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2f09a3a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.font_manager as fm\n",
    "from matplotlib.patches import Patch\n",
    "import seaborn as sns\n",
    "import re\n",
    "\n",
    "plt.rcParams['font.family'] = 'Malgun Gothic'  # Windowsì˜ ê¸°ë³¸ í•œê¸€ í°íŠ¸\n",
    "plt.rcParams['axes.unicode_minus'] = False     # ìŒìˆ˜ ê¸°í˜¸ ê¹¨ì§ ë°©ì§€\n",
    "\n",
    "file_list = glob.glob('EDA/*.csv')\n",
    "\n",
    "def get_season(month):\n",
    "    if month in [3, 4, 5]:\n",
    "        return 'ë´„'\n",
    "    elif month in [6, 7, 8]:\n",
    "        return 'ì—¬ë¦„'\n",
    "    elif month in [9, 10, 11]:\n",
    "        return 'ê°€ì„'\n",
    "    else:\n",
    "        return 'ê²¨ìš¸'\n",
    "    \n",
    "season_legend = {\n",
    "    'ë´„': '3,4,5ì›”',\n",
    "    'ì—¬ë¦„': '6,7,8ì›”',\n",
    "    'ê°€ì„': '9,10,11ì›”',\n",
    "    'ê²¨ìš¸': '12,1,2ì›”'\n",
    "}\n",
    "\n",
    "season_colors = {\n",
    "    'ë´„': 'salmon',\n",
    "    'ì—¬ë¦„': 'skyblue',\n",
    "    'ê°€ì„': 'gold',\n",
    "    'ê²¨ìš¸': 'lightgray'\n",
    "}\n",
    "\n",
    "for file_path in file_list:\n",
    "    try:\n",
    "        df = pd.read_csv(file_path, encoding = 'cp949', parse_dates=['week_start'])\n",
    "\n",
    "        df['year'] = df['week_start'].dt.year\n",
    "        df['month'] = df['week_start'].dt.month\n",
    "        df['season'] = df['month'].apply(get_season)\n",
    "\n",
    "        df_2024 = df[df['year'] == 2024]\n",
    "\n",
    "        seasonal_avg = df_2024.groupby('season')['í‰ê· ë‹¨ê°€(ì›)'].mean().reindex(['ë´„', 'ì—¬ë¦„', 'ê°€ì„', 'ê²¨ìš¸'])\n",
    "\n",
    "        filename = os.path.basename(file_path)\n",
    "        item_name = re.split(r'\\(', filename)[0]\n",
    "\n",
    "        plt.figure(figsize=(6, 4))\n",
    "\n",
    "        seasons = seasonal_avg.index.tolist()\n",
    "        values = seasonal_avg.values.tolist()\n",
    "        colors = [season_colors[s] for s in seasons]\n",
    "\n",
    "        plt.bar(range(len(seasons)), values, color=colors)\n",
    "\n",
    "        xtick_labels = [f\"{s}({season_legend[s]})\" for s in seasons]\n",
    "        plt.xticks(ticks=range(len(seasons)), labels=xtick_labels, rotation=0)\n",
    "\n",
    "        plt.title(f\"{item_name.strip()} - 2024ë…„ ê³„ì ˆë³„ í‰ê· ë‹¨ê°€\")\n",
    "        plt.xlabel(\"ê³„ì ˆ(ì›” ë²”ìœ„)\")\n",
    "        plt.ylabel(\"í‰ê· ë‹¨ê°€(ì›)\")\n",
    "        plt.grid(axis='y')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"âš ï¸ íŒŒì¼ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {file_path}\")\n",
    "        print(f\"ì—ëŸ¬ ë‚´ìš©: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e35bb80",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(11, 3.5))\n",
    "sns.boxplot(x='season', y='í‰ê· ë‹¨ê°€(ì›)', data=df, order=['ë´„', 'ì—¬ë¦„', 'ê°€ì„', 'ê²¨ìš¸'])\n",
    "plt.title(\"ê³„ì ˆë³„ í‰ê· ë‹¨ê°€ ë¶„í¬\")\n",
    "plt.xlabel(\"ê³„ì ˆ\")\n",
    "plt.ylabel(\"í‰ê· ë‹¨ê°€\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f032fc4a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "file_list = glob.glob('EDA/*.csv')\n",
    "\n",
    "for file_path in file_list:\n",
    "    try:\n",
    "        df = pd.read_csv(file_path, encoding='cp949', parse_dates=['week_start'])\n",
    "\n",
    "        df['week'] = df['week_start'].dt.isocalendar().week\n",
    "\n",
    "        weekly_avg = df.groupby('week')[['í‰ê· ë‹¨ê°€(ì›)', 'ì´ê±°ë˜ëŸ‰(kg)']].mean().reset_index()\n",
    "\n",
    "        filename = os.path.basename(file_path)\n",
    "        item_name = re.split(r'\\(', filename)[0].strip()\n",
    "\n",
    "        fig, ax1 = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "        line1, = ax1.plot(weekly_avg['week'], weekly_avg['í‰ê· ë‹¨ê°€(ì›)'], color='tab:blue', marker='o', label='í‰ê· ë‹¨ê°€')\n",
    "        ax1.set_xlabel(\"ì£¼ì°¨\")\n",
    "        ax1.set_ylabel(\"í‰ê· ë‹¨ê°€(ì›)\", color='tab:blue')\n",
    "        ax1.tick_params(axis='y', labelcolor='tab:blue')\n",
    "\n",
    "        ax2 = ax1.twinx()\n",
    "        line2, = ax2.plot(weekly_avg['week'], weekly_avg['ì´ê±°ë˜ëŸ‰(kg)'], color='tab:orange', marker='x', label='ì´ê±°ë˜ëŸ‰')\n",
    "        ax2.set_ylabel(\"ì´ê±°ë˜ëŸ‰\", color='tab:orange')\n",
    "        ax2.tick_params(axis='y', labelcolor='tab:orange')\n",
    "        \n",
    "        lines = [line1, line2]\n",
    "        labels = [line.get_label() for line in lines]\n",
    "        ax1.legend(lines, labels, loc='upper right')\n",
    "\n",
    "        plt.title(f\"{item_name} - ì£¼ì°¨ë³„ í‰ê· ë‹¨ê°€ & ì´ê±°ë˜ëŸ‰ (ì „ì²´ ì—°ë„ í‰ê· )\")\n",
    "        fig.tight_layout()\n",
    "        plt.grid(True)\n",
    "        plt.show()\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"âš ï¸ íŒŒì¼ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {file_path}\")\n",
    "        print(f\"ì—ëŸ¬ ë‚´ìš©: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e4a22bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.font_manager as fm\n",
    "import seaborn as sns\n",
    "\n",
    "df = pd.read_csv(\"ê°ì/ê°ì(EDAìš©)_ìŠ¤ì¼€ì¼ë§ë§Œ.csv\", encoding='cp949', parse_dates=[\"week_start\"])\n",
    "\n",
    "plt.rcParams['font.family'] = 'Malgun Gothic'  # Windowsì˜ ê¸°ë³¸ í•œê¸€ í°íŠ¸\n",
    "plt.rcParams['axes.unicode_minus'] = False     # ìŒìˆ˜ ê¸°í˜¸ ê¹¨ì§ ë°©ì§€\n",
    "\n",
    "df['year'] = df['week_start'].dt.year\n",
    "df['month'] = df['week_start'].dt.month\n",
    "df['week'] = df['week_start'].dt.isocalendar().week\n",
    "df['dayofweek'] = df['week_start'].dt.dayofweek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f682cc14",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_col = 'í‰ê· ë‹¨ê°€(ì›)'\n",
    "X = df.drop(columns=[target_col, 'week_start'])  # week_startëŠ” ì‹œê°„ ì¸ë±ìŠ¤ì´ë¯€ë¡œ ì œì™¸\n",
    "y = df[target_col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c19184fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "\n",
    "tscv = TimeSeriesSplit(n_splits=5)\n",
    "for train_idx, test_idx in tscv.split(X):\n",
    "    X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
    "    y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31de2f97",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, (train_idx, test_idx) in enumerate(tscv.split(df), 1):\n",
    "    print(f\"[Fold {i}]\")\n",
    "    print(\"Train ê¸°ê°„:\", df.iloc[train_idx[0]]['week_start'], \"â†’\", df.iloc[train_idx[-1]]['week_start'])\n",
    "    print(\"Test  ê¸°ê°„:\", df.iloc[test_idx[0]]['week_start'], \"â†’\", df.iloc[test_idx[-1]]['week_start'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac4dc71f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "import numpy as np\n",
    "\n",
    "model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "tscv = TimeSeriesSplit(n_splits=5)\n",
    "\n",
    "mae_list, rmse_list, r2_list = [], [], []\n",
    "\n",
    "for fold, (train_idx, test_idx) in enumerate(tscv.split(X), 1):\n",
    "    X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
    "    y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
    "\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "    mae_list.append(mae)\n",
    "    rmse_list.append(rmse)\n",
    "    r2_list.append(r2)\n",
    "\n",
    "    print(f\"[Fold {fold}] MAE: {mae:.2f} | RMSE: {rmse:.2f} | RÂ²: {r2:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7b45912",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X, y)\n",
    "\n",
    "importances = model.feature_importances_\n",
    "feature_names = X.columns\n",
    "sorted_idx = np.argsort(importances)\n",
    "\n",
    "plt.figure(figsize=(8, len(feature_names)//2))\n",
    "plt.barh(range(len(sorted_idx)), importances[sorted_idx], align='center')\n",
    "plt.yticks(range(len(sorted_idx)), feature_names[sorted_idx])\n",
    "plt.title(\"Feature Importance (Random Forest)\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08a73ed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import make_scorer, mean_squared_error\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "df = pd.read_csv(\"EDA/ë¬´(EDAìš©)_ìŠ¤ì¼€ì¼ë§ë§Œ.csv\", encoding=\"cp949\")\n",
    "\n",
    "df = df.drop(columns=[\"ë“±ê¸‰ì½”ë“œ\"], errors=\"ignore\")\n",
    "df[\"week_start\"] = pd.to_datetime(df[\"week_start\"])\n",
    "df = df.sort_values(\"week_start\")\n",
    "\n",
    "df_model[\"week_sin\"] = np.sin(2 * np.pi * df_model[\"week\"] / 52)\n",
    "df_model[\"week_cos\"] = np.cos(2 * np.pi * df_model[\"week\"] / 52)\n",
    "\n",
    "target_col = \"í‰ê· ë‹¨ê°€(ì›)\"\n",
    "lag_features = [\n",
    "    \"ì¼í‰ê· ê¸°ì˜¨\", \"ìµœê³ ê¸°ì˜¨\", \"ìµœì €ê¸°ì˜¨\", \"í‰ê· ìƒëŒ€ìŠµë„\", \"ê°•ìˆ˜ëŸ‰(mm)\", \"1ì‹œê°„ìµœê³ ê°•ìˆ˜ëŸ‰(mm)\",\n",
    "    \"ì¼í‰ê· ê¸°ì˜¨_t-1\", \"ìµœê³ ê¸°ì˜¨_t-1\", \"ìµœì €ê¸°ì˜¨_t-1\", \"í‰ê· ìƒëŒ€ìŠµë„_t-1\", \"ê°•ìˆ˜ëŸ‰(mm)_t-1\", \"1ì‹œê°„ìµœê³ ê°•ìˆ˜ëŸ‰(mm)_t-1\",\n",
    "    \"ì¼í‰ê· ê¸°ì˜¨_t-2\", \"ìµœê³ ê¸°ì˜¨_t-2\", \"ìµœì €ê¸°ì˜¨_t-2\", \"í‰ê· ìƒëŒ€ìŠµë„_t-2\", \"ê°•ìˆ˜ëŸ‰(mm)_t-2\", \"1ì‹œê°„ìµœê³ ê°•ìˆ˜ëŸ‰(mm)_t-2\",\n",
    "    \"ì¼í‰ê· ê¸°ì˜¨_t-3\", \"ìµœê³ ê¸°ì˜¨_t-3\", \"ìµœì €ê¸°ì˜¨_t-3\", \"í‰ê· ìƒëŒ€ìŠµë„_t-3\", \"ê°•ìˆ˜ëŸ‰(mm)_t-3\", \"1ì‹œê°„ìµœê³ ê°•ìˆ˜ëŸ‰(mm)_t-3\"\n",
    "]\n",
    "derived_features = [\"holiday_flag\", \"holiday_score\", \"grow_score\"]\n",
    "categorical_cols = [\"í’ˆì¢…ì½”ë“œ\", \"ì§íŒœì‚°ì§€ì½”ë“œ\"]\n",
    "numeric_features = [\"ì´ê±°ë˜ëŸ‰(kg)\"]\n",
    "\n",
    "used_features = numeric_features + lag_features + derived_features + categorical_cols + [\"year\", \"week\", \"week_start\"]\n",
    "df_model = df.dropna(subset=[target_col] + used_features)\n",
    "\n",
    "df_model = pd.get_dummies(df_model, columns=categorical_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef7e50cc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y = df_model[target_col]\n",
    "X = df_model.drop(columns=[target_col])\n",
    "\n",
    "df_model = df_model[df_model[\"year\"] <= 2024].copy()\n",
    "y = df_model[\"í‰ê· ë‹¨ê°€(ì›)\"]\n",
    "X = df_model.drop(columns=[\"í‰ê· ë‹¨ê°€(ì›)\", \"year\", \"week\", \"week_start\"], errors=\"ignore\")\n",
    "X = X.select_dtypes(include=[np.number]).astype(np.float32)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5b480b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_model = XGBRegressor(objective=\"reg:squarederror\", random_state=42)\n",
    "\n",
    "param_grid = {\n",
    "    \"max_depth\": [4, 6, 8],\n",
    "    \"learning_rate\": [0.05, 0.1, 0.2],\n",
    "    \"n_estimators\": [100, 200],\n",
    "    \"subsample\": [0.8, 1.0]\n",
    "}\n",
    "\n",
    "rmse_scorer = make_scorer(mean_squared_error, squared=False)\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=xgb_model,\n",
    "    param_grid=param_grid,\n",
    "    scoring=rmse_scorer,\n",
    "    cv=3,  # êµì°¨ê²€ì¦ fold ìˆ˜\n",
    "    verbose=1,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c9cd503",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df143c00",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "y_pred = best_model.predict(X_val)\n",
    "\n",
    "rmse = mean_squared_error(y_val, y_pred, squared=False)\n",
    "mae = mean_absolute_error(y_val, y_pred)\n",
    "r2 = r2_score(y_val, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b47286f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import TimeSeriesSplit, GridSearchCV\n",
    "from sklearn.metrics import make_scorer, mean_squared_error\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "df = pd.read_csv(\"EDA/ë¬´(EDAìš©)_ìŠ¤ì¼€ì¼ë§ë§Œ.csv\", encoding=\"cp949\")\n",
    "\n",
    "df = df.drop(columns=[\"ë“±ê¸‰ì½”ë“œ\"], errors=\"ignore\")\n",
    "df[\"week_start\"] = pd.to_datetime(df[\"week_start\"])\n",
    "df = df.sort_values(\"week_start\")\n",
    "\n",
    "df[\"week_sin\"] = np.sin(2 * np.pi * df[\"week\"] / 52)\n",
    "df[\"week_cos\"] = np.cos(2 * np.pi * df[\"week\"] / 52)\n",
    "\n",
    "target_col = \"í‰ê· ë‹¨ê°€(ì›)\"\n",
    "lag_features = [\n",
    "    \"ì¼í‰ê· ê¸°ì˜¨\", \"ìµœê³ ê¸°ì˜¨\", \"ìµœì €ê¸°ì˜¨\", \"í‰ê· ìƒëŒ€ìŠµë„\", \"ê°•ìˆ˜ëŸ‰(mm)\", \"1ì‹œê°„ìµœê³ ê°•ìˆ˜ëŸ‰(mm)\",\n",
    "    \"ì¼í‰ê· ê¸°ì˜¨_t-1\", \"ìµœê³ ê¸°ì˜¨_t-1\", \"ìµœì €ê¸°ì˜¨_t-1\", \"í‰ê· ìƒëŒ€ìŠµë„_t-1\", \"ê°•ìˆ˜ëŸ‰(mm)_t-1\", \"1ì‹œê°„ìµœê³ ê°•ìˆ˜ëŸ‰(mm)_t-1\",\n",
    "    \"ì¼í‰ê· ê¸°ì˜¨_t-2\", \"ìµœê³ ê¸°ì˜¨_t-2\", \"ìµœì €ê¸°ì˜¨_t-2\", \"í‰ê· ìƒëŒ€ìŠµë„_t-2\", \"ê°•ìˆ˜ëŸ‰(mm)_t-2\", \"1ì‹œê°„ìµœê³ ê°•ìˆ˜ëŸ‰(mm)_t-2\",\n",
    "    \"ì¼í‰ê· ê¸°ì˜¨_t-3\", \"ìµœê³ ê¸°ì˜¨_t-3\", \"ìµœì €ê¸°ì˜¨_t-3\", \"í‰ê· ìƒëŒ€ìŠµë„_t-3\", \"ê°•ìˆ˜ëŸ‰(mm)_t-3\", \"1ì‹œê°„ìµœê³ ê°•ìˆ˜ëŸ‰(mm)_t-3\"\n",
    "]\n",
    "derived_features = [\"holiday_flag\", \"holiday_score\", \"grow_score\"]\n",
    "categorical_cols = [\"í’ˆì¢…ì½”ë“œ\", \"ì§íŒœì‚°ì§€ì½”ë“œ\"]\n",
    "numeric_features = [\"ì´ê±°ë˜ëŸ‰(kg)\", \"week_sin\", \"week_cos\"]\n",
    "\n",
    "used_features = numeric_features + lag_features + derived_features + categorical_cols + [\"year\", \"week\", \"week_start\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04a54b8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_model = df.dropna(subset=[target_col] + used_features).copy()\n",
    "\n",
    "df_model = pd.get_dummies(df_model, columns=categorical_cols)\n",
    "\n",
    "df_model = df_model[df_model[\"year\"] <= 2024]\n",
    "y = df_model[\"í‰ê· ë‹¨ê°€(ì›)\"]\n",
    "X = df_model.drop(columns=[\"í‰ê· ë‹¨ê°€(ì›)\", \"year\", \"week\", \"week_start\"], errors=\"ignore\")\n",
    "X = X.select_dtypes(include=[np.number]).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cca1b6c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "tscv = TimeSeriesSplit(n_splits=5)\n",
    "\n",
    "param_grid = {\n",
    "    \"max_depth\": [4, 6, 8],\n",
    "    \"learning_rate\": [0.05, 0.1, 0.2],\n",
    "    \"n_estimators\": [100, 200],\n",
    "    \"subsample\": [0.8, 1.0]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60c5897b",
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse_scorer = make_scorer(mean_squared_error, squared=False)\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=XGBRegressor(objective=\"reg:squarederror\", random_state=42),\n",
    "    param_grid=param_grid,\n",
    "    scoring=rmse_scorer,\n",
    "    cv=tscv,\n",
    "    verbose=1,\n",
    "    n_jobs=-1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baddb875",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac0c86f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "df = pd.read_csv(\"EDA/ë¬´(EDAìš©)_ìŠ¤ì¼€ì¼ë§ë§Œ.csv\", encoding=\"cp949\")\n",
    "df = df.drop(columns=[\"ë“±ê¸‰ì½”ë“œ\"], errors=\"ignore\")\n",
    "df[\"week_start\"] = pd.to_datetime(df[\"week_start\"])\n",
    "df = df.sort_values(\"week_start\")\n",
    "\n",
    "df[\"week_sin\"] = np.sin(2 * np.pi * df[\"week\"] / 52)\n",
    "df[\"week_cos\"] = np.cos(2 * np.pi * df[\"week\"] / 52)\n",
    "\n",
    "target_col = \"í‰ê· ë‹¨ê°€(ì›)\"\n",
    "lag_features = [\n",
    "    \"ì¼í‰ê· ê¸°ì˜¨\", \"ìµœê³ ê¸°ì˜¨\", \"ìµœì €ê¸°ì˜¨\", \"í‰ê· ìƒëŒ€ìŠµë„\", \"ê°•ìˆ˜ëŸ‰(mm)\", \"1ì‹œê°„ìµœê³ ê°•ìˆ˜ëŸ‰(mm)\",\n",
    "    \"ì¼í‰ê· ê¸°ì˜¨_t-1\", \"ìµœê³ ê¸°ì˜¨_t-1\", \"ìµœì €ê¸°ì˜¨_t-1\", \"í‰ê· ìƒëŒ€ìŠµë„_t-1\", \"ê°•ìˆ˜ëŸ‰(mm)_t-1\", \"1ì‹œê°„ìµœê³ ê°•ìˆ˜ëŸ‰(mm)_t-1\",\n",
    "    \"ì¼í‰ê· ê¸°ì˜¨_t-2\", \"ìµœê³ ê¸°ì˜¨_t-2\", \"ìµœì €ê¸°ì˜¨_t-2\", \"í‰ê· ìƒëŒ€ìŠµë„_t-2\", \"ê°•ìˆ˜ëŸ‰(mm)_t-2\", \"1ì‹œê°„ìµœê³ ê°•ìˆ˜ëŸ‰(mm)_t-2\",\n",
    "    \"ì¼í‰ê· ê¸°ì˜¨_t-3\", \"ìµœê³ ê¸°ì˜¨_t-3\", \"ìµœì €ê¸°ì˜¨_t-3\", \"í‰ê· ìƒëŒ€ìŠµë„_t-3\", \"ê°•ìˆ˜ëŸ‰(mm)_t-3\", \"1ì‹œê°„ìµœê³ ê°•ìˆ˜ëŸ‰(mm)_t-3\"\n",
    "]\n",
    "derived_features = [\"holiday_flag\", \"holiday_score\", \"grow_score\"]\n",
    "categorical_cols = [\"í’ˆì¢…ì½”ë“œ\", \"ì§íŒœì‚°ì§€ì½”ë“œ\"]\n",
    "numeric_features = [\"ì´ê±°ë˜ëŸ‰(kg)\", \"week_sin\", \"week_cos\"]\n",
    "\n",
    "used_features = numeric_features + lag_features + derived_features + categorical_cols + [\"year\", \"week\", \"week_start\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "967bc9a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_model = df.dropna(subset=[target_col] + used_features).copy()\n",
    "df_model = pd.get_dummies(df_model, columns=categorical_cols)\n",
    "\n",
    "df_model = df_model[df_model[\"year\"] <= 2024]\n",
    "y = df_model[\"í‰ê· ë‹¨ê°€(ì›)\"]\n",
    "X = df_model.drop(columns=[\"í‰ê· ë‹¨ê°€(ì›)\", \"year\", \"week\", \"week_start\"], errors=\"ignore\")\n",
    "X = X.select_dtypes(include=[np.number]).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8691697",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = XGBRegressor(\n",
    "    objective=\"reg:squarederror\",\n",
    "    learning_rate=0.2,\n",
    "    max_depth=8,\n",
    "    n_estimators=200,\n",
    "    subsample=0.8,\n",
    "    random_state=42\n",
    ")\n",
    "best_model.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "724a6f83",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = best_model.predict(X)\n",
    "rmse = mean_squared_error(y, y_pred, squared=False)\n",
    "mae = mean_absolute_error(y, y_pred)\n",
    "r2 = r2_score(y, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b259ae0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "df = pd.read_csv(\"EDA/ë¬´(EDAìš©)_ìŠ¤ì¼€ì¼ë§ë§Œ.csv\", encoding=\"cp949\")\n",
    "df = df.drop(columns=[\"ë“±ê¸‰ì½”ë“œ\"], errors=\"ignore\")\n",
    "df[\"week_start\"] = pd.to_datetime(df[\"week_start\"])\n",
    "df = df.sort_values(\"week_start\")\n",
    "\n",
    "df[\"week_sin\"] = np.sin(2 * np.pi * df[\"week\"] / 52)\n",
    "df[\"week_cos\"] = np.cos(2 * np.pi * df[\"week\"] / 52)\n",
    "\n",
    "target_col = \"í‰ê· ë‹¨ê°€(ì›)\"\n",
    "lag_features = [\n",
    "    \"ì¼í‰ê· ê¸°ì˜¨\", \"ìµœê³ ê¸°ì˜¨\", \"ìµœì €ê¸°ì˜¨\", \"í‰ê· ìƒëŒ€ìŠµë„\", \"ê°•ìˆ˜ëŸ‰(mm)\", \"1ì‹œê°„ìµœê³ ê°•ìˆ˜ëŸ‰(mm)\",\n",
    "    \"ì¼í‰ê· ê¸°ì˜¨_t-1\", \"ìµœê³ ê¸°ì˜¨_t-1\", \"ìµœì €ê¸°ì˜¨_t-1\", \"í‰ê· ìƒëŒ€ìŠµë„_t-1\", \"ê°•ìˆ˜ëŸ‰(mm)_t-1\", \"1ì‹œê°„ìµœê³ ê°•ìˆ˜ëŸ‰(mm)_t-1\",\n",
    "    \"ì¼í‰ê· ê¸°ì˜¨_t-2\", \"ìµœê³ ê¸°ì˜¨_t-2\", \"ìµœì €ê¸°ì˜¨_t-2\", \"í‰ê· ìƒëŒ€ìŠµë„_t-2\", \"ê°•ìˆ˜ëŸ‰(mm)_t-2\", \"1ì‹œê°„ìµœê³ ê°•ìˆ˜ëŸ‰(mm)_t-2\",\n",
    "    \"ì¼í‰ê· ê¸°ì˜¨_t-3\", \"ìµœê³ ê¸°ì˜¨_t-3\", \"ìµœì €ê¸°ì˜¨_t-3\", \"í‰ê· ìƒëŒ€ìŠµë„_t-3\", \"ê°•ìˆ˜ëŸ‰(mm)_t-3\", \"1ì‹œê°„ìµœê³ ê°•ìˆ˜ëŸ‰(mm)_t-3\"\n",
    "]\n",
    "derived_features = [\"holiday_flag\", \"holiday_score\", \"grow_score\"]\n",
    "categorical_cols = [\"í’ˆì¢…ì½”ë“œ\", \"ì§íŒœì‚°ì§€ì½”ë“œ\"]\n",
    "numeric_features = [\"ì´ê±°ë˜ëŸ‰(kg)\", \"week_sin\", \"week_cos\"]\n",
    "used_features = numeric_features + lag_features + derived_features + categorical_cols + [\"year\", \"week\", \"week_start\"]\n",
    "\n",
    "df_model = df.dropna(subset=[target_col] + used_features).copy()\n",
    "df_model = pd.get_dummies(df_model, columns=categorical_cols)\n",
    "\n",
    "latest_date = df_model[\"week_start\"].max()\n",
    "cutoff_date = latest_date - pd.Timedelta(weeks=52)\n",
    "test_df = df_model[df_model[\"week_start\"] > cutoff_date].copy()\n",
    "\n",
    "train_df = df_model[df_model[\"week_start\"] <= cutoff_date].copy()\n",
    "\n",
    "X_train = train_df.drop(columns=[target_col, \"year\", \"week\", \"week_start\"], errors=\"ignore\")\n",
    "y_train = train_df[target_col]\n",
    "X_test = test_df.drop(columns=[target_col, \"year\", \"week\", \"week_start\"], errors=\"ignore\")\n",
    "y_test = test_df[target_col]\n",
    "\n",
    "X_train = X_train.select_dtypes(include=[np.number]).astype(np.float32)\n",
    "X_test = X_test.select_dtypes(include=[np.number]).astype(np.float32)\n",
    "\n",
    "model = XGBRegressor(\n",
    "    objective=\"reg:squarederror\",\n",
    "    learning_rate=0.2,\n",
    "    max_depth=8,\n",
    "    n_estimators=200,\n",
    "    subsample=0.8,\n",
    "    random_state=42\n",
    ")\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6faf3cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.font_manager as fm\n",
    "import pandas as pd\n",
    "\n",
    "plt.rcParams[\"font.family\"] = \"Malgun Gothic\"\n",
    "plt.rcParams[\"axes.unicode_minus\"] = False\n",
    "\n",
    "test_df = test_df.copy()\n",
    "test_df[\"ì˜ˆì¸¡ê°’\"] = y_pred\n",
    "test_df[\"ì‹¤ì œê°’\"] = y_test.values\n",
    "\n",
    "recent_weeks = (\n",
    "    test_df[[\"year\", \"week\", \"week_start\"]]\n",
    "    .drop_duplicates()\n",
    "    .sort_values(\"week_start\")\n",
    "    .tail(52)\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "recent_weeks[\"ì—°ë„_ì£¼ì°¨\"] = recent_weeks[\"year\"].astype(str) + \"-\" + recent_weeks[\"week\"].astype(str).str.zfill(2)\n",
    "\n",
    "weekly_result = (\n",
    "    test_df.groupby([\"year\", \"week\"])[[\"ì‹¤ì œê°’\", \"ì˜ˆì¸¡ê°’\"]]\n",
    "    .mean()\n",
    "    .reset_index()\n",
    ")\n",
    "weekly_result[\"ì—°ë„_ì£¼ì°¨\"] = weekly_result[\"year\"].astype(str) + \"-\" + weekly_result[\"week\"].astype(str).str.zfill(2)\n",
    "\n",
    "plot_df = recent_weeks.merge(weekly_result, on=[\"year\", \"week\", \"ì—°ë„_ì£¼ì°¨\"], how=\"left\")\n",
    "\n",
    "plt.figure(figsize=(16, 6))\n",
    "plt.plot(plot_df[\"ì—°ë„_ì£¼ì°¨\"], plot_df[\"ì‹¤ì œê°’\"], label=\"ì‹¤ì œ í‰ê· ë‹¨ê°€\", marker=\"o\")\n",
    "plt.plot(plot_df[\"ì—°ë„_ì£¼ì°¨\"], plot_df[\"ì˜ˆì¸¡ê°’\"], label=\"ì˜ˆì¸¡ í‰ê· ë‹¨ê°€\", marker=\"x\")\n",
    "plt.title(\"ì˜ˆì¸¡ vs ì‹¤ì œ í‰ê· ë‹¨ê°€ (ìµœê·¼ 1ë…„, ì£¼ì°¨ë³„)\")\n",
    "plt.xlabel(\"ì—°ë„-ì£¼ì°¨\")\n",
    "plt.ylabel(\"í‰ê· ë‹¨ê°€(ì›)\")\n",
    "plt.xticks(rotation=45, fontsize=9)\n",
    "plt.grid(True, linestyle=\"--\", alpha=0.5)\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5249f73f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "future_weeks = [23, 24, 25, 26, 27, 28, 29, 30]\n",
    "base_year = 2025\n",
    "last_week_start = df_model[df_model[\"year\"] == 2025][\"week_start\"].max()\n",
    "\n",
    "template = df_model[df_model[\"year\"] == 2025].copy()\n",
    "recent_avg = template.select_dtypes(include=[np.number]).mean()\n",
    "\n",
    "future_rows = []\n",
    "for week in future_weeks:\n",
    "    row = recent_avg.copy()\n",
    "    row[\"year\"] = base_year\n",
    "    row[\"week\"] = week\n",
    "    row[\"week_sin\"] = np.sin(2 * np.pi * week / 52)\n",
    "    row[\"week_cos\"] = np.cos(2 * np.pi * week / 52)\n",
    "    row[\"week_start\"] = last_week_start + pd.Timedelta(weeks=week - 22)  # 22ì£¼ì°¨ ì´í›„ë¶€í„° ê³„ì†\n",
    "    future_rows.append(row)\n",
    "\n",
    "future_input = pd.DataFrame(future_rows)\n",
    "\n",
    "for col in X_train.columns:\n",
    "    if col not in future_input.columns:\n",
    "        future_input[col] = 0  # ì›í•«ì¸ì½”ë”© ëˆ„ë½ ëŒ€ì‘\n",
    "\n",
    "X_future = future_input[X_train.columns].astype(np.float32)\n",
    "\n",
    "future_preds = model.predict(X_future)\n",
    "\n",
    "result_df = pd.DataFrame({\n",
    "    \"year\": future_input[\"year\"],\n",
    "    \"week\": future_input[\"week\"],\n",
    "    \"week_start\": future_input[\"week_start\"],\n",
    "    \"ì˜ˆì¸¡ê°’\": future_preds\n",
    "})\n",
    "\n",
    "result_df[\"ì—°ë„_ì£¼ì°¨\"] = (\n",
    "    result_df[\"year\"].astype(int).astype(str) + \"-\" + result_df[\"week\"].astype(int).astype(str).str.zfill(2)\n",
    ")\n",
    "\n",
    "result_df = result_df[[\"ì—°ë„_ì£¼ì°¨\", \"ì˜ˆì¸¡ê°’\", \"week_start\"]]\n",
    "display(result_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80fe45a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.rcParams[\"font.family\"] = \"Malgun Gothic\"\n",
    "plt.rcParams[\"axes.unicode_minus\"] = False\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(result_df[\"ì—°ë„_ì£¼ì°¨\"], result_df[\"ì˜ˆì¸¡ê°’\"], marker=\"o\", color=\"tomato\", label=\"ì˜ˆì¸¡ í‰ê· ë‹¨ê°€\")\n",
    "plt.title(\"2025ë…„ 23~30ì£¼ì°¨ ì˜ˆì¸¡ í‰ê· ë‹¨ê°€\")\n",
    "plt.xlabel(\"ì—°ë„-ì£¼ì°¨\")\n",
    "plt.ylabel(\"í‰ê· ë‹¨ê°€(ì›)\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid(True, linestyle=\"--\", alpha=0.6)\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0994f91",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "df = pd.read_csv(\"EDA/ë¬´(EDAìš©)_ìŠ¤ì¼€ì¼ë§ë§Œ.csv\", encoding=\"cp949\")\n",
    "df = df.drop(columns=[\"ë“±ê¸‰ì½”ë“œ\"], errors=\"ignore\")\n",
    "df[\"week_start\"] = pd.to_datetime(df[\"week_start\"])\n",
    "df = df.sort_values(\"week_start\")\n",
    "\n",
    "df[\"week_sin\"] = np.sin(2 * np.pi * df[\"week\"] / 52)\n",
    "df[\"week_cos\"] = np.cos(2 * np.pi * df[\"week\"] / 52)\n",
    "\n",
    "group_cols = [\"ì§íŒœì‚°ì§€ì½”ë“œ\"]\n",
    "df[\"í‰ê· ë‹¨ê°€(ì›)_lag1\"] = df.groupby(group_cols)[\"í‰ê· ë‹¨ê°€(ì›)\"].shift(1)\n",
    "df[\"í‰ê· ë‹¨ê°€(ì›)_lag2\"] = df.groupby(group_cols)[\"í‰ê· ë‹¨ê°€(ì›)\"].shift(2)\n",
    "df[\"í‰ê· ë‹¨ê°€(ì›)_ma3\"] = (\n",
    "    df.groupby(group_cols)[\"í‰ê· ë‹¨ê°€(ì›)\"]\n",
    "    .shift(1)\n",
    "    .rolling(window=3, min_periods=1)\n",
    "    .mean()\n",
    "    .reset_index(level=0, drop=True)\n",
    ")\n",
    "df[\"í‰ê· ë‹¨ê°€(ì›)_ma5\"] = (\n",
    "    df.groupby(group_cols)[\"í‰ê· ë‹¨ê°€(ì›)\"]\n",
    "    .shift(1)\n",
    "    .rolling(window=5, min_periods=1)\n",
    "    .mean()\n",
    "    .reset_index(level=0, drop=True)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32e3b6d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_col = \"í‰ê· ë‹¨ê°€(ì›)\"\n",
    "lag_features = [col for col in df.columns if \"_t-\" in col]\n",
    "derived_features = [\"holiday_flag\", \"holiday_score\", \"grow_score\"]\n",
    "categorical_cols = [\"í’ˆì¢…ì½”ë“œ\"]\n",
    "numeric_features = [\"ì´ê±°ë˜ëŸ‰(kg)\", \"week_sin\", \"week_cos\"]\n",
    "price_features = [\"í‰ê· ë‹¨ê°€(ì›)_lag1\", \"í‰ê· ë‹¨ê°€(ì›)_lag2\", \"í‰ê· ë‹¨ê°€(ì›)_ma3\", \"í‰ê· ë‹¨ê°€(ì›)_ma5\"]\n",
    "\n",
    "used_features = (\n",
    "    numeric_features + lag_features + derived_features +\n",
    "    categorical_cols + price_features + [\"ì§íŒœì‚°ì§€ì½”ë“œ\", \"year\", \"week\", \"week_start\"]\n",
    ")\n",
    "\n",
    "df_model = df.dropna(subset=[target_col] + used_features).copy()\n",
    "df_model = df_model[df_model[\"year\"] <= 2024].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30a0b538",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_splits = 5\n",
    "kf = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "df_model[\"ì§íŒœì‚°ì§€ì½”ë“œ_te\"] = np.nan\n",
    "\n",
    "for train_idx, val_idx in kf.split(df_model):\n",
    "    train_fold = df_model.iloc[train_idx]\n",
    "    val_fold = df_model.iloc[val_idx]\n",
    "    means = train_fold.groupby(\"ì§íŒœì‚°ì§€ì½”ë“œ\")[target_col].mean()\n",
    "    df_model.iloc[val_idx, df_model.columns.get_loc(\"ì§íŒœì‚°ì§€ì½”ë“œ_te\")] = val_fold[\"ì§íŒœì‚°ì§€ì½”ë“œ\"].map(means)\n",
    "\n",
    "global_mean = df_model[target_col].mean()\n",
    "df_model[\"ì§íŒœì‚°ì§€ì½”ë“œ_te\"] = df_model[\"ì§íŒœì‚°ì§€ì½”ë“œ_te\"].fillna(global_mean)\n",
    "\n",
    "df_model = pd.get_dummies(df_model, columns=[\"í’ˆì¢…ì½”ë“œ\"])\n",
    "\n",
    "y = df_model[target_col]\n",
    "X = df_model.drop(columns=[\"í‰ê· ë‹¨ê°€(ì›)\", \"year\", \"week\", \"week_start\", \"ì§íŒœì‚°ì§€ì½”ë“œ\"], errors=\"ignore\")\n",
    "X = X.select_dtypes(include=[np.number]).astype(np.float32)\n",
    "\n",
    "xgb = XGBRegressor(objective=\"reg:squarederror\", random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "721cfe8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "xgb = XGBRegressor(objective=\"reg:squarederror\", random_state=42)\n",
    "\n",
    "param_grid = {\n",
    "    \"learning_rate\": [0.05, 0.1, 0.2],\n",
    "    \"max_depth\": [6, 8],\n",
    "    \"n_estimators\": [100, 200],\n",
    "    \"subsample\": [0.8, 1.0],\n",
    "    \"colsample_bytree\": [0.8, 1.0]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=xgb,\n",
    "    param_grid=param_grid,\n",
    "    scoring=\"neg_root_mean_squared_error\",\n",
    "    cv=3,\n",
    "    verbose=1,\n",
    "    n_jobs=-1  # ëª¨ë“  CPU ì½”ì–´ ì‚¬ìš©\n",
    ")\n",
    "\n",
    "grid_search.fit(X, y)\n",
    "\n",
    "print(\"ğŸ“Œ ìµœì  í•˜ì´í¼íŒŒë¼ë¯¸í„°:\")\n",
    "print(grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a58c995",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = XGBRegressor(\n",
    "    objective=\"reg:squarederror\",\n",
    "    learning_rate=0.05,\n",
    "    max_depth=6,\n",
    "    n_estimators=200,\n",
    "    subsample=1.0,\n",
    "    colsample_bytree=0.8,\n",
    "    random_state=42\n",
    ")\n",
    "best_model.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37bfcefd",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X)\n",
    "rmse = mean_squared_error(y, y_pred, squared=False)\n",
    "mae = mean_absolute_error(y, y_pred)\n",
    "r2 = r2_score(y, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76e5dbf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "test_df = df[df[\"year\"] == 2025].dropna(subset=used_features).copy()\n",
    "y_test = test_df[\"í‰ê· ë‹¨ê°€(ì›)\"]\n",
    "\n",
    "X_test = test_df.drop(columns=[\"í‰ê· ë‹¨ê°€(ì›)\", \"year\", \"week\", \"week_start\", \"ì§íŒœì‚°ì§€ì½”ë“œ\"], errors=\"ignore\")\n",
    "X_test = pd.get_dummies(X_test, columns=[\"í’ˆì¢…ì½”ë“œ\"])\n",
    "\n",
    "model_cols = best_model.feature_names_in_\n",
    "missing_cols = set(model_cols) - set(X_test.columns)\n",
    "for col in missing_cols:\n",
    "    X_test[col] = 0\n",
    "X_test = X_test[model_cols]  # ì»¬ëŸ¼ ìˆœì„œ ì¼ì¹˜\n",
    "\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "plt.rcParams[\"font.family\"] = \"Malgun Gothic\"  # í•œê¸€ í°íŠ¸\n",
    "plt.rcParams[\"axes.unicode_minus\"] = False\n",
    "\n",
    "test_df = test_df.copy()\n",
    "test_df[\"ì˜ˆì¸¡ê°’\"] = y_pred\n",
    "test_df[\"ì‹¤ì œê°’\"] = y_test.values\n",
    "\n",
    "recent_weeks = (\n",
    "    test_df[[\"year\", \"week\", \"week_start\"]]\n",
    "    .drop_duplicates()\n",
    "    .sort_values(\"week_start\")\n",
    "    .tail(52)\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "recent_weeks[\"ì—°ë„_ì£¼ì°¨\"] = recent_weeks[\"year\"].astype(str) + \"-\" + recent_weeks[\"week\"].astype(str).str.zfill(2)\n",
    "\n",
    "weekly_result = (\n",
    "    test_df.groupby([\"year\", \"week\"])[[\"ì‹¤ì œê°’\", \"ì˜ˆì¸¡ê°’\"]]\n",
    "    .mean()\n",
    "    .reset_index()\n",
    ")\n",
    "weekly_result[\"ì—°ë„_ì£¼ì°¨\"] = weekly_result[\"year\"].astype(str) + \"-\" + weekly_result[\"week\"].astype(str).str.zfill(2)\n",
    "\n",
    "plot_df = recent_weeks.merge(weekly_result, on=[\"year\", \"week\", \"ì—°ë„_ì£¼ì°¨\"], how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea653912",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16, 6))\n",
    "plt.plot(plot_df[\"ì—°ë„_ì£¼ì°¨\"], plot_df[\"ì‹¤ì œê°’\"], label=\"ì‹¤ì œ í‰ê· ë‹¨ê°€\", marker=\"o\")\n",
    "plt.plot(plot_df[\"ì—°ë„_ì£¼ì°¨\"], plot_df[\"ì˜ˆì¸¡ê°’\"], label=\"ì˜ˆì¸¡ í‰ê· ë‹¨ê°€\", marker=\"x\")\n",
    "plt.title(\"ì˜ˆì¸¡ vs ì‹¤ì œ í‰ê· ë‹¨ê°€ (ìµœê·¼ 1ë…„, ì£¼ì°¨ë³„)\")\n",
    "plt.xlabel(\"ì—°ë„-ì£¼ì°¨\")\n",
    "plt.ylabel(\"í‰ê· ë‹¨ê°€(ì›)\")\n",
    "plt.xticks(rotation=45, fontsize=9)\n",
    "plt.grid(True, linestyle=\"--\", alpha=0.5)\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a91b66b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb8d4fdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.model_selection import TimeSeriesSplit, RandomizedSearchCV, train_test_split\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from xgboost.callback import EarlyStopping\n",
    "\n",
    "df = pd.read_csv(\"EDA/ë¬´(EDAìš©)_ìŠ¤ì¼€ì¼ë§ë§Œ_ë³‘í•©.csv\", encoding=\"cp949\")\n",
    "df = df.drop(columns=[\"ë“±ê¸‰ì½”ë“œ\"], errors=\"ignore\")\n",
    "df[\"week_start\"] = pd.to_datetime(df[\"week_start\"])\n",
    "df = df.sort_values(\"week_start\")\n",
    "\n",
    "df[\"week_sin\"] = np.sin(2 * np.pi * df[\"week\"] / 52)\n",
    "df[\"week_cos\"] = np.cos(2 * np.pi * df[\"week\"] / 52)\n",
    "\n",
    "group_cols = [\"ì§íŒœì‚°ì§€ì½”ë“œ\"]\n",
    "df[\"ì´ê±°ë˜ëŸ‰_lag1\"] = df.groupby(group_cols)[\"ì´ê±°ë˜ëŸ‰(kg)\"].shift(1)\n",
    "df[\"ì´ê±°ë˜ëŸ‰_ë³€í™”ìœ¨\"] = np.where(\n",
    "    df[\"ì´ê±°ë˜ëŸ‰_lag1\"] == 0,\n",
    "    0,\n",
    "    (df[\"ì´ê±°ë˜ëŸ‰(kg)\"] - df[\"ì´ê±°ë˜ëŸ‰_lag1\"]) / df[\"ì´ê±°ë˜ëŸ‰_lag1\"]\n",
    ")\n",
    "df[\"í‰ê· ë‹¨ê°€_ì „ë…„ë™ì£¼\"] = df.groupby(group_cols)[\"í‰ê· ë‹¨ê°€(ì›)\"].shift(52)\n",
    "df[\"í‰ê· ë‹¨ê°€_ì „ë…„ë¹„\"] = (df[\"í‰ê· ë‹¨ê°€(ì›)\"] - df[\"í‰ê· ë‹¨ê°€_ì „ë…„ë™ì£¼\"]) / df[\"í‰ê· ë‹¨ê°€_ì „ë…„ë™ì£¼\"]\n",
    "\n",
    "target_col = \"í‰ê· ë‹¨ê°€(ì›)\"\n",
    "lag_features = [col for col in df.columns if \"_t-\" in col]\n",
    "derived_features = [\"holiday_flag\", \"holiday_score\", \"grow_score\"]\n",
    "categorical_cols = [\"í’ˆì¢…ì½”ë“œ\"]\n",
    "numeric_features = [\"ì´ê±°ë˜ëŸ‰(kg)\", \"week_sin\", \"week_cos\"]\n",
    "change_features = [\"ì´ê±°ë˜ëŸ‰_ë³€í™”ìœ¨\", \"í‰ê· ë‹¨ê°€_ì „ë…„ë¹„\"]\n",
    "\n",
    "used_features = (\n",
    "    numeric_features + lag_features + derived_features +\n",
    "    categorical_cols + change_features + [\"ì§íŒœì‚°ì§€ì½”ë“œ\", \"year\", \"week\", \"week_start\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d02b50bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_model = df.dropna(subset=[target_col] + used_features).copy()\n",
    "df_model = df_model[df_model[\"year\"] <= 2024].copy()\n",
    "\n",
    "le = LabelEncoder()\n",
    "df_model[\"ì§íŒœì‚°ì§€ì½”ë“œ_le\"] = le.fit_transform(df_model[\"ì§íŒœì‚°ì§€ì½”ë“œ\"])\n",
    "\n",
    "df_model = pd.get_dummies(df_model, columns=[\"í’ˆì¢…ì½”ë“œ\"])\n",
    "\n",
    "y = df_model[target_col]\n",
    "X = df_model.drop(columns=[\"í‰ê· ë‹¨ê°€(ì›)\", \"year\", \"week\", \"week_start\", \"ì§íŒœì‚°ì§€ì½”ë“œ\"], errors=\"ignore\")\n",
    "X = X.select_dtypes(include=[np.number]).astype(np.float32)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, y, test_size=0.2, shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d3afd36",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb = XGBRegressor(objective=\"reg:squarederror\", random_state=42)\n",
    "param_dist = {\n",
    "    \"learning_rate\": [0.01, 0.03, 0.05],\n",
    "    \"max_depth\": [3, 4, 5],\n",
    "    \"min_child_weight\": [1, 3, 5],\n",
    "    \"subsample\": [0.7, 0.8, 0.9],\n",
    "    \"colsample_bytree\": [0.7, 0.8, 0.9],\n",
    "    \"gamma\": [0, 1, 5],\n",
    "    \"n_estimators\": [100, 150, 200, 300]\n",
    "}\n",
    "\n",
    "tscv = TimeSeriesSplit(n_splits=3)\n",
    "rand_search = RandomizedSearchCV(\n",
    "    estimator=xgb,\n",
    "    param_distributions=param_dist,\n",
    "    n_iter=30,\n",
    "    scoring=\"neg_root_mean_squared_error\",\n",
    "    cv=tscv,\n",
    "    verbose=1,\n",
    "    n_jobs=-1,\n",
    "    random_state=42\n",
    ")\n",
    "rand_search.fit(X, y)\n",
    "\n",
    "print(\"ğŸ“Œ ìµœì  í•˜ì´í¼íŒŒë¼ë¯¸í„°:\")\n",
    "print(rand_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90f62ce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = XGBRegressor(\n",
    "    objective=\"reg:squarederror\",\n",
    "    eval_metric=\"rmse\",\n",
    "    random_state=42,\n",
    "    **rand_search.best_params_\n",
    ")\n",
    "\n",
    "best_model.fit(\n",
    "    X_train, y_train,\n",
    "    eval_set=[(X_val, y_val)],\n",
    "    callbacks=[EarlyStopping(rounds=30)],\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "y_val_pred = best_model.predict(X_val)\n",
    "rmse = mean_squared_error(y_val, y_val_pred, squared=False)\n",
    "mae = mean_absolute_error(y_val, y_val_pred)\n",
    "r2 = r2_score(y_val, y_val_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28d53f33",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le = LabelEncoder()\n",
    "le.fit(df_model[\"ì§íŒœì‚°ì§€ì½”ë“œ\"])  # df_modelì€ year <= 2024\n",
    "\n",
    "test_df = df[df[\"year\"] == 2025].copy()\n",
    "test_regions = set(test_df[\"ì§íŒœì‚°ì§€ì½”ë“œ\"].unique())\n",
    "train_regions = set(le.classes_)\n",
    "\n",
    "unseen_regions = test_regions - train_regions\n",
    "\n",
    "if unseen_regions:\n",
    "    print(f\"âš ï¸ í…ŒìŠ¤íŠ¸ì…‹ì— í•™ìŠµì…‹ì— ì—†ë˜ LabelEncoder í´ë˜ìŠ¤ ì¡´ì¬: {unseen_regions}\")\n",
    "else:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0cbdd04",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = X.shape[0]\n",
    "\n",
    "n_features = X.shape[1]\n",
    "\n",
    "print(f\"ğŸ“¦ í•™ìŠµ ë°ì´í„° ìˆ˜: {n_samples}\")\n",
    "print(f\"ğŸ”¢ í”¼ì²˜ ìˆ˜: {n_features}\")\n",
    "print(f\"ğŸ“ ìƒ˜í”Œë‹¹ í”¼ì²˜ ë¹„ìœ¨: {n_samples / n_features:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a740f60",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "plt.rcParams[\"font.family\"] = \"Malgun Gothic\"\n",
    "plt.rcParams[\"axes.unicode_minus\"] = False\n",
    "\n",
    "importance = best_model.get_booster().get_score(importance_type=\"gain\")\n",
    "importance_df = pd.DataFrame({\n",
    "    \"feature\": list(importance.keys()),\n",
    "    \"importance\": list(importance.values())\n",
    "})\n",
    "importance_df = importance_df.sort_values(\"importance\", ascending=False).reset_index(drop=True)\n",
    "\n",
    "top_n = 20\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.barh(importance_df[\"feature\"][:top_n][::-1], importance_df[\"importance\"][:top_n][::-1])\n",
    "plt.xlabel(\"Importance (Gain)\")\n",
    "plt.title(f\"Top {top_n} Feature Importance (by Gain)\")\n",
    "plt.tight_layout()\n",
    "plt.grid(True, axis=\"x\", linestyle=\"--\", alpha=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ecd378a",
   "metadata": {},
   "outputs": [],
   "source": [
    "importance_dict = best_model.get_booster().get_score(importance_type=\"gain\")\n",
    "\n",
    "target_feature = \"ì´ê±°ë˜ëŸ‰_ë³€í™”ìœ¨\"\n",
    "importance_value = importance_dict.get(target_feature, 0)\n",
    "\n",
    "print(f\"ğŸ“Œ 'ì´ê±°ë˜ëŸ‰_ë³€í™”ìœ¨' ì¤‘ìš”ë„ (Gain): {importance_value:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f951f64",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "importance_dict = best_model.get_booster().get_score(importance_type=\"gain\")\n",
    "importance_df = pd.DataFrame({\n",
    "    \"feature\": list(importance_dict.keys()),\n",
    "    \"importance\": list(importance_dict.values())\n",
    "}).sort_values(by=\"importance\", ascending=False).reset_index(drop=True)\n",
    "\n",
    "importance_df[\"rank\"] = importance_df.index + 1\n",
    "\n",
    "target_feature = \"ì´ê±°ë˜ëŸ‰_ë³€í™”ìœ¨\"\n",
    "target_row = importance_df[importance_df[\"feature\"] == target_feature]\n",
    "\n",
    "if not target_row.empty:\n",
    "    rank = int(target_row[\"rank\"].values[0])\n",
    "    gain = float(target_row[\"importance\"].values[0])\n",
    "else:\n",
    "    print(\"âŒ 'ì´ê±°ë˜ëŸ‰_ë³€í™”ìœ¨'ì€ ë³€ìˆ˜ ì¤‘ìš”ë„ ëª©ë¡ì— ì—†ìŠµë‹ˆë‹¤.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "482b69cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "test_df = df[df[\"year\"] == 2025].copy()\n",
    "\n",
    "y_test = test_df[\"í‰ê· ë‹¨ê°€(ì›)\"].copy()\n",
    "test_df = test_df.drop(columns=[\"í‰ê· ë‹¨ê°€(ì›)\"])\n",
    "\n",
    "known_codes = set(le.classes_)\n",
    "test_df = test_df[test_df[\"ì§íŒœì‚°ì§€ì½”ë“œ\"].isin(known_codes)].copy()\n",
    "y_test = y_test.loc[test_df.index]  # y_testë„ ë™ì¼í•˜ê²Œ index ë§ì¶”ê¸°\n",
    "test_df[\"ì§íŒœì‚°ì§€ì½”ë“œ_le\"] = le.transform(test_df[\"ì§íŒœì‚°ì§€ì½”ë“œ\"])\n",
    "\n",
    "test_df = pd.get_dummies(test_df, columns=[\"í’ˆì¢…ì½”ë“œ\"])\n",
    "\n",
    "missing_cols = set(df_model.columns) - set(test_df.columns)\n",
    "missing_cols = [col for col in missing_cols if col.startswith(\"í’ˆì¢…ì½”ë“œ_\")]\n",
    "for col in missing_cols:\n",
    "    test_df[col] = 0\n",
    "\n",
    "X_test = test_df.drop(columns=[\"year\", \"week\", \"week_start\", \"ì§íŒœì‚°ì§€ì½”ë“œ\"], errors=\"ignore\")\n",
    "X_test = X_test.select_dtypes(include=[np.number])\n",
    "\n",
    "X_test = X_test[best_model.feature_names_in_].astype(np.float32)\n",
    "\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56fd3c91",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.rcParams[\"font.family\"] = \"Malgun Gothic\"\n",
    "plt.rcParams[\"axes.unicode_minus\"] = False\n",
    "\n",
    "plot_df = test_df.copy()\n",
    "plot_df = plot_df.reset_index(drop=True)  # ì¸ë±ìŠ¤ ì •ë ¬\n",
    "plot_df[\"ì˜ˆì¸¡ê°’\"] = y_pred\n",
    "plot_df[\"ì‹¤ì œê°’\"] = y_test.reset_index(drop=True)\n",
    "\n",
    "weekly_avg = (\n",
    "    plot_df.groupby([\"year\", \"week\"])[[\"ì‹¤ì œê°’\", \"ì˜ˆì¸¡ê°’\"]]\n",
    "    .mean()\n",
    "    .reset_index()\n",
    ")\n",
    "weekly_avg[\"ì—°ë„_ì£¼ì°¨\"] = (\n",
    "    weekly_avg[\"year\"].astype(str) + \"-\" + weekly_avg[\"week\"].astype(str).str.zfill(2)\n",
    ")\n",
    "\n",
    "plt.figure(figsize=(16, 6))\n",
    "plt.plot(weekly_avg[\"ì—°ë„_ì£¼ì°¨\"], weekly_avg[\"ì‹¤ì œê°’\"], label=\"ì‹¤ì œ í‰ê· ë‹¨ê°€\", marker=\"o\", linewidth=2)\n",
    "plt.plot(weekly_avg[\"ì—°ë„_ì£¼ì°¨\"], weekly_avg[\"ì˜ˆì¸¡ê°’\"], label=\"ì˜ˆì¸¡ í‰ê· ë‹¨ê°€\", marker=\"x\", linewidth=2)\n",
    "plt.title(\"ì˜ˆì¸¡ vs ì‹¤ì œ í‰ê· ë‹¨ê°€ (ì£¼ì°¨ë³„ í‰ê· )\")\n",
    "plt.xlabel(\"ì—°ë„-ì£¼ì°¨\")\n",
    "plt.ylabel(\"í‰ê· ë‹¨ê°€(ì›)\")\n",
    "plt.xticks(rotation=45, fontsize=9)\n",
    "plt.grid(True, linestyle=\"--\", alpha=0.5)\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3b9a648",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.rcParams[\"font.family\"] = \"Malgun Gothic\"\n",
    "plt.rcParams[\"axes.unicode_minus\"] = False\n",
    "\n",
    "part1_df = test_df.copy()\n",
    "part1_df[\"ì˜ˆì¸¡ê°’\"] = y_pred\n",
    "part1_df[\"ì‹¤ì œê°’\"] = y_test.values\n",
    "part1_df[\"ì—°ë„_ì£¼ì°¨\"] = part1_df[\"year\"].astype(str) + \"-\" + part1_df[\"week\"].astype(str).str.zfill(2)\n",
    "\n",
    "part1_avg = (\n",
    "    part1_df.groupby([\"year\", \"week\", \"ì—°ë„_ì£¼ì°¨\"])[[\"ì‹¤ì œê°’\", \"ì˜ˆì¸¡ê°’\"]]\n",
    "    .mean()\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "last_pred = part1_avg[\"ì˜ˆì¸¡ê°’\"].iloc[-1]\n",
    "weeks_future = pd.DataFrame({\n",
    "    \"year\": [2025]*30,\n",
    "    \"week\": list(range(23, 53)),\n",
    "})\n",
    "weeks_future[\"ì—°ë„_ì£¼ì°¨\"] = weeks_future[\"year\"].astype(str) + \"-\" + weeks_future[\"week\"].astype(str).str.zfill(2)\n",
    "weeks_future[\"ì˜ˆì¸¡ê°’\"] = last_pred\n",
    "weeks_future[\"ì‹¤ì œê°’\"] = np.nan  # ì‹¤ì œê°’ ì—†ìŒ\n",
    "\n",
    "plot_df = pd.concat([part1_avg, weeks_future], ignore_index=True)\n",
    "\n",
    "plt.figure(figsize=(16, 6))\n",
    "plt.plot(plot_df[\"ì—°ë„_ì£¼ì°¨\"], plot_df[\"ì˜ˆì¸¡ê°’\"], label=\"ì˜ˆì¸¡ í‰ê· ë‹¨ê°€\", marker=\"o\", linewidth=2)\n",
    "plt.plot(plot_df[\"ì—°ë„_ì£¼ì°¨\"], plot_df[\"ì‹¤ì œê°’\"], label=\"ì‹¤ì œ í‰ê· ë‹¨ê°€\", marker=\"x\", linewidth=2)\n",
    "plt.title(\"2025ë…„ í‰ê· ë‹¨ê°€ (1~22ì£¼: ì‹¤ì œ+ì˜ˆì¸¡ / 23~52ì£¼: ì •ë³´ ì—†ìŒ, ì˜ˆì¸¡ ì—°ì¥)\")\n",
    "plt.xlabel(\"ì—°ë„-ì£¼ì°¨\")\n",
    "plt.ylabel(\"í‰ê· ë‹¨ê°€(ì›)\")\n",
    "plt.xticks(rotation=45, fontsize=9)\n",
    "plt.grid(True, linestyle=\"--\", alpha=0.5)\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2452eab2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-dl-nlp",
   "language": "python",
   "name": "ml-dl-nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
