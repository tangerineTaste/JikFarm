{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5a1cdcaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "item_nm = 'ë°°ì¶”'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5a849626",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_2520\\3349438536.py:10: DtypeWarning: Columns (13) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_retry_success = pd.read_csv(retry_success_path, encoding='cp949')\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_2520\\3349438536.py:11: DtypeWarning: Columns (17) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_template = pd.read_csv(template_path, encoding='cp949')\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'0'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32m~\\anaconda3\\envs\\ml-dl-nlp\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3802\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3801\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3802\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3803\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\ml-dl-nlp\\lib\\site-packages\\pandas\\_libs\\index.pyx:138\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\ml-dl-nlp\\lib\\site-packages\\pandas\\_libs\\index.pyx:165\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:5745\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:5753\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: '0'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 14\u001b[0m\n\u001b[0;32m     11\u001b[0m df_template \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(template_path, encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcp949\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# \"0\" ê°’ë§Œ ìˆëŠ” í–‰ ì œê±°\u001b[39;00m\n\u001b[1;32m---> 14\u001b[0m df_filtered \u001b[38;5;241m=\u001b[39m df_retry_success[\u001b[43mdf_retry_success\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m0\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m0\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[0;32m     15\u001b[0m df_filtered\u001b[38;5;241m.\u001b[39mcolumns \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraw\u001b[39m\u001b[38;5;124m\"\u001b[39m]  \u001b[38;5;66;03m# ì—´ ì´ë¦„ ì¬ì§€ì •\u001b[39;00m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m# ë¬¸ìì—´ì„ íŒŒì´ì¬ ë”•ì…”ë„ˆë¦¬ë¡œ ì•ˆì „í•˜ê²Œ ë³€í™˜\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\ml-dl-nlp\\lib\\site-packages\\pandas\\core\\frame.py:3807\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3805\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   3806\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 3807\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3808\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   3809\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\ml-dl-nlp\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3804\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3802\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3803\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m-> 3804\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3805\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3806\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3807\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3808\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3809\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: '0'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import ast\n",
    "\n",
    "# íŒŒì¼ ê²½ë¡œ\n",
    "retry_success_path = \"ìœ í†µê³µì‚¬_retry_success_20250710_083318.csv\"\n",
    "template_path = \"ìœ í†µê³µì‚¬_ë„ë§¤ì‹œì¥_ë°°ì¶”.csv\"\n",
    "output_path = \"ìœ í†µê³µì‚¬_retry_success_í˜•ì‹ë³€í™˜_20250710.csv\"\n",
    "\n",
    "# CSV íŒŒì¼ ë¶ˆëŸ¬ì˜¤ê¸° (í•œê¸€ í¬í•¨ì´ë¯€ë¡œ cp949 ì¸ì½”ë”©)\n",
    "df_retry_success = pd.read_csv(retry_success_path, encoding='cp949')\n",
    "df_template = pd.read_csv(template_path, encoding='cp949')\n",
    "\n",
    "# \"0\" ê°’ë§Œ ìˆëŠ” í–‰ ì œê±°\n",
    "df_filtered = df_retry_success[df_retry_success[\"0\"] != \"0\"].copy()\n",
    "df_filtered.columns = [\"raw\"]  # ì—´ ì´ë¦„ ì¬ì§€ì •\n",
    "\n",
    "# ë¬¸ìì—´ì„ íŒŒì´ì¬ ë”•ì…”ë„ˆë¦¬ë¡œ ì•ˆì „í•˜ê²Œ ë³€í™˜\n",
    "df_parsed = df_filtered[\"raw\"].apply(ast.literal_eval)\n",
    "df_data = pd.DataFrame(df_parsed.tolist())\n",
    "\n",
    "# ì—´ ìˆœì„œ ë§ì¶”ê¸° (template ê¸°ì¤€)\n",
    "df_data = df_data.reindex(columns=df_template.columns)\n",
    "\n",
    "# ì €ì¥\n",
    "df_data.to_csv(output_path, index=False, encoding='cp949')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "482b0580",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì´ 8ê°œì˜ ì‹ ê·œ íŒŒì¼ì„ ë³‘í•©í•˜ì˜€ê³ , ê²°ê³¼ íŒŒì¼ ì €ì¥ ì™„ë£Œ: ë°°ì¶”/ìœ í†µê³µì‚¬_ë„ë§¤ì‹œì¥_ë°°ì¶”_ë³‘í•©ì¤‘ë³µì œê±°.csv\n"
     ]
    }
   ],
   "source": [
    "# ë³‘í•©í•˜ê¸°\n",
    "\n",
    "import pandas as pd\n",
    "import glob\n",
    "\n",
    "item_nm = 'ë°°ì¶”'\n",
    "\n",
    "# íŒŒì¼ ê²½ë¡œ ì„¤ì •\n",
    "existing_path = f\"{item_nm}/ìœ í†µê³µì‚¬_ë„ë§¤ì‹œì¥_{item_nm}.csv\"\n",
    "new_paths = glob.glob(f\"{item_nm}/ìœ í†µê³µì‚¬_retry_{item_nm}_*.csv\")\n",
    "output_path = f\"{item_nm}/ìœ í†µê³µì‚¬_ë„ë§¤ì‹œì¥_{item_nm}_ë³‘í•©ì¤‘ë³µì œê±°.csv\"\n",
    "\n",
    "# ê¸°ì¡´ íŒŒì¼ ë¡œë“œ\n",
    "df_existing = pd.read_csv(existing_path, encoding='cp949', low_memory=False)\n",
    "\n",
    "# ìƒˆë¡œìš´ íŒŒì¼ë“¤ ì½ì–´ì„œ ë³‘í•©\n",
    "df_new_list = [pd.read_csv(path, encoding='cp949', low_memory=False) for path in new_paths]\n",
    "df_new_combined = pd.concat(df_new_list, ignore_index=True)\n",
    "\n",
    "# ê¸°ì¡´ + ìƒˆë¡œìš´ ë°ì´í„° í•©ì¹˜ê¸°\n",
    "df_merged = pd.concat([df_existing, df_new_combined], ignore_index=True)\n",
    "\n",
    "# ë‚ ì§œ ì»¬ëŸ¼ ì •ì œ ë° ì •ë ¬\n",
    "df_merged[\"trd_clcln_ymd\"] = pd.to_datetime(df_merged[\"trd_clcln_ymd\"])\n",
    "df_merged.sort_values(\"trd_clcln_ymd\", inplace=True)\n",
    "\n",
    "# ì™„ì „ ì¤‘ë³µ ì œê±°\n",
    "df_merged.drop_duplicates(inplace=True)\n",
    "\n",
    "# ì €ì¥\n",
    "df_merged.to_csv(output_path, index=False, encoding='cp949')\n",
    "\n",
    "print(f\"ì´ {len(new_paths)}ê°œì˜ ì‹ ê·œ íŒŒì¼ì„ ë³‘í•©í•˜ì˜€ê³ , ê²°ê³¼ íŒŒì¼ ì €ì¥ ì™„ë£Œ: {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "12c3d58a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 1. íŒŒì¼ ê²½ë¡œ ì„¤ì •\n",
    "input_path = f\"{item_nm}/ìœ í†µê³µì‚¬_ë„ë§¤ì‹œì¥_{item_nm}_ë³‘í•©ì¤‘ë³µì œê±°.csv\"\n",
    "output_path = f\"{item_nm}/ìœ í†µê³µì‚¬_ë„ë§¤ì‹œì¥_{item_nm}_í•œê¸€ì»¬ëŸ¼ëª….csv\"\n",
    "\n",
    "# 2. CSV ì „ì²´ë¥¼ ë¬¸ìì—´ë¡œ ë¶ˆëŸ¬ì˜¤ê¸° (ìµœì´ˆ ê²½ê³  ë°©ì§€)\n",
    "df = pd.read_csv(input_path, encoding='cp949', dtype=str)\n",
    "\n",
    "# 3. í•œê¸€ ì»¬ëŸ¼ëª… ì„¤ì •\n",
    "new_columns = [\n",
    "    'í‰ê· ê°€ê²©(ì›)', 'ë²•ì¸ì½”ë“œ', 'ë²•ì¸ì´ë¦„', 'ìƒí’ˆ ëŒ€ë¶„ë¥˜ ì½”ë“œ', 'ìƒí’ˆ ëŒ€ë¶„ë¥˜ ì´ë¦„',\n",
    "    'ìƒí’ˆ ì¤‘ë¶„ë¥˜ ì½”ë“œ', 'ìƒí’ˆ ì¤‘ë¶„ë¥˜ ì´ë¦„', 'ìƒí’ˆ ì†Œë¶„ë¥˜ ì½”ë“œ', 'ìƒí’ˆ ì†Œë¶„ë¥˜ ì´ë¦„',\n",
    "    'ë“±ê¸‰ì½”ë“œ', 'ë“±ê¸‰ì´ë¦„', 'ìµœê³ ê°€(ì›)', 'ìµœì €ê°€(ì›)', 'í¬ì¥ì½”ë“œ', 'í¬ì¥ì´ë¦„',\n",
    "    'ì‚°ì§€ì½”ë“œ', 'ì‚°ì§€ì´ë¦„', 'í¬ê¸°ì½”ë“œ', 'í¬ê¸°ì´ë¦„', 'ì´ê°€ê²©(ì›)', 'ë‚ ì§œ(YYYY-MM-DD)',\n",
    "    'ë§¤ë§¤êµ¬ë¶„', 'ë‹¨ìœ„ì½”ë“œ', 'ë‹¨ìœ„(kg)', 'ë‹¨ìœ„ë¬¼ëŸ‰(kg)', 'ë‹¨ìœ„ì´ë¬¼ëŸ‰(kg)', 'ë„ë§¤ì‹œì¥ì½”ë“œ', 'ë„ë§¤ì‹œì¥ì´ë¦„'\n",
    "]\n",
    "\n",
    "if len(df.columns) != len(new_columns):\n",
    "    raise ValueError(\"ì»¬ëŸ¼ ìˆ˜ê°€ ì¼ì¹˜í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.\")\n",
    "\n",
    "df.columns = new_columns\n",
    "\n",
    "# 4. ë‚ ì§œ ì»¬ëŸ¼ ë³€í™˜\n",
    "df['ë‚ ì§œ(YYYY-MM-DD)'] = pd.to_datetime(df['ë‚ ì§œ(YYYY-MM-DD)'], errors='coerce')\n",
    "\n",
    "# 5. ìˆ«ì ì»¬ëŸ¼ ë³€í™˜\n",
    "numeric_columns = ['í‰ê· ê°€ê²©(ì›)', 'ìµœê³ ê°€(ì›)', 'ìµœì €ê°€(ì›)', 'ì´ê°€ê²©(ì›)', 'ë‹¨ìœ„ë¬¼ëŸ‰(kg)', 'ë‹¨ìœ„ì´ë¬¼ëŸ‰(kg)']\n",
    "for col in numeric_columns:\n",
    "    df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "\n",
    "# 6. í˜¼í•© íƒ€ì… ê²½ê³  ì»¬ëŸ¼ ì²˜ë¦¬: NaNì„ ë¹ˆ ë¬¸ìì—´ë¡œ, ëª¨ë‘ ë¬¸ìì—´í™”\n",
    "for col in ['í¬ì¥ì´ë¦„', 'ì‚°ì§€ì´ë¦„', 'í¬ê¸°ì´ë¦„']:\n",
    "    df[col] = df[col].fillna('').astype(str)\n",
    "\n",
    "# 7. CSV ì €ì¥ (ì™„ì „ ì •ë¦¬ëœ ìƒíƒœ)\n",
    "df.to_csv(output_path, index=False, encoding='cp949')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0add8419",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_15072\\4122489021.py:8: DtypeWarning: Columns (9,13,17) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(input_path, encoding='cp949')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# íŒŒì¼ ê²½ë¡œ\n",
    "input_path = f\"{item_nm}/ìœ í†µê³µì‚¬_ë„ë§¤ì‹œì¥_{item_nm}_í•œê¸€ì»¬ëŸ¼ëª….csv\"\n",
    "output_path = f\"{item_nm}/ìœ í†µê³µì‚¬_{item_nm}_ìš”ì•½ë°ì´í„°.csv\"\n",
    "\n",
    "# CSV íŒŒì¼ ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "df = pd.read_csv(input_path, encoding='cp949')\n",
    "\n",
    "selected_columns = ['ë‚ ì§œ(YYYY-MM-DD)', 'ìƒí’ˆ ì¤‘ë¶„ë¥˜ ì´ë¦„', 'ë“±ê¸‰ì´ë¦„', 'ì´ê°€ê²©(ì›)', 'ë‹¨ìœ„ì´ë¬¼ëŸ‰(kg)', 'ì‚°ì§€ì½”ë“œ', 'ì‚°ì§€ì´ë¦„']\n",
    "df_selected = df[selected_columns]\n",
    "\n",
    "# ìƒˆ CSVë¡œ ì €ì¥\n",
    "df_selected.to_csv(output_path, index=False, encoding='cp949')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "323131b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ì‚°ì§€ì´ë¦„ ê¸°ë°˜ìœ¼ë¡œ ì‚°ì§€ì½”ë“œ ìˆ˜ì • ì™„ë£Œ: ë°°ì¶”/ìœ í†µê³µì‚¬_ë°°ì¶”_ìš”ì•½ë°ì´í„°_ì‚°ì§€ì´ë¦„ê¸°ë°˜ìˆ˜ì •.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# íŒŒì¼ ê²½ë¡œ\n",
    "base_file = f\"{item_nm}/ìœ í†µê³µì‚¬_{item_nm}_ìš”ì•½ë°ì´í„°.csv\"\n",
    "jigpam_code_file = \"í‘œì¤€ì½”ë“œ/ì‚°ì§€ì½”ë“œ_ì§íŒœ.csv\"\n",
    "\n",
    "# íŒŒì¼ ì½ê¸° (cp949 ì¸ì½”ë”©)\n",
    "df_base = pd.read_csv(base_file, encoding='cp949')\n",
    "df_code = pd.read_csv(jigpam_code_file, encoding='cp949')\n",
    "\n",
    "# 'ì‚°ì§€ì½”ë“œ'ë¥¼ ìˆ«ìí˜•ìœ¼ë¡œ ë³€í™˜\n",
    "df_code['ì‚°ì§€ì½”ë“œ'] = pd.to_numeric(df_code['ì‚°ì§€ì½”ë“œ'], errors='coerce')\n",
    "\n",
    "# 800000 ì´ìƒì¸ í•­ëª©ë§Œ í•„í„°ë§í•˜ì—¬ ë§¤í•‘ ë”•ì…”ë„ˆë¦¬ ìƒì„±\n",
    "code_map = df_code[df_code['ì‚°ì§€ì½”ë“œ'] >= 800000] \\\n",
    "              .set_index('ì‚°ì§€ì´ë¦„')['ì‚°ì§€ì½”ë“œ'].to_dict()\n",
    "\n",
    "# ì•ˆì „í•œ ëŒ€ì²´ í•¨ìˆ˜ ì •ì˜\n",
    "def safe_replace(row):\n",
    "    new_code = code_map.get(row['ì‚°ì§€ì´ë¦„'], None)\n",
    "    if new_code is not None:\n",
    "        return new_code\n",
    "    return row['ì‚°ì§€ì½”ë“œ']  # ë§¤í•‘ ì•ˆë˜ë©´ ê¸°ì¡´ ê°’ ìœ ì§€\n",
    "\n",
    "# ì •ì œ í›„ ë¬¸ìí˜•ìœ¼ë¡œ ì €ì¥\n",
    "df_base['ì‚°ì§€ì½”ë“œ'] = df_base.apply(safe_replace, axis=1)\n",
    "\n",
    "# ê²°ê³¼ ì €ì¥\n",
    "output_path = f\"{item_nm}/ìœ í†µê³µì‚¬_{item_nm}_ìš”ì•½ë°ì´í„°_ì‚°ì§€ì´ë¦„ê¸°ë°˜ìˆ˜ì •.csv\"\n",
    "df_base.to_csv(output_path, index=False, encoding='cp949')\n",
    "\n",
    "print(f\"âœ… ì‚°ì§€ì´ë¦„ ê¸°ë°˜ìœ¼ë¡œ ì‚°ì§€ì½”ë“œ ìˆ˜ì • ì™„ë£Œ: {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d757a981",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_15072\\807280020.py:5: DtypeWarning: Columns (5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(f\"{item_nm}/ìœ í†µê³µì‚¬_{item_nm}_ìš”ì•½ë°ì´í„°_ì‚°ì§€ì´ë¦„ê¸°ë°˜ìˆ˜ì •.csv\", encoding = 'cp949')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì •ì œëœ ë°ì´í„°ê°€ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤: ë°°ì¶”/ìœ í†µê³µì‚¬_ë°°ì¶”_ìš”ì•½ë°ì´í„°_ì •ì œ.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# CSV íŒŒì¼ ë¡œë“œ\n",
    "df = pd.read_csv(f\"{item_nm}/ìœ í†µê³µì‚¬_{item_nm}_ìš”ì•½ë°ì´í„°_ì‚°ì§€ì´ë¦„ê¸°ë°˜ìˆ˜ì •.csv\", encoding = 'cp949')\n",
    "\n",
    "df['ìƒí’ˆ ì¤‘ë¶„ë¥˜ ì´ë¦„'] = df['ìƒí’ˆ ì¤‘ë¶„ë¥˜ ì´ë¦„'].replace('', pd.NA).fillna(f'{item_nm}')\n",
    "\n",
    "# ì‚°ì§€ì½”ë“œ ì •ì œ í•¨ìˆ˜\n",
    "def clean_origin_code_backpad(code):\n",
    "    code_str = str(code)\n",
    "    digits = re.sub(r'\\D', '', code_str)  # ìˆ«ìë§Œ ë‚¨ê¹€\n",
    "    if not digits:\n",
    "        return None  # ìˆ«ìê°€ í•˜ë‚˜ë„ ì—†ìœ¼ë©´ None\n",
    "    return digits[:6].ljust(6, '0')  # 6ìë¦¬ê¹Œì§€ ìë¥´ê³  ë¶€ì¡±í•˜ë©´ ë’¤ì— 0ìœ¼ë¡œ ì±„ì›€\n",
    "\n",
    "# ì •ì œ ì ìš©\n",
    "df['ì‚°ì§€ì½”ë“œ'] = df['ì‚°ì§€ì½”ë“œ'].apply(clean_origin_code)\n",
    "\n",
    "# ì €ì¥\n",
    "output_path = f\"{item_nm}/ìœ í†µê³µì‚¬_{item_nm}_ìš”ì•½ë°ì´í„°_ì •ì œ.csv\"\n",
    "df.to_csv(output_path, index=False, encoding = 'cp949')\n",
    "\n",
    "print(f\"ì •ì œëœ ë°ì´í„°ê°€ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤: {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "76c211d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ë‚ ì§œ(YYYY-MM-DD)        0\n",
       "ìƒí’ˆ ì¤‘ë¶„ë¥˜ ì´ë¦„             0\n",
       "ë“±ê¸‰ì´ë¦„                  0\n",
       "ì´ê°€ê²©(ì›)                0\n",
       "ë‹¨ìœ„ì´ë¬¼ëŸ‰(kg)             0\n",
       "ì‚°ì§€ì½”ë“œ                  0\n",
       "ì‚°ì§€ì´ë¦„              26134\n",
       "dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(f\"{item_nm}/ìœ í†µê³µì‚¬_{item_nm}_ìš”ì•½ë°ì´í„°_ì •ì œ.csv\", encoding = 'cp949')\n",
    "\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "92382234",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 1. íŒŒì¼ ê²½ë¡œ ì„¤ì •\n",
    "summary_path = f\"{item_nm}/ìœ í†µê³µì‚¬_{item_nm}_ìš”ì•½ë°ì´í„°_ì •ì œ.csv\"\n",
    "region_code_path = \"í‘œì¤€ì½”ë“œ/ì‚°ì§€ì½”ë“œ_ì§íŒœ.csv\"\n",
    "\n",
    "# 2. CSV ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "summary_df = pd.read_csv(summary_path, encoding='cp949')\n",
    "region_df = pd.read_csv(region_code_path, encoding='cp949')\n",
    "\n",
    "# 3. ì‚°ì§€ì½”ë“œ ë²”ìœ„ íŒŒì‹± í•¨ìˆ˜\n",
    "def parse_code_range(code_str):\n",
    "    if \"~\" in code_str:\n",
    "        start, end = code_str.split(\"~\")\n",
    "    else:\n",
    "        start = end = code_str\n",
    "    return int(start), int(end)\n",
    "\n",
    "# 4. ì‚°ì§€ì½”ë“œ ë²”ìœ„ ìˆ«ì ì»¬ëŸ¼ ìƒì„±\n",
    "region_df[['start_code', 'end_code']] = region_df['ì‚°ì§€ì½”ë“œ'].apply(\n",
    "    lambda x: pd.Series(parse_code_range(x))\n",
    ")\n",
    "\n",
    "# 5. ì‚°ì§€ì½”ë“œ â†’ ì§íŒœì‚°ì§€ì½”ë“œ/ì´ë¦„ ë§¤í•‘ í…Œì´ë¸” í™•ì¥\n",
    "expanded_rows = []\n",
    "for _, row in region_df.iterrows():\n",
    "    for code in range(row['start_code'], row['end_code'] + 1):\n",
    "        expanded_rows.append({\n",
    "            'ì‚°ì§€ì½”ë“œ': code,\n",
    "            'ì§íŒœì‚°ì§€ì½”ë“œ': row['ì§íŒœì‚°ì§€ì½”ë“œ'],\n",
    "            'ì§íŒœì‚°ì§€ì´ë¦„': row['ì§íŒœì‚°ì§€ì´ë¦„']\n",
    "        })\n",
    "expanded_map_df = pd.DataFrame(expanded_rows)\n",
    "\n",
    "# 6. ìš”ì•½ ë°ì´í„° ì‚°ì§€ì½”ë“œ ì •ìˆ˜í˜•ìœ¼ë¡œ ë³€í™˜\n",
    "summary_df['ì‚°ì§€ì½”ë“œ'] = pd.to_numeric(summary_df['ì‚°ì§€ì½”ë“œ'], errors='coerce').astype('Int64')\n",
    "summary_df = summary_df[summary_df['ì‚°ì§€ì½”ë“œ'].notna()].copy()\n",
    "summary_df['ì‚°ì§€ì½”ë“œ'] = summary_df['ì‚°ì§€ì½”ë“œ'].astype(int)\n",
    "\n",
    "# 7. ì§íŒœ ì»¬ëŸ¼ ì œê±° í›„ ë³‘í•©\n",
    "summary_df = summary_df.drop(columns=['ì§íŒœì‚°ì§€ì½”ë“œ', 'ì§íŒœì‚°ì§€ì´ë¦„'], errors='ignore')\n",
    "summary_df = pd.merge(summary_df, expanded_map_df, on='ì‚°ì§€ì½”ë“œ', how='left')\n",
    "\n",
    "# 8. ì‚°ì§€ì´ë¦„ì´ ëˆ„ë½ëœ ê²½ìš° ì§íŒœì‚°ì§€ì´ë¦„ìœ¼ë¡œ ë³´ì™„\n",
    "summary_df['ì‚°ì§€ì´ë¦„'] = summary_df['ì‚°ì§€ì´ë¦„'].fillna(summary_df['ì§íŒœì‚°ì§€ì´ë¦„'])\n",
    "\n",
    "\n",
    "# 9. ê²°ê³¼ ì €ì¥\n",
    "summary_df.to_csv(f\"{item_nm}/{item_nm}ìš”ì•½ë°ì´í„°_ì§íŒœì‚°ì§€ì •ë¦¬.csv\", index=False, encoding='cp949')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e5467f89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ë‚ ì§œ(YYYY-MM-DD)      0\n",
       "ìƒí’ˆ ì¤‘ë¶„ë¥˜ ì´ë¦„           0\n",
       "ë“±ê¸‰ì´ë¦„                0\n",
       "ì´ê°€ê²©(ì›)              0\n",
       "ë‹¨ìœ„ì´ë¬¼ëŸ‰(kg)           0\n",
       "ì‚°ì§€ì½”ë“œ                0\n",
       "ì‚°ì§€ì´ë¦„              957\n",
       "ì§íŒœì‚°ì§€ì½”ë“œ            957\n",
       "ì§íŒœì‚°ì§€ì´ë¦„            957\n",
       "dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(f\"{item_nm}/{item_nm}ìš”ì•½ë°ì´í„°_ì§íŒœì‚°ì§€ì •ë¦¬.csv\", encoding = 'cp949')\n",
    "\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "827857ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ë“±ê¸‰ì´ë¦„ ìˆ˜ì • ì™„ë£Œ: ë°°ì¶”/ë°°ì¶”ìš”ì•½ë°ì´í„°_ì§íŒœì •ë¦¬.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# CSV íŒŒì¼ ë¡œë“œ\n",
    "df = pd.read_csv(f\"{item_nm}/{item_nm}ìš”ì•½ë°ì´í„°_ì§íŒœì‚°ì§€ì •ë¦¬.csv\", encoding='cp949')\n",
    "\n",
    "# ë“±ê¸‰ì´ë¦„ì´ '.'ì¸ ê²½ìš° 'ë³´í†µ'ìœ¼ë¡œ ëŒ€ì²´\n",
    "df['ë“±ê¸‰ì´ë¦„'] = df['ë“±ê¸‰ì´ë¦„'].replace('.', 'ë³´í†µ')\n",
    "\n",
    "# ì €ì¥\n",
    "output_path = f\"{item_nm}/{item_nm}ìš”ì•½ë°ì´í„°_ì§íŒœì •ë¦¬.csv\"\n",
    "df.to_csv(output_path, index=False, encoding='cp949')\n",
    "\n",
    "print(f\"ë“±ê¸‰ì´ë¦„ ìˆ˜ì • ì™„ë£Œ: {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5ca61450",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ì™„ë£Œ] ëˆ„ë½ëœ ë‚ ì§œ 694ê±´ â†’ ëˆ„ë½ë‚ ì§œ_ë°°ì¶”.csv ì €ì¥ë¨\n"
     ]
    }
   ],
   "source": [
    "# ëˆ„ë½ ë‚ ì§œ í™•ì¸\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# 1. ë‚ ì§œ ë²”ìœ„ ìƒì„±\n",
    "full_dates = pd.date_range(start=\"2018-01-03\", end=\"2025-05-31\")\n",
    "\n",
    "# 2. CSV íŒŒì¼ì—ì„œ ë‚ ì§œ ì»¬ëŸ¼ ì½ê¸°\n",
    "df = pd.read_csv(f\"{item_nm}/{item_nm}ìš”ì•½ë°ì´í„°_ì§íŒœì •ë¦¬.csv\", encoding='cp949')\n",
    "\n",
    "\n",
    "# 3. ë‚ ì§œ ì»¬ëŸ¼ íŒŒì‹± (ì˜ˆ: ì»¬ëŸ¼ëª…ì´ 'ë‚ ì§œ'ì¼ ê²½ìš°)\n",
    "df['ë‚ ì§œ(YYYY-MM-DD)'] = pd.to_datetime(df['ë‚ ì§œ(YYYY-MM-DD)'])\n",
    "\n",
    "# 4. ì¡´ì¬í•˜ëŠ” ë‚ ì§œ ëª©ë¡\n",
    "existing_dates = pd.Series(df['ë‚ ì§œ(YYYY-MM-DD)'].unique())\n",
    "\n",
    "# 5. ëˆ„ë½ ë‚ ì§œ ê³„ì‚°\n",
    "missing_dates = full_dates[~full_dates.isin(existing_dates)]\n",
    "\n",
    "# 6. ê²°ê³¼ DataFrame (ì»¬ëŸ¼ëª… ì§€ì •)\n",
    "missing_df = pd.DataFrame({'ë‚ ì§œ(YYYY-MM-DD)': missing_dates.strftime(\"%Y-%m-%d\")})\n",
    "\n",
    "# 7. CSV ì €ì¥ (cp949 ì¸ì½”ë”©)\n",
    "missing_df.to_csv(f\"{item_nm}/ëˆ„ë½ë‚ ì§œ_{item_nm}.csv\", index=False, encoding=\"cp949\")\n",
    "\n",
    "print(f\"[ì™„ë£Œ] ëˆ„ë½ëœ ë‚ ì§œ {len(missing_df)}ê±´ â†’ ëˆ„ë½ë‚ ì§œ_{item_nm}.csv ì €ì¥ë¨\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c96b523e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“¦ ì‹¤íŒ¨ í•­ëª© ì¬ì‹œë„ ì‹œì‘: ë°°ì¶”\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "ì¬ì‹œë„ ë‚ ì§œ ì§„í–‰:   0%|                                                                        | 0/694 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "â–¶ï¸ ìš”ì²­ ì‹œë„: ë°°ì¶” | ì‹œì¥ì½”ë“œ: ë„ë§¤ì‹œì¥ì½”ë“œ | ë‚ ì§œ: 2018-01-07 | í˜ì´ì§€: 1 | ì¬ì‹œë„: 1\n",
      "âš ï¸ ê±°ë˜ ë°ì´í„° ì—†ìŒ\n",
      "â–¶ï¸ ìš”ì²­ ì‹œë„: ë°°ì¶” | ì‹œì¥ì½”ë“œ: 110008 | ë‚ ì§œ: 2018-01-07 | í˜ì´ì§€: 1 | ì¬ì‹œë„: 1\n",
      "âš ï¸ ê±°ë˜ ë°ì´í„° ì—†ìŒ\n",
      "â–¶ï¸ ìš”ì²­ ì‹œë„: ë°°ì¶” | ì‹œì¥ì½”ë“œ: 210001 | ë‚ ì§œ: 2018-01-07 | í˜ì´ì§€: 1 | ì¬ì‹œë„: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "ì¬ì‹œë„ ë‚ ì§œ ì§„í–‰:   0%|                                                                        | 0/694 [00:03<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ ê±°ë˜ ë°ì´í„° ì—†ìŒ\n",
      "â–¶ï¸ ìš”ì²­ ì‹œë„: ë°°ì¶” | ì‹œì¥ì½”ë“œ: 210005 | ë‚ ì§œ: 2018-01-07 | í˜ì´ì§€: 1 | ì¬ì‹œë„: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[24], line 71\u001b[0m\n\u001b[0;32m     59\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mâ–¶ï¸ ìš”ì²­ ì‹œë„: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mitem_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m | ì‹œì¥ì½”ë“œ: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmcode\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m | ë‚ ì§œ: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdate_str\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m | í˜ì´ì§€: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpage_no\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m | ì¬ì‹œë„: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mretry_count\u001b[38;5;250m \u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     61\u001b[0m params \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m     62\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mserviceKey\u001b[39m\u001b[38;5;124m'\u001b[39m: API_KEY,\n\u001b[0;32m     63\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpageNo\u001b[39m\u001b[38;5;124m'\u001b[39m: page_no,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcond[gds_mclsf_cd::EQ]\u001b[39m\u001b[38;5;124m'\u001b[39m: MID\n\u001b[0;32m     69\u001b[0m }\n\u001b[1;32m---> 71\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mrequests\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mBASE_URL\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverify\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     72\u001b[0m content_type \u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39mheaders\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mContent-Type\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     73\u001b[0m time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m1.0\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\ml-dl-nlp\\lib\\site-packages\\requests\\api.py:73\u001b[0m, in \u001b[0;36mget\u001b[1;34m(url, params, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mget\u001b[39m(url, params\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m     63\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Sends a GET request.\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \n\u001b[0;32m     65\u001b[0m \u001b[38;5;124;03m    :param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     70\u001b[0m \u001b[38;5;124;03m    :rtype: requests.Response\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 73\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m request(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mget\u001b[39m\u001b[38;5;124m\"\u001b[39m, url, params\u001b[38;5;241m=\u001b[39mparams, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\ml-dl-nlp\\lib\\site-packages\\requests\\api.py:59\u001b[0m, in \u001b[0;36mrequest\u001b[1;34m(method, url, **kwargs)\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;66;03m# By using the 'with' statement we are sure the session is closed, thus we\u001b[39;00m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;66;03m# avoid leaving sockets open which can trigger a ResourceWarning in some\u001b[39;00m\n\u001b[0;32m     57\u001b[0m \u001b[38;5;66;03m# cases, and look like a memory leak in others.\u001b[39;00m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m sessions\u001b[38;5;241m.\u001b[39mSession() \u001b[38;5;28;01mas\u001b[39;00m session:\n\u001b[1;32m---> 59\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m session\u001b[38;5;241m.\u001b[39mrequest(method\u001b[38;5;241m=\u001b[39mmethod, url\u001b[38;5;241m=\u001b[39murl, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\ml-dl-nlp\\lib\\site-packages\\requests\\sessions.py:589\u001b[0m, in \u001b[0;36mSession.request\u001b[1;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[0;32m    584\u001b[0m send_kwargs \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    585\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m\"\u001b[39m: timeout,\n\u001b[0;32m    586\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow_redirects\u001b[39m\u001b[38;5;124m\"\u001b[39m: allow_redirects,\n\u001b[0;32m    587\u001b[0m }\n\u001b[0;32m    588\u001b[0m send_kwargs\u001b[38;5;241m.\u001b[39mupdate(settings)\n\u001b[1;32m--> 589\u001b[0m resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msend(prep, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39msend_kwargs)\n\u001b[0;32m    591\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\ml-dl-nlp\\lib\\site-packages\\requests\\sessions.py:703\u001b[0m, in \u001b[0;36mSession.send\u001b[1;34m(self, request, **kwargs)\u001b[0m\n\u001b[0;32m    700\u001b[0m start \u001b[38;5;241m=\u001b[39m preferred_clock()\n\u001b[0;32m    702\u001b[0m \u001b[38;5;66;03m# Send the request\u001b[39;00m\n\u001b[1;32m--> 703\u001b[0m r \u001b[38;5;241m=\u001b[39m adapter\u001b[38;5;241m.\u001b[39msend(request, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    705\u001b[0m \u001b[38;5;66;03m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[0;32m    706\u001b[0m elapsed \u001b[38;5;241m=\u001b[39m preferred_clock() \u001b[38;5;241m-\u001b[39m start\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\ml-dl-nlp\\lib\\site-packages\\requests\\adapters.py:667\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[1;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[0;32m    664\u001b[0m     timeout \u001b[38;5;241m=\u001b[39m TimeoutSauce(connect\u001b[38;5;241m=\u001b[39mtimeout, read\u001b[38;5;241m=\u001b[39mtimeout)\n\u001b[0;32m    666\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 667\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    668\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    669\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    670\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    671\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    672\u001b[0m \u001b[43m        \u001b[49m\u001b[43mredirect\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    673\u001b[0m \u001b[43m        \u001b[49m\u001b[43massert_same_host\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    674\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    675\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    676\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    677\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    678\u001b[0m \u001b[43m        \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    679\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    681\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (ProtocolError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m    682\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(err, request\u001b[38;5;241m=\u001b[39mrequest)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\ml-dl-nlp\\lib\\site-packages\\urllib3\\connectionpool.py:793\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[0;32m    790\u001b[0m response_conn \u001b[38;5;241m=\u001b[39m conn \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m release_conn \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    792\u001b[0m \u001b[38;5;66;03m# Make the request on the HTTPConnection object\u001b[39;00m\n\u001b[1;32m--> 793\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_request(\n\u001b[0;32m    794\u001b[0m     conn,\n\u001b[0;32m    795\u001b[0m     method,\n\u001b[0;32m    796\u001b[0m     url,\n\u001b[0;32m    797\u001b[0m     timeout\u001b[38;5;241m=\u001b[39mtimeout_obj,\n\u001b[0;32m    798\u001b[0m     body\u001b[38;5;241m=\u001b[39mbody,\n\u001b[0;32m    799\u001b[0m     headers\u001b[38;5;241m=\u001b[39mheaders,\n\u001b[0;32m    800\u001b[0m     chunked\u001b[38;5;241m=\u001b[39mchunked,\n\u001b[0;32m    801\u001b[0m     retries\u001b[38;5;241m=\u001b[39mretries,\n\u001b[0;32m    802\u001b[0m     response_conn\u001b[38;5;241m=\u001b[39mresponse_conn,\n\u001b[0;32m    803\u001b[0m     preload_content\u001b[38;5;241m=\u001b[39mpreload_content,\n\u001b[0;32m    804\u001b[0m     decode_content\u001b[38;5;241m=\u001b[39mdecode_content,\n\u001b[0;32m    805\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mresponse_kw,\n\u001b[0;32m    806\u001b[0m )\n\u001b[0;32m    808\u001b[0m \u001b[38;5;66;03m# Everything went great!\u001b[39;00m\n\u001b[0;32m    809\u001b[0m clean_exit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\ml-dl-nlp\\lib\\site-packages\\urllib3\\connectionpool.py:537\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[1;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[0;32m    535\u001b[0m \u001b[38;5;66;03m# Receive the response from the server\u001b[39;00m\n\u001b[0;32m    536\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 537\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    538\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (BaseSSLError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    539\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_raise_timeout(err\u001b[38;5;241m=\u001b[39me, url\u001b[38;5;241m=\u001b[39murl, timeout_value\u001b[38;5;241m=\u001b[39mread_timeout)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\ml-dl-nlp\\lib\\site-packages\\urllib3\\connection.py:466\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    463\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mresponse\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m HTTPResponse\n\u001b[0;32m    465\u001b[0m \u001b[38;5;66;03m# Get the response from http.client.HTTPConnection\u001b[39;00m\n\u001b[1;32m--> 466\u001b[0m httplib_response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    468\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    469\u001b[0m     assert_header_parsing(httplib_response\u001b[38;5;241m.\u001b[39mmsg)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\ml-dl-nlp\\lib\\http\\client.py:1375\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1373\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1374\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1375\u001b[0m         \u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbegin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1376\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m:\n\u001b[0;32m   1377\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\ml-dl-nlp\\lib\\http\\client.py:318\u001b[0m, in \u001b[0;36mHTTPResponse.begin\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    316\u001b[0m \u001b[38;5;66;03m# read until we get a non-100 response\u001b[39;00m\n\u001b[0;32m    317\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m--> 318\u001b[0m     version, status, reason \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_read_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    319\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m status \u001b[38;5;241m!=\u001b[39m CONTINUE:\n\u001b[0;32m    320\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\ml-dl-nlp\\lib\\http\\client.py:279\u001b[0m, in \u001b[0;36mHTTPResponse._read_status\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    278\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_read_status\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m--> 279\u001b[0m     line \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreadline\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_MAXLINE\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miso-8859-1\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    280\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(line) \u001b[38;5;241m>\u001b[39m _MAXLINE:\n\u001b[0;32m    281\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m LineTooLong(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstatus line\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\ml-dl-nlp\\lib\\socket.py:717\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[1;34m(self, b)\u001b[0m\n\u001b[0;32m    715\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m    716\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 717\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    718\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[0;32m    719\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout_occurred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# ì‹¤íŒ¨ ë¡œê·¸ ê¸°ë°˜ ë°ì´í„° ì¬ìˆ˜ì§‘\n",
    "import os\n",
    "import pandas as pd\n",
    "import requests\n",
    "import time\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm\n",
    "import ssl\n",
    "import warnings\n",
    "import xml.etree.ElementTree as ET\n",
    "from requests.packages.urllib3.exceptions import InsecureRequestWarning\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# í™˜ê²½ ë° ê²½ê³  ì„¤ì •\n",
    "load_dotenv()\n",
    "warnings.filterwarnings('ignore', category=InsecureRequestWarning)\n",
    "ssl._create_default_https_context = ssl._create_unverified_context\n",
    "\n",
    "# ìƒìˆ˜\n",
    "API_KEY = os.getenv(\"DO_API_KEY\")\n",
    "BASE_URL = 'http://apis.data.go.kr/B552845/katSale/trades'\n",
    "item_nm = 'ë°°ì¶”'\n",
    "ITEM_CODES = {f\"{item_nm}\": \"1001\"}\n",
    "max_retries = 2  # ì¬ì‹œë„ ìµœëŒ€ íšŸìˆ˜ (1íšŒ ì‹œë„ + 0íšŒ ì¬ì‹œë„)\n",
    "\n",
    "# ë””ë ‰í† ë¦¬ ì¤€ë¹„\n",
    "os.makedirs(\"logs\", exist_ok=True)\n",
    "os.makedirs(\"data\", exist_ok=True)\n",
    "os.makedirs(\"success\", exist_ok=True)\n",
    "\n",
    "# ë„ë§¤ì‹œì¥ ì½”ë“œ ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "df_market = pd.read_csv(\"í‘œì¤€ì½”ë“œ/ë„ë§¤ì‹œì¥_ì½”ë“œ.csv\", encoding=\"cp949\", header=None)\n",
    "df_market[0] = df_market[0].astype(str)\n",
    "\n",
    "# ì‹¤íŒ¨ ë¡œê·¸ ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "fail_df = pd.read_csv(f\"{item_nm}/ëˆ„ë½ë‚ ì§œ_{item_nm}.csv\", encoding=\"cp949\")\n",
    "fail_dates = pd.to_datetime(fail_df['ë‚ ì§œ(YYYY-MM-DD)']).dt.strftime(\"%Y-%m-%d\")\n",
    "\n",
    "# ë„ë§¤ì‹œì¥ ë¦¬ìŠ¤íŠ¸\n",
    "market_list = df_market[[0, 1]].values.tolist()  # (ì‹œì¥ì½”ë“œ, ì‹œì¥ëª…)\n",
    "\n",
    "for item_name, code in ITEM_CODES.items():\n",
    "    LARGE = code[:2]\n",
    "    MID = code[2:]\n",
    "    data_list = []\n",
    "    cnt =0\n",
    "\n",
    "    print(f\"\\nğŸ“¦ ì‹¤íŒ¨ í•­ëª© ì¬ì‹œë„ ì‹œì‘: {item_name}\")\n",
    "    for date_str in tqdm(fail_dates, desc=\"ì¬ì‹œë„ ë‚ ì§œ ì§„í–‰\"):\n",
    "        for mcode, market_name in market_list:\n",
    "            retry_count = 0\n",
    "            market_success = False\n",
    "\n",
    "            while retry_count < max_retries:\n",
    "                page_no = 1\n",
    "                cnt += 1\n",
    "                try:\n",
    "                    while True:\n",
    "                        print(f\"â–¶ï¸ ìš”ì²­ ì‹œë„: {item_name} | ì‹œì¥ì½”ë“œ: {mcode} | ë‚ ì§œ: {date_str} | í˜ì´ì§€: {page_no} | ì¬ì‹œë„: {retry_count + 1}\")\n",
    "\n",
    "                        params = {\n",
    "                            'serviceKey': API_KEY,\n",
    "                            'pageNo': page_no,\n",
    "                            'numOfRows': 100,\n",
    "                            'cond[trd_clcln_ymd::EQ]': date_str,\n",
    "                            'cond[whsl_mrkt_cd::EQ]': mcode,\n",
    "                            'cond[gds_lclsf_cd::EQ]': LARGE,\n",
    "                            'cond[gds_mclsf_cd::EQ]': MID\n",
    "                        }\n",
    "\n",
    "                        response = requests.get(BASE_URL, params=params, verify=False, timeout=10)\n",
    "                        content_type = response.headers.get(\"Content-Type\", \"\")\n",
    "                        time.sleep(1.0)\n",
    "                        response_preview = response.text[:500].strip()\n",
    "\n",
    "                        # ì˜¤ë¥˜ ì²´í¬\n",
    "                        if \"LIMITED_\" in response_preview:\n",
    "                            fail_reason = \"âŒ API í˜¸ì¶œ ì œí•œ (LIMITED_ ì‘ë‹µ)\"\n",
    "                        elif \"SERVICE ERROR\" in response_preview:\n",
    "                            fail_reason = \"âŒ ì„œë¹„ìŠ¤ ì˜¤ë¥˜ (SERVICE ERROR ì‘ë‹µ)\"\n",
    "                        elif \"ERROR\" in response_preview.upper():\n",
    "                            fail_reason = \"âŒ ê¸°íƒ€ ì˜¤ë¥˜ í¬í•¨ (ERROR í‚¤ì›Œë“œ í¬í•¨)\"\n",
    "                        elif \"TOO MANY REQUESTS\" in response_preview.upper():\n",
    "                            fail_reason = \"âŒ ìš”ì²­ ê³¼ë‹¤ë¡œ ì¸í•œ ì œí•œ (Too Many Requests)\"\n",
    "                        else:\n",
    "                            fail_reason = None\n",
    "\n",
    "                        if fail_reason:\n",
    "                            print(f\"â›” {fail_reason} - ì¬ì‹œë„ ëŒ€ê¸° ì¤‘ (2ë¶„)\")\n",
    "                            log_prefix = f\"logs/retry_failed_{item_name}_{mcode}_{date_str}\"\n",
    "                            with open(f\"{log_prefix}.html\", \"w\", encoding=\"utf-8\") as f:\n",
    "                                f.write(response.text)\n",
    "                            with open(f\"{log_prefix}_info.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "                                f.write(f\"[ì˜¤ë¥˜] {fail_reason}\\n{response_preview}\")\n",
    "                            retry_count += 1\n",
    "                            if retry_count >= max_retries:\n",
    "                                print(f\"â— ìµœëŒ€ ì¬ì‹œë„ {max_retries}íšŒ ì´ˆê³¼ - ì¤‘ë‹¨\")\n",
    "                                break\n",
    "                            time.sleep(60)\n",
    "                            continue\n",
    "\n",
    "                        # ì‘ë‹µ íŒŒì‹±\n",
    "                        if \"application/json\" in content_type:\n",
    "                            json_data = response.json()\n",
    "                            body = json_data.get(\"response\", {}).get(\"body\", {})\n",
    "                            items = body.get(\"items\", {}).get(\"item\", [])\n",
    "                            total_count = int(body.get(\"totalCount\", 0))\n",
    "\n",
    "                        elif \"application/xml\" in content_type or response.text.strip().startswith(\"<\"):\n",
    "                            root = ET.fromstring(response.text)\n",
    "                            total_count_el = root.find(\".//totalCount\")\n",
    "                            total_count = int(total_count_el.text) if total_count_el is not None else 0\n",
    "                            item_els = root.findall(\".//item\")\n",
    "                            items = [{el.tag: el.text for el in item} for item in item_els]\n",
    "                        else:\n",
    "                            raise ValueError(f\"ì•Œ ìˆ˜ ì—†ëŠ” ì‘ë‹µ í˜•ì‹: {content_type}\")\n",
    "\n",
    "                        if not items:\n",
    "                            print(\"âš ï¸ ê±°ë˜ ë°ì´í„° ì—†ìŒ\")\n",
    "                            market_success = True\n",
    "                            break\n",
    "\n",
    "                        data_list.extend(items)\n",
    "\n",
    "                        if cnt % 10000 == 0:\n",
    "                            print(f\"ğŸ§ª ì¤‘ê°„ ì €ì¥ ì‹œë„: í˜„ì¬ data_list ê¸¸ì´ = {len(data_list)}\")\n",
    "                            mid_save_path = f\"{item_nm}/ìœ í†µê³µì‚¬_retry_{item_name}_{datetime.now().strftime('%Y%m%d_%H%M%S')}_mid.csv\"\n",
    "                            pd.DataFrame(data_list).to_csv(mid_save_path, encoding='cp949', index=False)\n",
    "                            print(f\"ğŸ’¾ ì¤‘ê°„ ì €ì¥ ì™„ë£Œ: {mid_save_path}\")\n",
    "\n",
    "                        market_success = True\n",
    "                        if page_no * 100 >= total_count:\n",
    "                            print(f\"âœ… ë§ˆì§€ë§‰ í˜ì´ì§€ ë„ë‹¬ (totalCount: {total_count})\")\n",
    "                            break\n",
    "                        if page_no > 10:\n",
    "                            print(\"ğŸš¨ í˜ì´ì§€ 10 ì´ˆê³¼ - ë¬´í•œ ë£¨í”„ ë°©ì§€ë¥¼ ìœ„í•´ ì¤‘ë‹¨\")\n",
    "                            break\n",
    "\n",
    "                        page_no += 1\n",
    "                        time.sleep(1.0)\n",
    "\n",
    "                    if market_success:\n",
    "                        break\n",
    "                    else:\n",
    "                        retry_count += 1\n",
    "                        time.sleep(2 * retry_count)\n",
    "\n",
    "                except Exception as e:\n",
    "                    retry_count += 1\n",
    "                    print(f\"â—ì˜ˆì™¸ ë°œìƒ: {e} (ì¬ì‹œë„ {retry_count}/{max_retries})\")\n",
    "                    fail_log_prefix = f\"logs/retry_failed_{item_name}_{mcode}_{date_str}_try{retry_count}\"\n",
    "                    if 'response' in locals():\n",
    "                        with open(f\"{fail_log_prefix}.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "                            f.write(response.text)\n",
    "                    with open(f\"{fail_log_prefix}_info.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "                        f.write(f\"[ì˜ˆì™¸] {str(e)}\\n\")\n",
    "                    if retry_count >= max_retries:\n",
    "                        break\n",
    "                    time.sleep(2 * retry_count)\n",
    "\n",
    "            if not market_success:\n",
    "                fail_log_path = f\"logs/retry_failed_{item_name}_{mcode}_{date_str}.txt\"\n",
    "                with open(fail_log_path, \"w\", encoding=\"utf-8\") as f:\n",
    "                    f.write(f\"âŒ {datetime.now()} - {item_name} {mcode} {date_str} ë°ì´í„° ìˆ˜ì§‘ ì‹¤íŒ¨\\n\")\n",
    "\n",
    "    # ì €ì¥\n",
    "    if data_list:\n",
    "        df = pd.DataFrame(data_list)\n",
    "        filename = f\"{item_nm}/ìœ í†µê³µì‚¬_retry_{item_name}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv\"\n",
    "        df.to_csv(filename, encoding='cp949', index=False)\n",
    "        print(f\"âœ… ì €ì¥ ì™„ë£Œ: {filename}\")\n",
    "    else:\n",
    "        print(f\"âš ï¸ {item_name}: ì¬ì‹œë„ì—ì„œë„ ë°ì´í„° ì—†ìŒ\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fd7068c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-dl-nlp",
   "language": "python",
   "name": "ml-dl-nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
