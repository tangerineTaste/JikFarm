{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5a1cdcaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "item_nm = '배추'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5a849626",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_2520\\3349438536.py:10: DtypeWarning: Columns (13) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_retry_success = pd.read_csv(retry_success_path, encoding='cp949')\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_2520\\3349438536.py:11: DtypeWarning: Columns (17) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_template = pd.read_csv(template_path, encoding='cp949')\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'0'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32m~\\anaconda3\\envs\\ml-dl-nlp\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3802\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3801\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3802\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3803\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\ml-dl-nlp\\lib\\site-packages\\pandas\\_libs\\index.pyx:138\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\ml-dl-nlp\\lib\\site-packages\\pandas\\_libs\\index.pyx:165\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:5745\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:5753\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: '0'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 14\u001b[0m\n\u001b[0;32m     11\u001b[0m df_template \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(template_path, encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcp949\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# \"0\" 값만 있는 행 제거\u001b[39;00m\n\u001b[1;32m---> 14\u001b[0m df_filtered \u001b[38;5;241m=\u001b[39m df_retry_success[\u001b[43mdf_retry_success\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m0\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m0\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[0;32m     15\u001b[0m df_filtered\u001b[38;5;241m.\u001b[39mcolumns \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraw\u001b[39m\u001b[38;5;124m\"\u001b[39m]  \u001b[38;5;66;03m# 열 이름 재지정\u001b[39;00m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m# 문자열을 파이썬 딕셔너리로 안전하게 변환\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\ml-dl-nlp\\lib\\site-packages\\pandas\\core\\frame.py:3807\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3805\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   3806\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 3807\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3808\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   3809\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\ml-dl-nlp\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3804\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3802\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3803\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m-> 3804\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3805\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3806\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3807\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3808\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3809\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: '0'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import ast\n",
    "\n",
    "# 파일 경로\n",
    "retry_success_path = \"유통공사_retry_success_20250710_083318.csv\"\n",
    "template_path = \"유통공사_도매시장_배추.csv\"\n",
    "output_path = \"유통공사_retry_success_형식변환_20250710.csv\"\n",
    "\n",
    "# CSV 파일 불러오기 (한글 포함이므로 cp949 인코딩)\n",
    "df_retry_success = pd.read_csv(retry_success_path, encoding='cp949')\n",
    "df_template = pd.read_csv(template_path, encoding='cp949')\n",
    "\n",
    "# \"0\" 값만 있는 행 제거\n",
    "df_filtered = df_retry_success[df_retry_success[\"0\"] != \"0\"].copy()\n",
    "df_filtered.columns = [\"raw\"]  # 열 이름 재지정\n",
    "\n",
    "# 문자열을 파이썬 딕셔너리로 안전하게 변환\n",
    "df_parsed = df_filtered[\"raw\"].apply(ast.literal_eval)\n",
    "df_data = pd.DataFrame(df_parsed.tolist())\n",
    "\n",
    "# 열 순서 맞추기 (template 기준)\n",
    "df_data = df_data.reindex(columns=df_template.columns)\n",
    "\n",
    "# 저장\n",
    "df_data.to_csv(output_path, index=False, encoding='cp949')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "482b0580",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "총 8개의 신규 파일을 병합하였고, 결과 파일 저장 완료: 배추/유통공사_도매시장_배추_병합중복제거.csv\n"
     ]
    }
   ],
   "source": [
    "# 병합하기\n",
    "\n",
    "import pandas as pd\n",
    "import glob\n",
    "\n",
    "item_nm = '배추'\n",
    "\n",
    "# 파일 경로 설정\n",
    "existing_path = f\"{item_nm}/유통공사_도매시장_{item_nm}.csv\"\n",
    "new_paths = glob.glob(f\"{item_nm}/유통공사_retry_{item_nm}_*.csv\")\n",
    "output_path = f\"{item_nm}/유통공사_도매시장_{item_nm}_병합중복제거.csv\"\n",
    "\n",
    "# 기존 파일 로드\n",
    "df_existing = pd.read_csv(existing_path, encoding='cp949', low_memory=False)\n",
    "\n",
    "# 새로운 파일들 읽어서 병합\n",
    "df_new_list = [pd.read_csv(path, encoding='cp949', low_memory=False) for path in new_paths]\n",
    "df_new_combined = pd.concat(df_new_list, ignore_index=True)\n",
    "\n",
    "# 기존 + 새로운 데이터 합치기\n",
    "df_merged = pd.concat([df_existing, df_new_combined], ignore_index=True)\n",
    "\n",
    "# 날짜 컬럼 정제 및 정렬\n",
    "df_merged[\"trd_clcln_ymd\"] = pd.to_datetime(df_merged[\"trd_clcln_ymd\"])\n",
    "df_merged.sort_values(\"trd_clcln_ymd\", inplace=True)\n",
    "\n",
    "# 완전 중복 제거\n",
    "df_merged.drop_duplicates(inplace=True)\n",
    "\n",
    "# 저장\n",
    "df_merged.to_csv(output_path, index=False, encoding='cp949')\n",
    "\n",
    "print(f\"총 {len(new_paths)}개의 신규 파일을 병합하였고, 결과 파일 저장 완료: {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "12c3d58a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 1. 파일 경로 설정\n",
    "input_path = f\"{item_nm}/유통공사_도매시장_{item_nm}_병합중복제거.csv\"\n",
    "output_path = f\"{item_nm}/유통공사_도매시장_{item_nm}_한글컬럼명.csv\"\n",
    "\n",
    "# 2. CSV 전체를 문자열로 불러오기 (최초 경고 방지)\n",
    "df = pd.read_csv(input_path, encoding='cp949', dtype=str)\n",
    "\n",
    "# 3. 한글 컬럼명 설정\n",
    "new_columns = [\n",
    "    '평균가격(원)', '법인코드', '법인이름', '상품 대분류 코드', '상품 대분류 이름',\n",
    "    '상품 중분류 코드', '상품 중분류 이름', '상품 소분류 코드', '상품 소분류 이름',\n",
    "    '등급코드', '등급이름', '최고가(원)', '최저가(원)', '포장코드', '포장이름',\n",
    "    '산지코드', '산지이름', '크기코드', '크기이름', '총가격(원)', '날짜(YYYY-MM-DD)',\n",
    "    '매매구분', '단위코드', '단위(kg)', '단위물량(kg)', '단위총물량(kg)', '도매시장코드', '도매시장이름'\n",
    "]\n",
    "\n",
    "if len(df.columns) != len(new_columns):\n",
    "    raise ValueError(\"컬럼 수가 일치하지 않습니다.\")\n",
    "\n",
    "df.columns = new_columns\n",
    "\n",
    "# 4. 날짜 컬럼 변환\n",
    "df['날짜(YYYY-MM-DD)'] = pd.to_datetime(df['날짜(YYYY-MM-DD)'], errors='coerce')\n",
    "\n",
    "# 5. 숫자 컬럼 변환\n",
    "numeric_columns = ['평균가격(원)', '최고가(원)', '최저가(원)', '총가격(원)', '단위물량(kg)', '단위총물량(kg)']\n",
    "for col in numeric_columns:\n",
    "    df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "\n",
    "# 6. 혼합 타입 경고 컬럼 처리: NaN을 빈 문자열로, 모두 문자열화\n",
    "for col in ['포장이름', '산지이름', '크기이름']:\n",
    "    df[col] = df[col].fillna('').astype(str)\n",
    "\n",
    "# 7. CSV 저장 (완전 정리된 상태)\n",
    "df.to_csv(output_path, index=False, encoding='cp949')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0add8419",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_15072\\4122489021.py:8: DtypeWarning: Columns (9,13,17) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(input_path, encoding='cp949')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 파일 경로\n",
    "input_path = f\"{item_nm}/유통공사_도매시장_{item_nm}_한글컬럼명.csv\"\n",
    "output_path = f\"{item_nm}/유통공사_{item_nm}_요약데이터.csv\"\n",
    "\n",
    "# CSV 파일 불러오기\n",
    "df = pd.read_csv(input_path, encoding='cp949')\n",
    "\n",
    "selected_columns = ['날짜(YYYY-MM-DD)', '상품 중분류 이름', '등급이름', '총가격(원)', '단위총물량(kg)', '산지코드', '산지이름']\n",
    "df_selected = df[selected_columns]\n",
    "\n",
    "# 새 CSV로 저장\n",
    "df_selected.to_csv(output_path, index=False, encoding='cp949')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "323131b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 산지이름 기반으로 산지코드 수정 완료: 배추/유통공사_배추_요약데이터_산지이름기반수정.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 파일 경로\n",
    "base_file = f\"{item_nm}/유통공사_{item_nm}_요약데이터.csv\"\n",
    "jigpam_code_file = \"표준코드/산지코드_직팜.csv\"\n",
    "\n",
    "# 파일 읽기 (cp949 인코딩)\n",
    "df_base = pd.read_csv(base_file, encoding='cp949')\n",
    "df_code = pd.read_csv(jigpam_code_file, encoding='cp949')\n",
    "\n",
    "# '산지코드'를 숫자형으로 변환\n",
    "df_code['산지코드'] = pd.to_numeric(df_code['산지코드'], errors='coerce')\n",
    "\n",
    "# 800000 이상인 항목만 필터링하여 매핑 딕셔너리 생성\n",
    "code_map = df_code[df_code['산지코드'] >= 800000] \\\n",
    "              .set_index('산지이름')['산지코드'].to_dict()\n",
    "\n",
    "# 안전한 대체 함수 정의\n",
    "def safe_replace(row):\n",
    "    new_code = code_map.get(row['산지이름'], None)\n",
    "    if new_code is not None:\n",
    "        return new_code\n",
    "    return row['산지코드']  # 매핑 안되면 기존 값 유지\n",
    "\n",
    "# 정제 후 문자형으로 저장\n",
    "df_base['산지코드'] = df_base.apply(safe_replace, axis=1)\n",
    "\n",
    "# 결과 저장\n",
    "output_path = f\"{item_nm}/유통공사_{item_nm}_요약데이터_산지이름기반수정.csv\"\n",
    "df_base.to_csv(output_path, index=False, encoding='cp949')\n",
    "\n",
    "print(f\"✅ 산지이름 기반으로 산지코드 수정 완료: {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d757a981",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_15072\\807280020.py:5: DtypeWarning: Columns (5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(f\"{item_nm}/유통공사_{item_nm}_요약데이터_산지이름기반수정.csv\", encoding = 'cp949')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정제된 데이터가 저장되었습니다: 배추/유통공사_배추_요약데이터_정제.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# CSV 파일 로드\n",
    "df = pd.read_csv(f\"{item_nm}/유통공사_{item_nm}_요약데이터_산지이름기반수정.csv\", encoding = 'cp949')\n",
    "\n",
    "df['상품 중분류 이름'] = df['상품 중분류 이름'].replace('', pd.NA).fillna(f'{item_nm}')\n",
    "\n",
    "# 산지코드 정제 함수\n",
    "def clean_origin_code_backpad(code):\n",
    "    code_str = str(code)\n",
    "    digits = re.sub(r'\\D', '', code_str)  # 숫자만 남김\n",
    "    if not digits:\n",
    "        return None  # 숫자가 하나도 없으면 None\n",
    "    return digits[:6].ljust(6, '0')  # 6자리까지 자르고 부족하면 뒤에 0으로 채움\n",
    "\n",
    "# 정제 적용\n",
    "df['산지코드'] = df['산지코드'].apply(clean_origin_code)\n",
    "\n",
    "# 저장\n",
    "output_path = f\"{item_nm}/유통공사_{item_nm}_요약데이터_정제.csv\"\n",
    "df.to_csv(output_path, index=False, encoding = 'cp949')\n",
    "\n",
    "print(f\"정제된 데이터가 저장되었습니다: {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "76c211d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "날짜(YYYY-MM-DD)        0\n",
       "상품 중분류 이름             0\n",
       "등급이름                  0\n",
       "총가격(원)                0\n",
       "단위총물량(kg)             0\n",
       "산지코드                  0\n",
       "산지이름              26134\n",
       "dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(f\"{item_nm}/유통공사_{item_nm}_요약데이터_정제.csv\", encoding = 'cp949')\n",
    "\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "92382234",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 1. 파일 경로 설정\n",
    "summary_path = f\"{item_nm}/유통공사_{item_nm}_요약데이터_정제.csv\"\n",
    "region_code_path = \"표준코드/산지코드_직팜.csv\"\n",
    "\n",
    "# 2. CSV 불러오기\n",
    "summary_df = pd.read_csv(summary_path, encoding='cp949')\n",
    "region_df = pd.read_csv(region_code_path, encoding='cp949')\n",
    "\n",
    "# 3. 산지코드 범위 파싱 함수\n",
    "def parse_code_range(code_str):\n",
    "    if \"~\" in code_str:\n",
    "        start, end = code_str.split(\"~\")\n",
    "    else:\n",
    "        start = end = code_str\n",
    "    return int(start), int(end)\n",
    "\n",
    "# 4. 산지코드 범위 숫자 컬럼 생성\n",
    "region_df[['start_code', 'end_code']] = region_df['산지코드'].apply(\n",
    "    lambda x: pd.Series(parse_code_range(x))\n",
    ")\n",
    "\n",
    "# 5. 산지코드 → 직팜산지코드/이름 매핑 테이블 확장\n",
    "expanded_rows = []\n",
    "for _, row in region_df.iterrows():\n",
    "    for code in range(row['start_code'], row['end_code'] + 1):\n",
    "        expanded_rows.append({\n",
    "            '산지코드': code,\n",
    "            '직팜산지코드': row['직팜산지코드'],\n",
    "            '직팜산지이름': row['직팜산지이름']\n",
    "        })\n",
    "expanded_map_df = pd.DataFrame(expanded_rows)\n",
    "\n",
    "# 6. 요약 데이터 산지코드 정수형으로 변환\n",
    "summary_df['산지코드'] = pd.to_numeric(summary_df['산지코드'], errors='coerce').astype('Int64')\n",
    "summary_df = summary_df[summary_df['산지코드'].notna()].copy()\n",
    "summary_df['산지코드'] = summary_df['산지코드'].astype(int)\n",
    "\n",
    "# 7. 직팜 컬럼 제거 후 병합\n",
    "summary_df = summary_df.drop(columns=['직팜산지코드', '직팜산지이름'], errors='ignore')\n",
    "summary_df = pd.merge(summary_df, expanded_map_df, on='산지코드', how='left')\n",
    "\n",
    "# 8. 산지이름이 누락된 경우 직팜산지이름으로 보완\n",
    "summary_df['산지이름'] = summary_df['산지이름'].fillna(summary_df['직팜산지이름'])\n",
    "\n",
    "\n",
    "# 9. 결과 저장\n",
    "summary_df.to_csv(f\"{item_nm}/{item_nm}요약데이터_직팜산지정리.csv\", index=False, encoding='cp949')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e5467f89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "날짜(YYYY-MM-DD)      0\n",
       "상품 중분류 이름           0\n",
       "등급이름                0\n",
       "총가격(원)              0\n",
       "단위총물량(kg)           0\n",
       "산지코드                0\n",
       "산지이름              957\n",
       "직팜산지코드            957\n",
       "직팜산지이름            957\n",
       "dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(f\"{item_nm}/{item_nm}요약데이터_직팜산지정리.csv\", encoding = 'cp949')\n",
    "\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "827857ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "등급이름 수정 완료: 배추/배추요약데이터_직팜정리.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# CSV 파일 로드\n",
    "df = pd.read_csv(f\"{item_nm}/{item_nm}요약데이터_직팜산지정리.csv\", encoding='cp949')\n",
    "\n",
    "# 등급이름이 '.'인 경우 '보통'으로 대체\n",
    "df['등급이름'] = df['등급이름'].replace('.', '보통')\n",
    "\n",
    "# 저장\n",
    "output_path = f\"{item_nm}/{item_nm}요약데이터_직팜정리.csv\"\n",
    "df.to_csv(output_path, index=False, encoding='cp949')\n",
    "\n",
    "print(f\"등급이름 수정 완료: {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5ca61450",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[완료] 누락된 날짜 694건 → 누락날짜_배추.csv 저장됨\n"
     ]
    }
   ],
   "source": [
    "# 누락 날짜 확인\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# 1. 날짜 범위 생성\n",
    "full_dates = pd.date_range(start=\"2018-01-03\", end=\"2025-05-31\")\n",
    "\n",
    "# 2. CSV 파일에서 날짜 컬럼 읽기\n",
    "df = pd.read_csv(f\"{item_nm}/{item_nm}요약데이터_직팜정리.csv\", encoding='cp949')\n",
    "\n",
    "\n",
    "# 3. 날짜 컬럼 파싱 (예: 컬럼명이 '날짜'일 경우)\n",
    "df['날짜(YYYY-MM-DD)'] = pd.to_datetime(df['날짜(YYYY-MM-DD)'])\n",
    "\n",
    "# 4. 존재하는 날짜 목록\n",
    "existing_dates = pd.Series(df['날짜(YYYY-MM-DD)'].unique())\n",
    "\n",
    "# 5. 누락 날짜 계산\n",
    "missing_dates = full_dates[~full_dates.isin(existing_dates)]\n",
    "\n",
    "# 6. 결과 DataFrame (컬럼명 지정)\n",
    "missing_df = pd.DataFrame({'날짜(YYYY-MM-DD)': missing_dates.strftime(\"%Y-%m-%d\")})\n",
    "\n",
    "# 7. CSV 저장 (cp949 인코딩)\n",
    "missing_df.to_csv(f\"{item_nm}/누락날짜_{item_nm}.csv\", index=False, encoding=\"cp949\")\n",
    "\n",
    "print(f\"[완료] 누락된 날짜 {len(missing_df)}건 → 누락날짜_{item_nm}.csv 저장됨\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c96b523e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📦 실패 항목 재시도 시작: 배추\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "재시도 날짜 진행:   0%|                                                                        | 0/694 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "▶️ 요청 시도: 배추 | 시장코드: 도매시장코드 | 날짜: 2018-01-07 | 페이지: 1 | 재시도: 1\n",
      "⚠️ 거래 데이터 없음\n",
      "▶️ 요청 시도: 배추 | 시장코드: 110008 | 날짜: 2018-01-07 | 페이지: 1 | 재시도: 1\n",
      "⚠️ 거래 데이터 없음\n",
      "▶️ 요청 시도: 배추 | 시장코드: 210001 | 날짜: 2018-01-07 | 페이지: 1 | 재시도: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "재시도 날짜 진행:   0%|                                                                        | 0/694 [00:03<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 거래 데이터 없음\n",
      "▶️ 요청 시도: 배추 | 시장코드: 210005 | 날짜: 2018-01-07 | 페이지: 1 | 재시도: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[24], line 71\u001b[0m\n\u001b[0;32m     59\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m▶️ 요청 시도: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mitem_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m | 시장코드: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmcode\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m | 날짜: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdate_str\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m | 페이지: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpage_no\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m | 재시도: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mretry_count\u001b[38;5;250m \u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     61\u001b[0m params \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m     62\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mserviceKey\u001b[39m\u001b[38;5;124m'\u001b[39m: API_KEY,\n\u001b[0;32m     63\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpageNo\u001b[39m\u001b[38;5;124m'\u001b[39m: page_no,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcond[gds_mclsf_cd::EQ]\u001b[39m\u001b[38;5;124m'\u001b[39m: MID\n\u001b[0;32m     69\u001b[0m }\n\u001b[1;32m---> 71\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mrequests\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mBASE_URL\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverify\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     72\u001b[0m content_type \u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39mheaders\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mContent-Type\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     73\u001b[0m time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m1.0\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\ml-dl-nlp\\lib\\site-packages\\requests\\api.py:73\u001b[0m, in \u001b[0;36mget\u001b[1;34m(url, params, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mget\u001b[39m(url, params\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m     63\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Sends a GET request.\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \n\u001b[0;32m     65\u001b[0m \u001b[38;5;124;03m    :param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     70\u001b[0m \u001b[38;5;124;03m    :rtype: requests.Response\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 73\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m request(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mget\u001b[39m\u001b[38;5;124m\"\u001b[39m, url, params\u001b[38;5;241m=\u001b[39mparams, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\ml-dl-nlp\\lib\\site-packages\\requests\\api.py:59\u001b[0m, in \u001b[0;36mrequest\u001b[1;34m(method, url, **kwargs)\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;66;03m# By using the 'with' statement we are sure the session is closed, thus we\u001b[39;00m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;66;03m# avoid leaving sockets open which can trigger a ResourceWarning in some\u001b[39;00m\n\u001b[0;32m     57\u001b[0m \u001b[38;5;66;03m# cases, and look like a memory leak in others.\u001b[39;00m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m sessions\u001b[38;5;241m.\u001b[39mSession() \u001b[38;5;28;01mas\u001b[39;00m session:\n\u001b[1;32m---> 59\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m session\u001b[38;5;241m.\u001b[39mrequest(method\u001b[38;5;241m=\u001b[39mmethod, url\u001b[38;5;241m=\u001b[39murl, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\ml-dl-nlp\\lib\\site-packages\\requests\\sessions.py:589\u001b[0m, in \u001b[0;36mSession.request\u001b[1;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[0;32m    584\u001b[0m send_kwargs \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    585\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m\"\u001b[39m: timeout,\n\u001b[0;32m    586\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow_redirects\u001b[39m\u001b[38;5;124m\"\u001b[39m: allow_redirects,\n\u001b[0;32m    587\u001b[0m }\n\u001b[0;32m    588\u001b[0m send_kwargs\u001b[38;5;241m.\u001b[39mupdate(settings)\n\u001b[1;32m--> 589\u001b[0m resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msend(prep, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39msend_kwargs)\n\u001b[0;32m    591\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\ml-dl-nlp\\lib\\site-packages\\requests\\sessions.py:703\u001b[0m, in \u001b[0;36mSession.send\u001b[1;34m(self, request, **kwargs)\u001b[0m\n\u001b[0;32m    700\u001b[0m start \u001b[38;5;241m=\u001b[39m preferred_clock()\n\u001b[0;32m    702\u001b[0m \u001b[38;5;66;03m# Send the request\u001b[39;00m\n\u001b[1;32m--> 703\u001b[0m r \u001b[38;5;241m=\u001b[39m adapter\u001b[38;5;241m.\u001b[39msend(request, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    705\u001b[0m \u001b[38;5;66;03m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[0;32m    706\u001b[0m elapsed \u001b[38;5;241m=\u001b[39m preferred_clock() \u001b[38;5;241m-\u001b[39m start\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\ml-dl-nlp\\lib\\site-packages\\requests\\adapters.py:667\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[1;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[0;32m    664\u001b[0m     timeout \u001b[38;5;241m=\u001b[39m TimeoutSauce(connect\u001b[38;5;241m=\u001b[39mtimeout, read\u001b[38;5;241m=\u001b[39mtimeout)\n\u001b[0;32m    666\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 667\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    668\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    669\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    670\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    671\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    672\u001b[0m \u001b[43m        \u001b[49m\u001b[43mredirect\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    673\u001b[0m \u001b[43m        \u001b[49m\u001b[43massert_same_host\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    674\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    675\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    676\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    677\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    678\u001b[0m \u001b[43m        \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    679\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    681\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (ProtocolError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m    682\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(err, request\u001b[38;5;241m=\u001b[39mrequest)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\ml-dl-nlp\\lib\\site-packages\\urllib3\\connectionpool.py:793\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[0;32m    790\u001b[0m response_conn \u001b[38;5;241m=\u001b[39m conn \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m release_conn \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    792\u001b[0m \u001b[38;5;66;03m# Make the request on the HTTPConnection object\u001b[39;00m\n\u001b[1;32m--> 793\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_request(\n\u001b[0;32m    794\u001b[0m     conn,\n\u001b[0;32m    795\u001b[0m     method,\n\u001b[0;32m    796\u001b[0m     url,\n\u001b[0;32m    797\u001b[0m     timeout\u001b[38;5;241m=\u001b[39mtimeout_obj,\n\u001b[0;32m    798\u001b[0m     body\u001b[38;5;241m=\u001b[39mbody,\n\u001b[0;32m    799\u001b[0m     headers\u001b[38;5;241m=\u001b[39mheaders,\n\u001b[0;32m    800\u001b[0m     chunked\u001b[38;5;241m=\u001b[39mchunked,\n\u001b[0;32m    801\u001b[0m     retries\u001b[38;5;241m=\u001b[39mretries,\n\u001b[0;32m    802\u001b[0m     response_conn\u001b[38;5;241m=\u001b[39mresponse_conn,\n\u001b[0;32m    803\u001b[0m     preload_content\u001b[38;5;241m=\u001b[39mpreload_content,\n\u001b[0;32m    804\u001b[0m     decode_content\u001b[38;5;241m=\u001b[39mdecode_content,\n\u001b[0;32m    805\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mresponse_kw,\n\u001b[0;32m    806\u001b[0m )\n\u001b[0;32m    808\u001b[0m \u001b[38;5;66;03m# Everything went great!\u001b[39;00m\n\u001b[0;32m    809\u001b[0m clean_exit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\ml-dl-nlp\\lib\\site-packages\\urllib3\\connectionpool.py:537\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[1;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[0;32m    535\u001b[0m \u001b[38;5;66;03m# Receive the response from the server\u001b[39;00m\n\u001b[0;32m    536\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 537\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    538\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (BaseSSLError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    539\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_raise_timeout(err\u001b[38;5;241m=\u001b[39me, url\u001b[38;5;241m=\u001b[39murl, timeout_value\u001b[38;5;241m=\u001b[39mread_timeout)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\ml-dl-nlp\\lib\\site-packages\\urllib3\\connection.py:466\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    463\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mresponse\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m HTTPResponse\n\u001b[0;32m    465\u001b[0m \u001b[38;5;66;03m# Get the response from http.client.HTTPConnection\u001b[39;00m\n\u001b[1;32m--> 466\u001b[0m httplib_response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    468\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    469\u001b[0m     assert_header_parsing(httplib_response\u001b[38;5;241m.\u001b[39mmsg)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\ml-dl-nlp\\lib\\http\\client.py:1375\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1373\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1374\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1375\u001b[0m         \u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbegin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1376\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m:\n\u001b[0;32m   1377\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\ml-dl-nlp\\lib\\http\\client.py:318\u001b[0m, in \u001b[0;36mHTTPResponse.begin\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    316\u001b[0m \u001b[38;5;66;03m# read until we get a non-100 response\u001b[39;00m\n\u001b[0;32m    317\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m--> 318\u001b[0m     version, status, reason \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_read_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    319\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m status \u001b[38;5;241m!=\u001b[39m CONTINUE:\n\u001b[0;32m    320\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\ml-dl-nlp\\lib\\http\\client.py:279\u001b[0m, in \u001b[0;36mHTTPResponse._read_status\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    278\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_read_status\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m--> 279\u001b[0m     line \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreadline\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_MAXLINE\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miso-8859-1\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    280\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(line) \u001b[38;5;241m>\u001b[39m _MAXLINE:\n\u001b[0;32m    281\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m LineTooLong(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstatus line\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\ml-dl-nlp\\lib\\socket.py:717\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[1;34m(self, b)\u001b[0m\n\u001b[0;32m    715\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m    716\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 717\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    718\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[0;32m    719\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout_occurred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# 실패 로그 기반 데이터 재수집\n",
    "import os\n",
    "import pandas as pd\n",
    "import requests\n",
    "import time\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm\n",
    "import ssl\n",
    "import warnings\n",
    "import xml.etree.ElementTree as ET\n",
    "from requests.packages.urllib3.exceptions import InsecureRequestWarning\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# 환경 및 경고 설정\n",
    "load_dotenv()\n",
    "warnings.filterwarnings('ignore', category=InsecureRequestWarning)\n",
    "ssl._create_default_https_context = ssl._create_unverified_context\n",
    "\n",
    "# 상수\n",
    "API_KEY = os.getenv(\"DO_API_KEY\")\n",
    "BASE_URL = 'http://apis.data.go.kr/B552845/katSale/trades'\n",
    "item_nm = '배추'\n",
    "ITEM_CODES = {f\"{item_nm}\": \"1001\"}\n",
    "max_retries = 2  # 재시도 최대 횟수 (1회 시도 + 0회 재시도)\n",
    "\n",
    "# 디렉토리 준비\n",
    "os.makedirs(\"logs\", exist_ok=True)\n",
    "os.makedirs(\"data\", exist_ok=True)\n",
    "os.makedirs(\"success\", exist_ok=True)\n",
    "\n",
    "# 도매시장 코드 불러오기\n",
    "df_market = pd.read_csv(\"표준코드/도매시장_코드.csv\", encoding=\"cp949\", header=None)\n",
    "df_market[0] = df_market[0].astype(str)\n",
    "\n",
    "# 실패 로그 불러오기\n",
    "fail_df = pd.read_csv(f\"{item_nm}/누락날짜_{item_nm}.csv\", encoding=\"cp949\")\n",
    "fail_dates = pd.to_datetime(fail_df['날짜(YYYY-MM-DD)']).dt.strftime(\"%Y-%m-%d\")\n",
    "\n",
    "# 도매시장 리스트\n",
    "market_list = df_market[[0, 1]].values.tolist()  # (시장코드, 시장명)\n",
    "\n",
    "for item_name, code in ITEM_CODES.items():\n",
    "    LARGE = code[:2]\n",
    "    MID = code[2:]\n",
    "    data_list = []\n",
    "    cnt =0\n",
    "\n",
    "    print(f\"\\n📦 실패 항목 재시도 시작: {item_name}\")\n",
    "    for date_str in tqdm(fail_dates, desc=\"재시도 날짜 진행\"):\n",
    "        for mcode, market_name in market_list:\n",
    "            retry_count = 0\n",
    "            market_success = False\n",
    "\n",
    "            while retry_count < max_retries:\n",
    "                page_no = 1\n",
    "                cnt += 1\n",
    "                try:\n",
    "                    while True:\n",
    "                        print(f\"▶️ 요청 시도: {item_name} | 시장코드: {mcode} | 날짜: {date_str} | 페이지: {page_no} | 재시도: {retry_count + 1}\")\n",
    "\n",
    "                        params = {\n",
    "                            'serviceKey': API_KEY,\n",
    "                            'pageNo': page_no,\n",
    "                            'numOfRows': 100,\n",
    "                            'cond[trd_clcln_ymd::EQ]': date_str,\n",
    "                            'cond[whsl_mrkt_cd::EQ]': mcode,\n",
    "                            'cond[gds_lclsf_cd::EQ]': LARGE,\n",
    "                            'cond[gds_mclsf_cd::EQ]': MID\n",
    "                        }\n",
    "\n",
    "                        response = requests.get(BASE_URL, params=params, verify=False, timeout=10)\n",
    "                        content_type = response.headers.get(\"Content-Type\", \"\")\n",
    "                        time.sleep(1.0)\n",
    "                        response_preview = response.text[:500].strip()\n",
    "\n",
    "                        # 오류 체크\n",
    "                        if \"LIMITED_\" in response_preview:\n",
    "                            fail_reason = \"❌ API 호출 제한 (LIMITED_ 응답)\"\n",
    "                        elif \"SERVICE ERROR\" in response_preview:\n",
    "                            fail_reason = \"❌ 서비스 오류 (SERVICE ERROR 응답)\"\n",
    "                        elif \"ERROR\" in response_preview.upper():\n",
    "                            fail_reason = \"❌ 기타 오류 포함 (ERROR 키워드 포함)\"\n",
    "                        elif \"TOO MANY REQUESTS\" in response_preview.upper():\n",
    "                            fail_reason = \"❌ 요청 과다로 인한 제한 (Too Many Requests)\"\n",
    "                        else:\n",
    "                            fail_reason = None\n",
    "\n",
    "                        if fail_reason:\n",
    "                            print(f\"⛔ {fail_reason} - 재시도 대기 중 (2분)\")\n",
    "                            log_prefix = f\"logs/retry_failed_{item_name}_{mcode}_{date_str}\"\n",
    "                            with open(f\"{log_prefix}.html\", \"w\", encoding=\"utf-8\") as f:\n",
    "                                f.write(response.text)\n",
    "                            with open(f\"{log_prefix}_info.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "                                f.write(f\"[오류] {fail_reason}\\n{response_preview}\")\n",
    "                            retry_count += 1\n",
    "                            if retry_count >= max_retries:\n",
    "                                print(f\"❗ 최대 재시도 {max_retries}회 초과 - 중단\")\n",
    "                                break\n",
    "                            time.sleep(60)\n",
    "                            continue\n",
    "\n",
    "                        # 응답 파싱\n",
    "                        if \"application/json\" in content_type:\n",
    "                            json_data = response.json()\n",
    "                            body = json_data.get(\"response\", {}).get(\"body\", {})\n",
    "                            items = body.get(\"items\", {}).get(\"item\", [])\n",
    "                            total_count = int(body.get(\"totalCount\", 0))\n",
    "\n",
    "                        elif \"application/xml\" in content_type or response.text.strip().startswith(\"<\"):\n",
    "                            root = ET.fromstring(response.text)\n",
    "                            total_count_el = root.find(\".//totalCount\")\n",
    "                            total_count = int(total_count_el.text) if total_count_el is not None else 0\n",
    "                            item_els = root.findall(\".//item\")\n",
    "                            items = [{el.tag: el.text for el in item} for item in item_els]\n",
    "                        else:\n",
    "                            raise ValueError(f\"알 수 없는 응답 형식: {content_type}\")\n",
    "\n",
    "                        if not items:\n",
    "                            print(\"⚠️ 거래 데이터 없음\")\n",
    "                            market_success = True\n",
    "                            break\n",
    "\n",
    "                        data_list.extend(items)\n",
    "\n",
    "                        if cnt % 10000 == 0:\n",
    "                            print(f\"🧪 중간 저장 시도: 현재 data_list 길이 = {len(data_list)}\")\n",
    "                            mid_save_path = f\"{item_nm}/유통공사_retry_{item_name}_{datetime.now().strftime('%Y%m%d_%H%M%S')}_mid.csv\"\n",
    "                            pd.DataFrame(data_list).to_csv(mid_save_path, encoding='cp949', index=False)\n",
    "                            print(f\"💾 중간 저장 완료: {mid_save_path}\")\n",
    "\n",
    "                        market_success = True\n",
    "                        if page_no * 100 >= total_count:\n",
    "                            print(f\"✅ 마지막 페이지 도달 (totalCount: {total_count})\")\n",
    "                            break\n",
    "                        if page_no > 10:\n",
    "                            print(\"🚨 페이지 10 초과 - 무한 루프 방지를 위해 중단\")\n",
    "                            break\n",
    "\n",
    "                        page_no += 1\n",
    "                        time.sleep(1.0)\n",
    "\n",
    "                    if market_success:\n",
    "                        break\n",
    "                    else:\n",
    "                        retry_count += 1\n",
    "                        time.sleep(2 * retry_count)\n",
    "\n",
    "                except Exception as e:\n",
    "                    retry_count += 1\n",
    "                    print(f\"❗예외 발생: {e} (재시도 {retry_count}/{max_retries})\")\n",
    "                    fail_log_prefix = f\"logs/retry_failed_{item_name}_{mcode}_{date_str}_try{retry_count}\"\n",
    "                    if 'response' in locals():\n",
    "                        with open(f\"{fail_log_prefix}.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "                            f.write(response.text)\n",
    "                    with open(f\"{fail_log_prefix}_info.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "                        f.write(f\"[예외] {str(e)}\\n\")\n",
    "                    if retry_count >= max_retries:\n",
    "                        break\n",
    "                    time.sleep(2 * retry_count)\n",
    "\n",
    "            if not market_success:\n",
    "                fail_log_path = f\"logs/retry_failed_{item_name}_{mcode}_{date_str}.txt\"\n",
    "                with open(fail_log_path, \"w\", encoding=\"utf-8\") as f:\n",
    "                    f.write(f\"❌ {datetime.now()} - {item_name} {mcode} {date_str} 데이터 수집 실패\\n\")\n",
    "\n",
    "    # 저장\n",
    "    if data_list:\n",
    "        df = pd.DataFrame(data_list)\n",
    "        filename = f\"{item_nm}/유통공사_retry_{item_name}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv\"\n",
    "        df.to_csv(filename, encoding='cp949', index=False)\n",
    "        print(f\"✅ 저장 완료: {filename}\")\n",
    "    else:\n",
    "        print(f\"⚠️ {item_name}: 재시도에서도 데이터 없음\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fd7068c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-dl-nlp",
   "language": "python",
   "name": "ml-dl-nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
