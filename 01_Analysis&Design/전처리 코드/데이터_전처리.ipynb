{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5a1cdcaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 양파 : 1201 # 배추 : 1001 # 상추 : 1005 # 사과 : 0601 # 무 : 1101 # 감자 : 0501 # 대파 : 1202 # 건고추 : 1207\n",
    "# 마늘 : 1209 # 딸기 : 0804  # 방울토마토 : 0806 # 오이 : 0901 # 양배추 : 1004  # 고구마 : 0502  # 배 : 0602\n",
    "\n",
    "item_nm = '무'\n",
    "item_cd = 1101"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "5a849626",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "\n",
    "# 기본 파일 경로\n",
    "base_path = f\"{item_nm}/유통공사_도매시장_{item_nm}.csv\"\n",
    "\n",
    "# retry 파일 목록 수집\n",
    "retry_paths = glob.glob(f\"{item_nm}/유통공사_retry_{item_nm}_*.csv\")\n",
    "\n",
    "# 기본 파일 읽기\n",
    "df_list = [pd.read_csv(base_path, encoding=\"cp949\", low_memory=False)]\n",
    "\n",
    "# retry 파일들 읽기 (있을 경우에만)\n",
    "for path in retry_paths:\n",
    "    df_list.append(pd.read_csv(path, encoding=\"cp949\", low_memory=False))\n",
    "\n",
    "# 병합\n",
    "df = pd.concat(df_list, ignore_index=True)\n",
    "\n",
    "# 중복 제거 (전체 행 기준 또는 주요 열 기준)\n",
    "df = df.drop_duplicates()\n",
    "\n",
    "# plor_cd가 문자열이 아닐 가능성 대비\n",
    "df['plor_cd'] = df['plor_cd'].fillna('').astype(str)\n",
    "\n",
    "pattern = r'^[^0-9]+$'\n",
    "\n",
    "condition = (\n",
    "    df['totprc'].isna() | (df['totprc'] <= 0) |\n",
    "    df['unit_tot_qty'].isna() | (df['unit_tot_qty'] <= 0) |\n",
    "    df['plor_cd'].str.strip().isin(['0', '0.0']) |\n",
    "    df['plor_cd'].str.match(pattern, na=False) |\n",
    "    df['plor_nm'].isna() |\n",
    "    (df['plor_nm'] == 0)\n",
    ")\n",
    "\n",
    "# 조건에 해당하는 행 추출\n",
    "df_filtered = df[~condition]\n",
    "\n",
    "# 결과 저장\n",
    "df_filtered.to_csv(f\"{item_nm}/유통공사_도매시장_{item_nm}_결측치제거.csv\", index=False, encoding=\"cp949\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "12c3d58a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 1. 파일 경로 설정\n",
    "input_path = f\"{item_nm}/유통공사_도매시장_{item_nm}_결측치제거.csv\"\n",
    "output_path = f\"{item_nm}/유통공사_도매시장_{item_nm}_한글컬럼명.csv\"\n",
    "\n",
    "# 2. CSV 전체를 문자열로 불러오기 (최초 경고 방지)\n",
    "df = pd.read_csv(input_path, encoding='cp949', dtype=str)\n",
    "\n",
    "# 3. 한글 컬럼명 설정\n",
    "new_columns = [\n",
    "    '평균가격(원)', '법인코드', '법인이름', '상품 대분류 코드', '상품 대분류 이름',\n",
    "    '상품 중분류 코드', '상품 중분류 이름', '상품 소분류 코드', '상품 소분류 이름',\n",
    "    '등급코드', '등급이름', '최고가(원)', '최저가(원)', '포장코드', '포장이름',\n",
    "    '산지코드', '산지이름', '크기코드', '크기이름', '총가격(원)', '연월일',\n",
    "    '매매구분', '단위코드', '단위(kg)', '단위물량(kg)', '단위총물량(kg)', '도매시장코드', '도매시장이름'\n",
    "]\n",
    "\n",
    "if len(df.columns) != len(new_columns):\n",
    "    raise ValueError(\"컬럼 수가 일치하지 않습니다.\")\n",
    "\n",
    "df.columns = new_columns\n",
    "\n",
    "# 4. 날짜 컬럼 변환\n",
    "df['연월일'] = pd.to_datetime(df['연월일'], errors='coerce')\n",
    "\n",
    "# 5. 숫자 컬럼 변환\n",
    "numeric_columns = ['평균가격(원)', '최고가(원)', '최저가(원)', '총가격(원)', '단위물량(kg)', '단위총물량(kg)']\n",
    "for col in numeric_columns:\n",
    "    df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "\n",
    "# 6. 혼합 타입 경고 컬럼 처리: NaN을 빈 문자열로, 모두 문자열화\n",
    "for col in ['포장이름', '산지이름', '크기이름']:\n",
    "    df[col] = df[col].fillna('').astype(str)\n",
    "\n",
    "# 7. CSV 저장 (완전 정리된 상태)\n",
    "df.to_csv(output_path, index=False, encoding='cp949')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "0add8419",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_9524\\736215019.py:8: DtypeWarning: Columns (9,13,17) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(input_path, encoding='cp949')\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_9524\\736215019.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_selected.rename(columns={\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_9524\\736215019.py:22: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_selected['평균단가(원)'] = df_selected['총금액(원)'] / df_selected['총거래량(kg)']\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_9524\\736215019.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_selected['평균단가(원)'] = df_selected['평균단가(원)'].replace([float('inf'), -float('inf')], None)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 파일 경로\n",
    "input_path = f\"{item_nm}/유통공사_도매시장_{item_nm}_한글컬럼명.csv\"\n",
    "output_path = f\"{item_nm}/유통공사_{item_nm}_요약데이터.csv\"\n",
    "\n",
    "# CSV 파일 불러오기\n",
    "df = pd.read_csv(input_path, encoding='cp949')\n",
    "\n",
    "selected_columns = ['연월일', '상품 중분류 코드', '상품 중분류 이름', '상품 소분류 코드', '상품 소분류 이름',\n",
    "                    '총가격(원)', '단위총물량(kg)', '산지코드', '산지이름']\n",
    "df_selected = df[selected_columns]\n",
    "df_selected.rename(columns={\n",
    "    '상품 중분류 코드':'품목코드',\n",
    "    '상품 중분류 이름':'품목명',\n",
    "    '상품 소분류 코드':'품종코드',\n",
    "    '상품 소분류 이름':'품종명',\n",
    "    '총가격(원)':'총금액(원)',\n",
    "    '단위총물량(kg)':'총거래량(kg)'\n",
    "}, inplace=True)\n",
    "\n",
    "df_selected['평균단가(원)'] = df_selected['총금액(원)'] / df_selected['총거래량(kg)']\n",
    "df_selected['평균단가(원)'] = df_selected['평균단가(원)'].replace([float('inf'), -float('inf')], None)\n",
    "df_selected.insert(df_selected.columns.get_loc('총거래량(kg)') + 1, '평균단가(원)', df_selected.pop('평균단가(원)'))\n",
    "\n",
    "# 새 CSV로 저장\n",
    "df_selected.to_csv(output_path, index=False, encoding='cp949')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "793dd88c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "연월일         0\n",
       "품목코드        0\n",
       "품목명         8\n",
       "품종코드        0\n",
       "품종명         7\n",
       "총금액(원)      0\n",
       "총거래량(kg)    0\n",
       "평균단가(원)     0\n",
       "산지코드        0\n",
       "산지이름        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(f\"{item_nm}/유통공사_{item_nm}_요약데이터.csv\", encoding = 'cp949')\n",
    "\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d757a981",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정제된 데이터가 저장되었습니다: 배추/유통공사_배추_요약데이터_정제.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# CSV 파일 로드\n",
    "df = pd.read_csv(f\"{item_nm}/유통공사_{item_nm}_요약데이터.csv\", encoding='cp949')\n",
    "\n",
    "# 상품 중분류 이름 결측치 처리\n",
    "df['품목코드'] = df['품목코드'].replace('', pd.NA).fillna(item_nm)\n",
    "df['품목명'] = df['품목명'].replace('', pd.NA).fillna(item_nm)\n",
    "df['품종코드'] = df['품종코드'].replace('', pd.NA).fillna(item_nm)\n",
    "df['품종명'] = df['품종명'].replace('', pd.NA).fillna(item_nm)\n",
    "\n",
    "# 산지코드 정제 함수 (문자 → 0, 앞자리 0 제거, 6자리 맞춤)\n",
    "def clean_origin_code_backpad(code):\n",
    "    code_str = str(code).strip()\n",
    "    replaced = re.sub(r'\\D', '0', code_str)      # 문자 → 0\n",
    "    stripped = replaced.lstrip('0')              # 앞쪽 0 제거\n",
    "    if not stripped:  # 모두 0이거나 제거 결과 없음\n",
    "        stripped = '0'\n",
    "    return stripped[:6].ljust(6, '0')            # 앞 6자리 + 뒤 0 패딩\n",
    "\n",
    "# 적용\n",
    "df['산지코드'] = df['산지코드'].apply(clean_origin_code_backpad)\n",
    "\n",
    "# 저장\n",
    "output_path = f\"{item_nm}/유통공사_{item_nm}_요약데이터_정제.csv\"\n",
    "df.to_csv(output_path, index=False, encoding='cp949')\n",
    "\n",
    "print(f\"정제된 데이터가 저장되었습니다: {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "76c211d5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "연월일         0\n",
       "품목코드        0\n",
       "품목명         0\n",
       "품종코드        0\n",
       "품종명         0\n",
       "총금액(원)      0\n",
       "총거래량(kg)    0\n",
       "평균단가(원)     0\n",
       "산지코드        0\n",
       "산지이름        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(f\"{item_nm}/유통공사_{item_nm}_요약데이터_정제.csv\", encoding = 'cp949')\n",
    "\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "ddb059fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 파일 경로 설정\n",
    "file_path = f\"{item_nm}/유통공사_{item_nm}_요약데이터_정제.csv\"\n",
    "\n",
    "# CSV 파일 읽기 (경고 방지를 위해 low_memory=False 사용)\n",
    "df = pd.read_csv(file_path, encoding=\"cp949\", low_memory=False)\n",
    "\n",
    "# 산지코드가 문자열로 처리되도록 변환\n",
    "df['산지코드'] = df['산지코드'].fillna('').astype(str)\n",
    "\n",
    "# 필터링 조건: totprc 또는 unit_tot_qty가 NaN이거나 0인 경우\n",
    "pattern = r'^[^0-9]+$'\n",
    "\n",
    "condition = (\n",
    "    (df['산지코드'] == '') |\n",
    "    (df['산지코드'].str.strip() == \"0\") |\n",
    "    (df['산지코드'].str.strip() == \"0.0\")\n",
    "#     df['plor_cd'].str.match(pattern, na=False)) \n",
    "#     (df['plor_nm'].isna() | (df['plor_nm'] == 0))\n",
    ")\n",
    "\n",
    "# 조건에 해당하는 행 추출\n",
    "df_filtered = df[condition]\n",
    "\n",
    "# 결과 저장\n",
    "df_filtered.to_csv(f\"{item_nm}/결측치_{item_nm}.csv\", index=False, encoding=\"cp949\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "92382234",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 1. 파일 경로 설정\n",
    "summary_path = f\"{item_nm}/유통공사_{item_nm}_요약데이터_정제.csv\"\n",
    "region_code_path = \"표준코드/산지코드_직팜.csv\"\n",
    "\n",
    "# 2. CSV 불러오기\n",
    "summary_df = pd.read_csv(summary_path, encoding='cp949')\n",
    "region_df = pd.read_csv(region_code_path, encoding='cp949')\n",
    "\n",
    "# 3. 산지코드 범위 파싱 함수\n",
    "def parse_code_range(code_str):\n",
    "    if \"~\" in code_str:\n",
    "        start, end = code_str.split(\"~\")\n",
    "    else:\n",
    "        start = end = code_str\n",
    "    return int(start), int(end)\n",
    "\n",
    "# 4. 산지코드 범위 숫자 컬럼 생성\n",
    "region_df[['start_code', 'end_code']] = region_df['산지코드'].apply(\n",
    "    lambda x: pd.Series(parse_code_range(x))\n",
    ")\n",
    "\n",
    "# 5. 산지코드 → 직팜산지코드/이름 매핑 테이블 확장\n",
    "expanded_rows = []\n",
    "for _, row in region_df.iterrows():\n",
    "    for code in range(row['start_code'], row['end_code'] + 1):\n",
    "        expanded_rows.append({\n",
    "            '산지코드': code,\n",
    "            '직팜산지코드': row['직팜산지코드'],\n",
    "            '직팜산지이름': row['직팜산지이름']\n",
    "        })\n",
    "expanded_map_df = pd.DataFrame(expanded_rows)\n",
    "\n",
    "# 6. 요약 데이터 산지코드 정수형으로 변환\n",
    "summary_df['산지코드'] = pd.to_numeric(summary_df['산지코드'], errors='coerce').astype('Int64')\n",
    "summary_df = summary_df[summary_df['산지코드'].notna()].copy()\n",
    "summary_df['산지코드'] = summary_df['산지코드'].astype(int)\n",
    "\n",
    "# 7. 직팜 컬럼 제거 후 병합\n",
    "summary_df = summary_df.drop(columns=['직팜산지코드', '직팜산지이름'], errors='ignore')\n",
    "summary_df = pd.merge(summary_df, expanded_map_df, on='산지코드', how='left')\n",
    "\n",
    "# 8. 산지이름이 누락된 경우 직팜산지이름으로 보완\n",
    "summary_df['산지이름'] = summary_df['산지이름'].fillna(summary_df['직팜산지이름'])\n",
    "\n",
    "\n",
    "# 9. 결과 저장\n",
    "summary_df.to_csv(f\"{item_nm}/{item_nm}요약데이터_직팜산지정리.csv\", index=False, encoding='cp949')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "e5467f89",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "연월일         0\n",
       "품목코드        0\n",
       "품목명         0\n",
       "품종코드        0\n",
       "품종명         0\n",
       "총금액(원)      0\n",
       "총거래량(kg)    0\n",
       "평균단가(원)     0\n",
       "산지코드        0\n",
       "산지이름        0\n",
       "직팜산지코드      0\n",
       "직팜산지이름      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(f\"{item_nm}/{item_nm}요약데이터_직팜산지정리.csv\", encoding = 'cp949')\n",
    "\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "d0c425a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "결측치 포함 행 0개를 '배추/배추_결측치포함행.csv'로 저장했습니다.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 파일 경로와 인코딩으로 데이터 불러오기\n",
    "df = pd.read_csv(f\"{item_nm}/{item_nm}요약데이터_직팜산지정리.csv\", encoding='cp949')\n",
    "\n",
    "# 결측치가 하나라도 있는 행만 추출\n",
    "df_na = df[df.isna().any(axis=1)]\n",
    "\n",
    "# 결과 저장\n",
    "output_path = f\"{item_nm}/{item_nm}_결측치포함행.csv\"\n",
    "df_na.to_csv(output_path, index=False, encoding='cp949')\n",
    "\n",
    "print(f\"결측치 포함 행 {len(df_na)}개를 '{output_path}'로 저장했습니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "2c88d6fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 파일 불러오기\n",
    "df = pd.read_csv(f\"{item_nm}/{item_nm}요약데이터_직팜산지정리.csv\", encoding='cp949')\n",
    "\n",
    "# 제거할 컬럼 리스트\n",
    "columns_to_drop = ['산지코드', '산지이름', '직팜산지이름']\n",
    "df.drop(columns=columns_to_drop, inplace=True, errors='ignore')\n",
    "\n",
    "# 새로 추가할 컬럼들 (초기값은 None)\n",
    "new_columns = [\n",
    "    '휴일여부', '명절지수', '작기정보'\n",
    "]\n",
    "for col in new_columns:\n",
    "    df[col] = None\n",
    "\n",
    "# 결과 저장\n",
    "df.to_csv(f\"{item_nm}/{item_nm}요약데이터_컬럼정리완료.csv\", index=False, encoding='cp949')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "e46e1f7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 파일 경로\n",
    "summary_path = f\"{item_nm}/{item_nm}요약데이터_컬럼정리완료.csv\"\n",
    "mapping_path = \"기상/산지코드_직팜_관측지점_매핑완료.csv\"\n",
    "\n",
    "# CSV 파일 불러오기\n",
    "df_summary = pd.read_csv(summary_path, encoding='cp949')\n",
    "df_mapping = pd.read_csv(mapping_path, encoding='cp949')\n",
    "\n",
    "# 중복 제거\n",
    "df_mapping = df_mapping.drop_duplicates(subset='직팜산지코드')\n",
    "\n",
    "# '직팜산지코드' 기준으로 '관측지점' 컬럼 병합\n",
    "df_merge = pd.merge(\n",
    "    df_summary,\n",
    "    df_mapping[['직팜산지코드', '관측지점']],\n",
    "    on='직팜산지코드',\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# '작기정보' 컬럼 오른쪽에 '관측지점' 컬럼 삽입\n",
    "if '작기정보' in df_merge.columns:\n",
    "    insert_idx = df_merge.columns.get_loc('작기정보') + 1  # '작기정보' 다음 위치\n",
    "    관측지점_series = df_merge.pop('관측지점')\n",
    "    df_merge.insert(insert_idx, '관측지점', 관측지점_series)\n",
    "\n",
    "# 결과 저장\n",
    "df_merge.to_csv(f\"{item_nm}/{item_nm}요약데이터_관측지점추가.csv\", index=False, encoding='cp949')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "0c43b24c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 파일 경로 설정\n",
    "crop_path = f\"{item_nm}/{item_nm}요약데이터_관측지점추가.csv\"\n",
    "weather_path = \"기상/기상청_일기요소.csv\"\n",
    "output_path = f\"{item_nm}/{item_nm}요약데이터_기상병합완료.csv\"\n",
    "\n",
    "# 데이터 불러오기\n",
    "df_crop = pd.read_csv(crop_path, encoding='cp949')\n",
    "df_weather = pd.read_csv(weather_path, encoding='cp949')\n",
    "\n",
    "# 날짜 처리 → YYYYMMDD 문자열\n",
    "df_crop['연월일'] = pd.to_datetime(df_crop['연월일'], errors='coerce')\n",
    "df_crop['날짜'] = df_crop['연월일'].dt.strftime('%Y%m%d')\n",
    "\n",
    "df_weather['TM'] = pd.to_datetime(df_weather['TM'], errors='coerce')\n",
    "df_weather['날짜'] = df_weather['TM'].dt.strftime('%Y%m%d')\n",
    "\n",
    "# 관측지점/STN 모두 int로 통일 후 str 변환\n",
    "df_crop['관측지점'] = df_crop['관측지점'].astype('Int64').astype(str)\n",
    "df_weather['STN'] = df_weather['STN'].astype('Int64').astype(str)\n",
    "\n",
    "# 병합 키 생성\n",
    "df_crop['merge_key'] = df_crop['날짜'] + '_' + df_crop['관측지점']\n",
    "df_weather['merge_key'] = df_weather['날짜'] + '_' + df_weather['STN']\n",
    "\n",
    "# 날씨 컬럼 매핑\n",
    "weather_cols = {\n",
    "    'TA_AVG': '일평균기온',\n",
    "    'TA_MAX': '최고기온',\n",
    "    'TA_MIN': '최저기온',\n",
    "    'HM_AVG': '평균상대습도',\n",
    "    'RN_DAY': '강수량(mm)',\n",
    "    'RN_60M_MAX': '1시간최고강수량(mm)'\n",
    "}\n",
    "\n",
    "# 병합용 데이터 준비\n",
    "df_weather_subset = df_weather[['merge_key'] + list(weather_cols.keys())].copy()\n",
    "df_weather_subset.rename(columns=weather_cols, inplace=True)\n",
    "\n",
    "# 병합 수행\n",
    "df_merged = pd.merge(df_crop, df_weather_subset, on='merge_key', how='left')\n",
    "\n",
    "# 정리: 병합키 및 중간 날짜 컬럼 제거\n",
    "df_merged.drop(columns=['merge_key', '날짜'], inplace=True)\n",
    "\n",
    "# <NA> → 빈 문자열, NaN → 빈 문자열 처리\n",
    "df_merged.replace(\"<NA>\", \"\", inplace=True)\n",
    "df_merged.fillna(\"\", inplace=True)\n",
    "\n",
    "# 결과 저장\n",
    "df_merged.to_csv(output_path, index=False, encoding='cp949')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "a37ec1d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 파일 불러오기\n",
    "df = pd.read_csv(f\"{item_nm}/{item_nm}요약데이터_기상병합완료.csv\", encoding='cp949')\n",
    "\n",
    "# 제거할 컬럼 리스트\n",
    "columns_to_drop = ['관측지점']\n",
    "df.drop(columns=columns_to_drop, inplace=True, errors='ignore')\n",
    "\n",
    "# 결과 저장\n",
    "df.to_csv(f\"{item_nm}/{item_nm}요약데이터_기상.csv\", index=False, encoding='cp949')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "1dc339b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "\n",
    "# df = pd.read_csv(f\"{item_nm}/{item_nm}요약데이터_기상.csv\", encoding='cp949')\n",
    "\n",
    "# df = df[~(df['직팜산지코드'] == 2000)]\n",
    "\n",
    "# df.to_csv(f\"{item_nm}/{item_nm}요약데이터_기상_수입산제거.csv\", index=False, encoding='cp949')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "4d179190",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "\n",
    "# # CSV 파일 불러오기\n",
    "# df = pd.read_csv(f\"{item_nm}/{item_nm}요약데이터_기상.csv\", encoding='cp949')\n",
    "# df['연월일'] = pd.to_datetime(df['연월일'])\n",
    "\n",
    "# # 이상치 제거 함수\n",
    "# def remove_outliers_iqr(group, column):\n",
    "#     if len(group) < 4:\n",
    "#         return group  # 너무 적으면 제거하지 않음\n",
    "    \n",
    "#     q1 = group[column].quantile(0.25)\n",
    "#     q3 = group[column].quantile(0.75)\n",
    "#     iqr = q3 - q1\n",
    "#     lower = q1 - 1.5 * iqr\n",
    "#     upper = q3 + 1.5 * iqr\n",
    "#     return group[(group[column] >= lower) & (group[column] <= upper)]\n",
    "\n",
    "# # 일별로 그룹핑하여 이상치 제거\n",
    "# daily_filtered = df.groupby('연월일', group_keys=False).apply(\n",
    "#     remove_outliers_iqr, column='평균단가(원)'\n",
    "# )\n",
    "\n",
    "# # 날짜별 제거 개수 계산\n",
    "# original_counts = df.groupby('연월일').size().rename('원래수')\n",
    "# filtered_counts = daily_filtered.groupby('연월일').size().rename('제거후수')\n",
    "# removal_stats = pd.concat([original_counts, filtered_counts], axis=1).fillna(0).astype(int)\n",
    "# removal_stats['제거수'] = removal_stats['원래수'] - removal_stats['제거후수']\n",
    "\n",
    "\n",
    "# # 총 제거 수 계산\n",
    "# total_removed = removal_stats['제거수'].sum()\n",
    "\n",
    "# # ✅ 출력\n",
    "# print(\"✅ 총 제거된 이상치 수:\", total_removed)\n",
    "# print(\"\\n📅 날짜별 제거 수 :\")\n",
    "# print(removal_stats[['제거수']])\n",
    "\n",
    "# # 결과 CSV 저장\n",
    "# daily_filtered.to_csv(f\"{item_nm}/{item_nm}_이상치제거_일별기준.csv\", index=False, encoding='cp949')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "d4339bba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 총 제거된 이상치 수: 119926\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# CSV 파일 불러오기\n",
    "df = pd.read_csv(f\"{item_nm}/{item_nm}요약데이터_기상.csv\", encoding='cp949')\n",
    "df['연월일'] = pd.to_datetime(df['연월일'])\n",
    "\n",
    "# 주차(월요일 시작) 컬럼 생성\n",
    "df['주차시작'] = df['연월일'].apply(lambda d: d - pd.Timedelta(days=d.weekday()))\n",
    "df['주차끝'] = df['주차시작'] + pd.Timedelta(days=6)\n",
    "df['주차'] = df['주차시작'].dt.strftime('%Y-%m-%d') + '~' + df['주차끝'].dt.strftime('%Y-%m-%d')\n",
    "\n",
    "# 국산/수입산 분리\n",
    "df_korean = df[df['직팜산지코드'] != 2000].copy()\n",
    "df_imported = df[df['직팜산지코드'] == 2000].copy()\n",
    "\n",
    "# 이상치 제거 함수\n",
    "def remove_outliers_iqr(group, column):\n",
    "    if len(group) < 4:\n",
    "        return group\n",
    "    q1 = group[column].quantile(0.25)\n",
    "    q3 = group[column].quantile(0.75)\n",
    "    iqr = q3 - q1\n",
    "    lower = q1 - 1.5 * iqr\n",
    "    upper = q3 + 1.5 * iqr\n",
    "    return group[(group[column] >= lower) & (group[column] <= upper)]\n",
    "\n",
    "# 국산에 대해서만 이상치 제거\n",
    "filtered_korean = (\n",
    "    df_korean.groupby('주차', group_keys=False)\n",
    "    .apply(remove_outliers_iqr, column='평균단가(원)')\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "df_imported = df_imported.reset_index(drop=True)\n",
    "\n",
    "# 제거 개수 계산\n",
    "original_counts = df_korean.groupby('주차').size().rename('원래수')\n",
    "filtered_counts = filtered_korean.groupby('주차').size().rename('제거후수')\n",
    "removal_stats = pd.concat([original_counts, filtered_counts], axis=1).fillna(0).astype(int)\n",
    "removal_stats['제거수'] = removal_stats['원래수'] - removal_stats['제거후수']\n",
    "total_removed = removal_stats['제거수'].sum()\n",
    "\n",
    "# 출력\n",
    "print(\"✅ 총 제거된 이상치 수:\", total_removed)\n",
    "\n",
    "# 국산(이상치 제거됨) + 수입산 결합\n",
    "weekly_filtered = pd.concat([filtered_korean, df_imported], ignore_index=True)\n",
    "\n",
    "# 컬럼 정리\n",
    "weekly_filtered = weekly_filtered[['주차'] + [col for col in weekly_filtered.columns if col != '주차']]\n",
    "weekly_filtered = weekly_filtered.drop(columns=['주차시작', '주차끝'], errors='ignore')\n",
    "\n",
    "# 연월일 기준 정렬\n",
    "weekly_filtered = weekly_filtered.sort_values(by='연월일').reset_index(drop=True)\n",
    "\n",
    "# 결과 CSV 저장\n",
    "weekly_filtered.to_csv(f\"{item_nm}/{item_nm}_이상치제거_주간기준.csv\", index=False, encoding='cp949')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "0a9d3740",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 연월일이 모두 제거된 날짜 수: 0\n",
      "📌 연월일이 모두 제거된 날짜 목록: []\n",
      "📆 len<4 또는 날짜가 제거된 주차 수: 0\n",
      "📅 해당 주차 목록: []\n"
     ]
    }
   ],
   "source": [
    "small_group_weeks = df_korean.groupby('주차').filter(lambda g: len(g) < 4)['주차'].unique()\n",
    "\n",
    "# 2. '연월일' 단위로 제거된 날짜 판별\n",
    "original_dates = set(df_korean['연월일'].unique())\n",
    "filtered_dates = set(filtered_korean['연월일'].unique())\n",
    "removed_dates = original_dates - filtered_dates  # 제거되어 아예 사라진 날짜\n",
    "\n",
    "# 3. 해당 날짜가 어느 주차에 속했는지 매핑\n",
    "removed_rows = df_korean[df_korean['연월일'].isin(removed_dates)]\n",
    "removed_rows = removed_rows[['연월일', '주차']].drop_duplicates()\n",
    "\n",
    "# 4. 조건 통합: \"문제성 있는 날짜 및 주차\"\n",
    "problematic_dates = removed_rows['연월일'].tolist()\n",
    "problematic_weeks = sorted(set(small_group_weeks).union(set(removed_rows['주차'])))\n",
    "\n",
    "# 5. 결과 출력\n",
    "print(\"⚠️ 연월일이 모두 제거된 날짜 수:\", len(problematic_dates))\n",
    "print(\"📌 연월일이 모두 제거된 날짜 목록:\", problematic_dates)\n",
    "print(\"📆 len<4 또는 날짜가 제거된 주차 수:\", len(problematic_weeks))\n",
    "print(\"📅 해당 주차 목록:\", problematic_weeks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "ce77d12f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# 이상치 제거 후 파일 불러오기\n",
    "df = pd.read_csv(f\"{item_nm}/{item_nm}_이상치제거_주간기준.csv\", encoding='cp949')\n",
    "\n",
    "# 국산만 기준으로 주간 평균 단가 계산 (df_korean 없이)\n",
    "weekly_avg = df[df['직팜산지코드'] != 2000].groupby('주차')['평균단가(원)'].mean().rename('주간평균단가(원)')\n",
    "\n",
    "# 병합\n",
    "df = df.merge(weekly_avg, on='주차', how='left')\n",
    "\n",
    "# 등급 부여\n",
    "df['등급이름'] = np.select(\n",
    "    condlist=[\n",
    "        (df['직팜산지코드'] != 2000) & (df['평균단가(원)'] > df['주간평균단가(원)'] * 1.3),\n",
    "        (df['직팜산지코드'] != 2000) & (df['평균단가(원)'] > df['주간평균단가(원)'] * 0.7) & (df['평균단가(원)'] <= df['주간평균단가(원)'] * 1.3),\n",
    "        (df['직팜산지코드'] != 2000) & (df['평균단가(원)'] <= df['주간평균단가(원)'] * 0.7),\n",
    "        (df['직팜산지코드'] == 2000)\n",
    "    ],\n",
    "    choicelist=['고', '중', '저', '수입산'],\n",
    "    default='등급불명'\n",
    ")\n",
    "\n",
    "# 컬럼 정리\n",
    "cols = list(df.columns)\n",
    "for col in ['주간평균단가(원)', '등급이름']:\n",
    "    if col in cols:\n",
    "        cols.remove(col)\n",
    "\n",
    "idx_price = cols.index('평균단가(원)') if '평균단가(원)' in cols else - 1\n",
    "idx_total = cols.index('총금액(원)') if '총금액(원)' in cols else - 1\n",
    "\n",
    "if idx_price != -1:\n",
    "    cols.insert(idx_price + 1, '주간평균단가(원)')\n",
    "if idx_total != -1:\n",
    "    cols.insert(idx_total, '등급이름')\n",
    "\n",
    "df = df[cols]\n",
    "\n",
    "df.to_csv(f\"{item_nm}/{item_nm}_이상치제거_주간기준_등급이름.csv\", index=False, encoding='cp949')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "fc4503d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 등급포함 CSV 불러오기\n",
    "df = pd.read_csv(f\"{item_nm}/{item_nm}_이상치제거_주간기준_등급이름.csv\", encoding='cp949')\n",
    "\n",
    "# 등급이름 → 등급코드 매핑\n",
    "grade_map = {\n",
    "    '고': 11,\n",
    "    '중': 12,\n",
    "    '저': 13,\n",
    "    '수입산': 20,\n",
    "    '등급불명': 99\n",
    "}\n",
    "\n",
    "# 등급코드 컬럼 생성\n",
    "df['등급코드'] = df['등급이름'].map(grade_map)\n",
    "\n",
    "# 등급이름 앞에 등급코드 삽입\n",
    "cols = list(df.columns)\n",
    "if '등급이름' in cols and '등급코드' in cols:\n",
    "    cols.remove('등급코드')\n",
    "    idx = cols.index('등급이름')\n",
    "    cols.insert(idx, '등급코드')\n",
    "    df = df[cols]\n",
    "\n",
    "# 결과 저장\n",
    "df.to_csv(f\"{item_nm}/{item_nm}_이상치제거_주간기준_등급코드.csv\", index=False, encoding='cp949')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f07d24cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 1. 두 파일 불러오기\n",
    "df = pd.read_csv(f\"EDA/{item_nm}(EDA용)_스케일링만.csv\", encoding=\"cp949\")\n",
    "df_ext = pd.read_csv(\"표준코드/factor_external_weekly.csv\", encoding=\"cp949\")\n",
    "\n",
    "columns_to_drop = [\"holiday_flag\", \"holiday_score\", \"grow_score\"]\n",
    "df = df.drop(columns=columns_to_drop, errors=\"ignore\")\n",
    "\n",
    "# 2. factor_external_weekly에서 weekno → year, week 분리\n",
    "if 'weekno' in df_ext.columns:\n",
    "    df_ext['year'] = df_ext['weekno'].astype(str).str[:4].astype(int)\n",
    "    df_ext['week'] = df_ext['weekno'].astype(str).str[4:].astype(int)\n",
    "    df_ext.drop(columns=['weekno'], inplace=True)\n",
    "\n",
    "# 3. item_code가 1101인 데이터만 필터링\n",
    "df_ext_filtered = df_ext[df_ext['item_code'] == item_cd]\n",
    "    \n",
    "# 4. 중복 제거 (year, week 기준)\n",
    "df_ext_unique = df_ext_filtered.drop_duplicates(subset=['year', 'week'])\n",
    "\n",
    "# 5. 병합 (year, week 기준)\n",
    "df_merged = pd.merge(\n",
    "    df,\n",
    "    df_ext_unique[['year', 'week', 'holiday_flag', 'holiday_score', 'grow_score']],\n",
    "    on=['year', 'week'],\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# 6. '평균단가(원)' 왼쪽에 삽입\n",
    "price_col_index = df_merged.columns.get_loc('평균단가(원)')\n",
    "for col in ['grow_score', 'holiday_score', 'holiday_flag']:\n",
    "    if col in df_merged.columns:\n",
    "        df_merged.insert(price_col_index, col, df_merged.pop(col))\n",
    "\n",
    "# 7. 결과 저장\n",
    "df_merged.to_csv(f\"EDA/{item_nm}(EDA용)_스케일링만_병합.csv\", index=False, encoding=\"cp949\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99c4a9f8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-dl-nlp",
   "language": "python",
   "name": "ml-dl-nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
