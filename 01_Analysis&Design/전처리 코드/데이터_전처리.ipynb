{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5a1cdcaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "item_nm = 'ë°©ìš¸í† ë§ˆí† '"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5a849626",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "\n",
    "# ê¸°ë³¸ íŒŒì¼ ê²½ë¡œ\n",
    "base_path = f\"{item_nm}/ìœ í†µê³µì‚¬_ë„ë§¤ì‹œì¥_{item_nm}.csv\"\n",
    "\n",
    "# retry íŒŒì¼ ëª©ë¡ ìˆ˜ì§‘\n",
    "retry_paths = glob.glob(f\"{item_nm}/ìœ í†µê³µì‚¬_retry_{item_nm}_*.csv\")\n",
    "\n",
    "# ê¸°ë³¸ íŒŒì¼ ì½ê¸°\n",
    "df_list = [pd.read_csv(base_path, encoding=\"cp949\", low_memory=False)]\n",
    "\n",
    "# retry íŒŒì¼ë“¤ ì½ê¸° (ìˆì„ ê²½ìš°ì—ë§Œ)\n",
    "for path in retry_paths:\n",
    "    df_list.append(pd.read_csv(path, encoding=\"cp949\", low_memory=False))\n",
    "\n",
    "# ë³‘í•©\n",
    "df = pd.concat(df_list, ignore_index=True)\n",
    "\n",
    "# ì¤‘ë³µ ì œê±° (ì „ì²´ í–‰ ê¸°ì¤€ ë˜ëŠ” ì£¼ìš” ì—´ ê¸°ì¤€)\n",
    "df = df.drop_duplicates()\n",
    "\n",
    "# plor_cdê°€ ë¬¸ìì—´ì´ ì•„ë‹ ê°€ëŠ¥ì„± ëŒ€ë¹„\n",
    "df['plor_cd'] = df['plor_cd'].fillna('').astype(str)\n",
    "\n",
    "pattern = r'^[^0-9]+$'\n",
    "\n",
    "condition = (\n",
    "    df['totprc'].isna() | (df['totprc'] <= 0) |\n",
    "    df['unit_tot_qty'].isna() | (df['unit_tot_qty'] <= 0) |\n",
    "    df['plor_cd'].str.strip().isin(['0', '0.0']) |\n",
    "    df['plor_cd'].str.match(pattern, na=False) |\n",
    "    df['plor_nm'].isna() |\n",
    "    (df['plor_nm'] == 0)\n",
    ")\n",
    "\n",
    "# ì¡°ê±´ì— í•´ë‹¹í•˜ëŠ” í–‰ ì¶”ì¶œ\n",
    "df_filtered = df[~condition]\n",
    "\n",
    "# ê²°ê³¼ ì €ì¥\n",
    "df_filtered.to_csv(f\"{item_nm}/ìœ í†µê³µì‚¬_ë„ë§¤ì‹œì¥_{item_nm}_ê²°ì¸¡ì¹˜ì œê±°.csv\", index=False, encoding=\"cp949\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "12c3d58a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 1. íŒŒì¼ ê²½ë¡œ ì„¤ì •\n",
    "input_path = f\"{item_nm}/ìœ í†µê³µì‚¬_ë„ë§¤ì‹œì¥_{item_nm}_ê²°ì¸¡ì¹˜ì œê±°.csv\"\n",
    "output_path = f\"{item_nm}/ìœ í†µê³µì‚¬_ë„ë§¤ì‹œì¥_{item_nm}_í•œê¸€ì»¬ëŸ¼ëª….csv\"\n",
    "\n",
    "# 2. CSV ì „ì²´ë¥¼ ë¬¸ìì—´ë¡œ ë¶ˆëŸ¬ì˜¤ê¸° (ìµœì´ˆ ê²½ê³  ë°©ì§€)\n",
    "df = pd.read_csv(input_path, encoding='cp949', dtype=str)\n",
    "\n",
    "# 3. í•œê¸€ ì»¬ëŸ¼ëª… ì„¤ì •\n",
    "new_columns = [\n",
    "    'í‰ê· ê°€ê²©(ì›)', 'ë²•ì¸ì½”ë“œ', 'ë²•ì¸ì´ë¦„', 'ìƒí’ˆ ëŒ€ë¶„ë¥˜ ì½”ë“œ', 'ìƒí’ˆ ëŒ€ë¶„ë¥˜ ì´ë¦„',\n",
    "    'ìƒí’ˆ ì¤‘ë¶„ë¥˜ ì½”ë“œ', 'ìƒí’ˆ ì¤‘ë¶„ë¥˜ ì´ë¦„', 'ìƒí’ˆ ì†Œë¶„ë¥˜ ì½”ë“œ', 'ìƒí’ˆ ì†Œë¶„ë¥˜ ì´ë¦„',\n",
    "    'ë“±ê¸‰ì½”ë“œ', 'ë“±ê¸‰ì´ë¦„', 'ìµœê³ ê°€(ì›)', 'ìµœì €ê°€(ì›)', 'í¬ì¥ì½”ë“œ', 'í¬ì¥ì´ë¦„',\n",
    "    'ì‚°ì§€ì½”ë“œ', 'ì‚°ì§€ì´ë¦„', 'í¬ê¸°ì½”ë“œ', 'í¬ê¸°ì´ë¦„', 'ì´ê°€ê²©(ì›)', 'ë‚ ì§œ(YYYY-MM-DD)',\n",
    "    'ë§¤ë§¤êµ¬ë¶„', 'ë‹¨ìœ„ì½”ë“œ', 'ë‹¨ìœ„(kg)', 'ë‹¨ìœ„ë¬¼ëŸ‰(kg)', 'ë‹¨ìœ„ì´ë¬¼ëŸ‰(kg)', 'ë„ë§¤ì‹œì¥ì½”ë“œ', 'ë„ë§¤ì‹œì¥ì´ë¦„'\n",
    "]\n",
    "\n",
    "if len(df.columns) != len(new_columns):\n",
    "    raise ValueError(\"ì»¬ëŸ¼ ìˆ˜ê°€ ì¼ì¹˜í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.\")\n",
    "\n",
    "df.columns = new_columns\n",
    "\n",
    "# 4. ë‚ ì§œ ì»¬ëŸ¼ ë³€í™˜\n",
    "df['ë‚ ì§œ(YYYY-MM-DD)'] = pd.to_datetime(df['ë‚ ì§œ(YYYY-MM-DD)'], errors='coerce')\n",
    "\n",
    "# 5. ìˆ«ì ì»¬ëŸ¼ ë³€í™˜\n",
    "numeric_columns = ['í‰ê· ê°€ê²©(ì›)', 'ìµœê³ ê°€(ì›)', 'ìµœì €ê°€(ì›)', 'ì´ê°€ê²©(ì›)', 'ë‹¨ìœ„ë¬¼ëŸ‰(kg)', 'ë‹¨ìœ„ì´ë¬¼ëŸ‰(kg)']\n",
    "for col in numeric_columns:\n",
    "    df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "\n",
    "# 6. í˜¼í•© íƒ€ì… ê²½ê³  ì»¬ëŸ¼ ì²˜ë¦¬: NaNì„ ë¹ˆ ë¬¸ìì—´ë¡œ, ëª¨ë‘ ë¬¸ìì—´í™”\n",
    "for col in ['í¬ì¥ì´ë¦„', 'ì‚°ì§€ì´ë¦„', 'í¬ê¸°ì´ë¦„']:\n",
    "    df[col] = df[col].fillna('').astype(str)\n",
    "\n",
    "# 7. CSV ì €ì¥ (ì™„ì „ ì •ë¦¬ëœ ìƒíƒœ)\n",
    "df.to_csv(output_path, index=False, encoding='cp949')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0add8419",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_7484\\4122489021.py:8: DtypeWarning: Columns (9,15,17) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(input_path, encoding='cp949')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# íŒŒì¼ ê²½ë¡œ\n",
    "input_path = f\"{item_nm}/ìœ í†µê³µì‚¬_ë„ë§¤ì‹œì¥_{item_nm}_í•œê¸€ì»¬ëŸ¼ëª….csv\"\n",
    "output_path = f\"{item_nm}/ìœ í†µê³µì‚¬_{item_nm}_ìš”ì•½ë°ì´í„°.csv\"\n",
    "\n",
    "# CSV íŒŒì¼ ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "df = pd.read_csv(input_path, encoding='cp949')\n",
    "\n",
    "selected_columns = ['ë‚ ì§œ(YYYY-MM-DD)', 'ìƒí’ˆ ì¤‘ë¶„ë¥˜ ì´ë¦„', 'ë“±ê¸‰ì´ë¦„', 'ì´ê°€ê²©(ì›)', 'ë‹¨ìœ„ì´ë¬¼ëŸ‰(kg)', 'ì‚°ì§€ì½”ë“œ', 'ì‚°ì§€ì´ë¦„']\n",
    "df_selected = df[selected_columns]\n",
    "\n",
    "# ìƒˆ CSVë¡œ ì €ì¥\n",
    "df_selected.to_csv(output_path, index=False, encoding='cp949')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d757a981",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_7484\\3299644001.py:5: DtypeWarning: Columns (5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(f\"{item_nm}/ìœ í†µê³µì‚¬_{item_nm}_ìš”ì•½ë°ì´í„°.csv\", encoding='cp949')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì •ì œëœ ë°ì´í„°ê°€ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤: ë°©ìš¸í† ë§ˆí† /ìœ í†µê³µì‚¬_ë°©ìš¸í† ë§ˆí† _ìš”ì•½ë°ì´í„°_ì •ì œ.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# CSV íŒŒì¼ ë¡œë“œ\n",
    "df = pd.read_csv(f\"{item_nm}/ìœ í†µê³µì‚¬_{item_nm}_ìš”ì•½ë°ì´í„°.csv\", encoding='cp949')\n",
    "\n",
    "# ìƒí’ˆ ì¤‘ë¶„ë¥˜ ì´ë¦„ ê²°ì¸¡ì¹˜ ì²˜ë¦¬\n",
    "df['ìƒí’ˆ ì¤‘ë¶„ë¥˜ ì´ë¦„'] = df['ìƒí’ˆ ì¤‘ë¶„ë¥˜ ì´ë¦„'].replace('', pd.NA).fillna(item_nm)\n",
    "\n",
    "# ì‚°ì§€ì½”ë“œ ì •ì œ í•¨ìˆ˜ (ë¬¸ì â†’ 0, ì•ìë¦¬ 0 ì œê±°, 6ìë¦¬ ë§ì¶¤)\n",
    "def clean_origin_code_backpad(code):\n",
    "    code_str = str(code).strip()\n",
    "    replaced = re.sub(r'\\D', '0', code_str)      # ë¬¸ì â†’ 0\n",
    "    stripped = replaced.lstrip('0')              # ì•ìª½ 0 ì œê±°\n",
    "    if not stripped:  # ëª¨ë‘ 0ì´ê±°ë‚˜ ì œê±° ê²°ê³¼ ì—†ìŒ\n",
    "        stripped = '0'\n",
    "    return stripped[:6].ljust(6, '0')            # ì• 6ìë¦¬ + ë’¤ 0 íŒ¨ë”©\n",
    "\n",
    "# ì ìš©\n",
    "df['ì‚°ì§€ì½”ë“œ'] = df['ì‚°ì§€ì½”ë“œ'].apply(clean_origin_code_backpad)\n",
    "\n",
    "# ì €ì¥\n",
    "output_path = f\"{item_nm}/ìœ í†µê³µì‚¬_{item_nm}_ìš”ì•½ë°ì´í„°_ì •ì œ.csv\"\n",
    "df.to_csv(output_path, index=False, encoding='cp949')\n",
    "\n",
    "print(f\"ì •ì œëœ ë°ì´í„°ê°€ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤: {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "76c211d5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ë‚ ì§œ(YYYY-MM-DD)    0\n",
       "ìƒí’ˆ ì¤‘ë¶„ë¥˜ ì´ë¦„         0\n",
       "ë“±ê¸‰ì´ë¦„              0\n",
       "ì´ê°€ê²©(ì›)            0\n",
       "ë‹¨ìœ„ì´ë¬¼ëŸ‰(kg)         0\n",
       "ì‚°ì§€ì½”ë“œ              0\n",
       "ì‚°ì§€ì´ë¦„              0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(f\"{item_nm}/ìœ í†µê³µì‚¬_{item_nm}_ìš”ì•½ë°ì´í„°_ì •ì œ.csv\", encoding = 'cp949')\n",
    "\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ddb059fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# íŒŒì¼ ê²½ë¡œ ì„¤ì •\n",
    "file_path = f\"{item_nm}/ìœ í†µê³µì‚¬_{item_nm}_ìš”ì•½ë°ì´í„°_ì •ì œ.csv\"\n",
    "\n",
    "# CSV íŒŒì¼ ì½ê¸° (ê²½ê³  ë°©ì§€ë¥¼ ìœ„í•´ low_memory=False ì‚¬ìš©)\n",
    "df = pd.read_csv(file_path, encoding=\"cp949\", low_memory=False)\n",
    "\n",
    "# ì‚°ì§€ì½”ë“œê°€ ë¬¸ìì—´ë¡œ ì²˜ë¦¬ë˜ë„ë¡ ë³€í™˜\n",
    "df['ì‚°ì§€ì½”ë“œ'] = df['ì‚°ì§€ì½”ë“œ'].fillna('').astype(str)\n",
    "\n",
    "# í•„í„°ë§ ì¡°ê±´: totprc ë˜ëŠ” unit_tot_qtyê°€ NaNì´ê±°ë‚˜ 0ì¸ ê²½ìš°\n",
    "pattern = r'^[^0-9]+$'\n",
    "\n",
    "condition = (\n",
    "    (df['ì‚°ì§€ì½”ë“œ'] == '') |\n",
    "    (df['ì‚°ì§€ì½”ë“œ'].str.strip() == \"0\") |\n",
    "    (df['ì‚°ì§€ì½”ë“œ'].str.strip() == \"0.0\")\n",
    "#     df['plor_cd'].str.match(pattern, na=False)) \n",
    "#     (df['plor_nm'].isna() | (df['plor_nm'] == 0))\n",
    ")\n",
    "\n",
    "# ì¡°ê±´ì— í•´ë‹¹í•˜ëŠ” í–‰ ì¶”ì¶œ\n",
    "df_filtered = df[condition]\n",
    "\n",
    "# ê²°ê³¼ ì €ì¥\n",
    "df_filtered.to_csv(f\"{item_nm}/ê²°ì¸¡ì¹˜_{item_nm}.csv\", index=False, encoding=\"cp949\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "92382234",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 1. íŒŒì¼ ê²½ë¡œ ì„¤ì •\n",
    "summary_path = f\"{item_nm}/ìœ í†µê³µì‚¬_{item_nm}_ìš”ì•½ë°ì´í„°_ì •ì œ.csv\"\n",
    "region_code_path = \"í‘œì¤€ì½”ë“œ/ì‚°ì§€ì½”ë“œ_ì§íŒœ.csv\"\n",
    "\n",
    "# 2. CSV ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "summary_df = pd.read_csv(summary_path, encoding='cp949')\n",
    "region_df = pd.read_csv(region_code_path, encoding='cp949')\n",
    "\n",
    "# 3. ì‚°ì§€ì½”ë“œ ë²”ìœ„ íŒŒì‹± í•¨ìˆ˜\n",
    "def parse_code_range(code_str):\n",
    "    if \"~\" in code_str:\n",
    "        start, end = code_str.split(\"~\")\n",
    "    else:\n",
    "        start = end = code_str\n",
    "    return int(start), int(end)\n",
    "\n",
    "# 4. ì‚°ì§€ì½”ë“œ ë²”ìœ„ ìˆ«ì ì»¬ëŸ¼ ìƒì„±\n",
    "region_df[['start_code', 'end_code']] = region_df['ì‚°ì§€ì½”ë“œ'].apply(\n",
    "    lambda x: pd.Series(parse_code_range(x))\n",
    ")\n",
    "\n",
    "# 5. ì‚°ì§€ì½”ë“œ â†’ ì§íŒœì‚°ì§€ì½”ë“œ/ì´ë¦„ ë§¤í•‘ í…Œì´ë¸” í™•ì¥\n",
    "expanded_rows = []\n",
    "for _, row in region_df.iterrows():\n",
    "    for code in range(row['start_code'], row['end_code'] + 1):\n",
    "        expanded_rows.append({\n",
    "            'ì‚°ì§€ì½”ë“œ': code,\n",
    "            'ì§íŒœì‚°ì§€ì½”ë“œ': row['ì§íŒœì‚°ì§€ì½”ë“œ'],\n",
    "            'ì§íŒœì‚°ì§€ì´ë¦„': row['ì§íŒœì‚°ì§€ì´ë¦„']\n",
    "        })\n",
    "expanded_map_df = pd.DataFrame(expanded_rows)\n",
    "\n",
    "# 6. ìš”ì•½ ë°ì´í„° ì‚°ì§€ì½”ë“œ ì •ìˆ˜í˜•ìœ¼ë¡œ ë³€í™˜\n",
    "summary_df['ì‚°ì§€ì½”ë“œ'] = pd.to_numeric(summary_df['ì‚°ì§€ì½”ë“œ'], errors='coerce').astype('Int64')\n",
    "summary_df = summary_df[summary_df['ì‚°ì§€ì½”ë“œ'].notna()].copy()\n",
    "summary_df['ì‚°ì§€ì½”ë“œ'] = summary_df['ì‚°ì§€ì½”ë“œ'].astype(int)\n",
    "\n",
    "# 7. ì§íŒœ ì»¬ëŸ¼ ì œê±° í›„ ë³‘í•©\n",
    "summary_df = summary_df.drop(columns=['ì§íŒœì‚°ì§€ì½”ë“œ', 'ì§íŒœì‚°ì§€ì´ë¦„'], errors='ignore')\n",
    "summary_df = pd.merge(summary_df, expanded_map_df, on='ì‚°ì§€ì½”ë“œ', how='left')\n",
    "\n",
    "# 8. ì‚°ì§€ì´ë¦„ì´ ëˆ„ë½ëœ ê²½ìš° ì§íŒœì‚°ì§€ì´ë¦„ìœ¼ë¡œ ë³´ì™„\n",
    "summary_df['ì‚°ì§€ì´ë¦„'] = summary_df['ì‚°ì§€ì´ë¦„'].fillna(summary_df['ì§íŒœì‚°ì§€ì´ë¦„'])\n",
    "\n",
    "\n",
    "# 9. ê²°ê³¼ ì €ì¥\n",
    "summary_df.to_csv(f\"{item_nm}/{item_nm}ìš”ì•½ë°ì´í„°_ì§íŒœì‚°ì§€ì •ë¦¬.csv\", index=False, encoding='cp949')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e5467f89",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ë‚ ì§œ(YYYY-MM-DD)    0\n",
       "ìƒí’ˆ ì¤‘ë¶„ë¥˜ ì´ë¦„         0\n",
       "ë“±ê¸‰ì´ë¦„              0\n",
       "ì´ê°€ê²©(ì›)            0\n",
       "ë‹¨ìœ„ì´ë¬¼ëŸ‰(kg)         0\n",
       "ì‚°ì§€ì½”ë“œ              0\n",
       "ì‚°ì§€ì´ë¦„              0\n",
       "ì§íŒœì‚°ì§€ì½”ë“œ            0\n",
       "ì§íŒœì‚°ì§€ì´ë¦„            0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(f\"{item_nm}/{item_nm}ìš”ì•½ë°ì´í„°_ì§íŒœì‚°ì§€ì •ë¦¬.csv\", encoding = 'cp949')\n",
    "\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "827857ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ë“±ê¸‰ì´ë¦„ ìˆ˜ì • ì™„ë£Œ: ë°©ìš¸í† ë§ˆí† /ë°©ìš¸í† ë§ˆí† ìš”ì•½ë°ì´í„°_ì§íŒœì •ë¦¬.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# CSV íŒŒì¼ ë¡œë“œ\n",
    "df = pd.read_csv(f\"{item_nm}/{item_nm}ìš”ì•½ë°ì´í„°_ì§íŒœì‚°ì§€ì •ë¦¬.csv\", encoding='cp949')\n",
    "\n",
    "# ë“±ê¸‰ì´ë¦„ì´ NaN ë˜ëŠ” ê³µë°±ì´ê±°ë‚˜ '.'ì¸ ê²½ìš° 'ë³´í†µ'ìœ¼ë¡œ ëŒ€ì²´\n",
    "df['ë“±ê¸‰ì´ë¦„'] = df['ë“±ê¸‰ì´ë¦„'].replace('.', 'ë³´í†µ').fillna('ë³´í†µ')\n",
    "df['ë“±ê¸‰ì´ë¦„'] = df['ë“±ê¸‰ì´ë¦„'].replace(r'^\\s*$', 'ë³´í†µ', regex=True)\n",
    "\n",
    "# 'íŠ¹', 'ìƒ', 'ë³´í†µ' ì™¸ì˜ ê°’ì€ ëª¨ë‘ 'í•˜'ë¡œ ë³€ê²½\n",
    "df['ë“±ê¸‰ì´ë¦„'] = df['ë“±ê¸‰ì´ë¦„'].apply(lambda x: x if x in ['íŠ¹', 'ìƒ', 'ë³´í†µ'] else 'í•˜')\n",
    "\n",
    "# ì €ì¥\n",
    "output_path = f\"{item_nm}/{item_nm}ìš”ì•½ë°ì´í„°_ì§íŒœì •ë¦¬.csv\"\n",
    "df.to_csv(output_path, index=False, encoding='cp949')\n",
    "\n",
    "print(f\"ë“±ê¸‰ì´ë¦„ ìˆ˜ì • ì™„ë£Œ: {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d0c425a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ê²°ì¸¡ì¹˜ í¬í•¨ í–‰ 0ê°œë¥¼ 'ë°©ìš¸í† ë§ˆí† /ë°©ìš¸í† ë§ˆí† _ê²°ì¸¡ì¹˜í¬í•¨í–‰.csv'ë¡œ ì €ì¥í–ˆìŠµë‹ˆë‹¤.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# íŒŒì¼ ê²½ë¡œì™€ ì¸ì½”ë”©ìœ¼ë¡œ ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "df = pd.read_csv(f\"{item_nm}/{item_nm}ìš”ì•½ë°ì´í„°_ì§íŒœì •ë¦¬.csv\", encoding='cp949')\n",
    "\n",
    "# ê²°ì¸¡ì¹˜ê°€ í•˜ë‚˜ë¼ë„ ìˆëŠ” í–‰ë§Œ ì¶”ì¶œ\n",
    "df_na = df[df.isna().any(axis=1)]\n",
    "\n",
    "# ê²°ê³¼ ì €ì¥\n",
    "output_path = f\"{item_nm}/{item_nm}_ê²°ì¸¡ì¹˜í¬í•¨í–‰.csv\"\n",
    "df_na.to_csv(output_path, index=False, encoding='cp949')\n",
    "\n",
    "print(f\"ê²°ì¸¡ì¹˜ í¬í•¨ í–‰ {len(df_na)}ê°œë¥¼ '{output_path}'ë¡œ ì €ì¥í–ˆìŠµë‹ˆë‹¤.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5ca61450",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ì™„ë£Œ] ëˆ„ë½ëœ ë‚ ì§œ 694ê±´ â†’ ëˆ„ë½ë‚ ì§œ_ë°°ì¶”.csv ì €ì¥ë¨\n"
     ]
    }
   ],
   "source": [
    "# # ëˆ„ë½ ë‚ ì§œ í™•ì¸\n",
    "\n",
    "# import pandas as pd\n",
    "\n",
    "# # 1. ë‚ ì§œ ë²”ìœ„ ìƒì„±\n",
    "# full_dates = pd.date_range(start=\"2018-01-03\", end=\"2025-05-31\")\n",
    "\n",
    "# # 2. CSV íŒŒì¼ì—ì„œ ë‚ ì§œ ì»¬ëŸ¼ ì½ê¸°\n",
    "# df = pd.read_csv(f\"{item_nm}/{item_nm}ìš”ì•½ë°ì´í„°_ì§íŒœì •ë¦¬.csv\", encoding='cp949')\n",
    "\n",
    "\n",
    "# # 3. ë‚ ì§œ ì»¬ëŸ¼ íŒŒì‹± (ì˜ˆ: ì»¬ëŸ¼ëª…ì´ 'ë‚ ì§œ'ì¼ ê²½ìš°)\n",
    "# df['ë‚ ì§œ(YYYY-MM-DD)'] = pd.to_datetime(df['ë‚ ì§œ(YYYY-MM-DD)'])\n",
    "\n",
    "# # 4. ì¡´ì¬í•˜ëŠ” ë‚ ì§œ ëª©ë¡\n",
    "# existing_dates = pd.Series(df['ë‚ ì§œ(YYYY-MM-DD)'].unique())\n",
    "\n",
    "# # 5. ëˆ„ë½ ë‚ ì§œ ê³„ì‚°\n",
    "# missing_dates = full_dates[~full_dates.isin(existing_dates)]\n",
    "\n",
    "# # 6. ê²°ê³¼ DataFrame (ì»¬ëŸ¼ëª… ì§€ì •)\n",
    "# missing_df = pd.DataFrame({'ë‚ ì§œ(YYYY-MM-DD)': missing_dates.strftime(\"%Y-%m-%d\")})\n",
    "\n",
    "# # 7. CSV ì €ì¥ (cp949 ì¸ì½”ë”©)\n",
    "# missing_df.to_csv(f\"{item_nm}/ëˆ„ë½ë‚ ì§œ_{item_nm}.csv\", index=False, encoding=\"cp949\")\n",
    "\n",
    "# print(f\"[ì™„ë£Œ] ëˆ„ë½ëœ ë‚ ì§œ {len(missing_df)}ê±´ â†’ ëˆ„ë½ë‚ ì§œ_{item_nm}.csv ì €ì¥ë¨\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c96b523e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“¦ ì‹¤íŒ¨ í•­ëª© ì¬ì‹œë„ ì‹œì‘: ë°°ì¶”\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "ì¬ì‹œë„ ë‚ ì§œ ì§„í–‰:   0%|                                                                        | 0/694 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "â–¶ï¸ ìš”ì²­ ì‹œë„: ë°°ì¶” | ì‹œì¥ì½”ë“œ: ë„ë§¤ì‹œì¥ì½”ë“œ | ë‚ ì§œ: 2018-01-07 | í˜ì´ì§€: 1 | ì¬ì‹œë„: 1\n",
      "âš ï¸ ê±°ë˜ ë°ì´í„° ì—†ìŒ\n",
      "â–¶ï¸ ìš”ì²­ ì‹œë„: ë°°ì¶” | ì‹œì¥ì½”ë“œ: 110008 | ë‚ ì§œ: 2018-01-07 | í˜ì´ì§€: 1 | ì¬ì‹œë„: 1\n",
      "âš ï¸ ê±°ë˜ ë°ì´í„° ì—†ìŒ\n",
      "â–¶ï¸ ìš”ì²­ ì‹œë„: ë°°ì¶” | ì‹œì¥ì½”ë“œ: 210001 | ë‚ ì§œ: 2018-01-07 | í˜ì´ì§€: 1 | ì¬ì‹œë„: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "ì¬ì‹œë„ ë‚ ì§œ ì§„í–‰:   0%|                                                                        | 0/694 [00:03<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ ê±°ë˜ ë°ì´í„° ì—†ìŒ\n",
      "â–¶ï¸ ìš”ì²­ ì‹œë„: ë°°ì¶” | ì‹œì¥ì½”ë“œ: 210005 | ë‚ ì§œ: 2018-01-07 | í˜ì´ì§€: 1 | ì¬ì‹œë„: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[24], line 71\u001b[0m\n\u001b[0;32m     59\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mâ–¶ï¸ ìš”ì²­ ì‹œë„: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mitem_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m | ì‹œì¥ì½”ë“œ: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmcode\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m | ë‚ ì§œ: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdate_str\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m | í˜ì´ì§€: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpage_no\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m | ì¬ì‹œë„: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mretry_count\u001b[38;5;250m \u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     61\u001b[0m params \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m     62\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mserviceKey\u001b[39m\u001b[38;5;124m'\u001b[39m: API_KEY,\n\u001b[0;32m     63\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpageNo\u001b[39m\u001b[38;5;124m'\u001b[39m: page_no,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcond[gds_mclsf_cd::EQ]\u001b[39m\u001b[38;5;124m'\u001b[39m: MID\n\u001b[0;32m     69\u001b[0m }\n\u001b[1;32m---> 71\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mrequests\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mBASE_URL\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverify\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     72\u001b[0m content_type \u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39mheaders\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mContent-Type\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     73\u001b[0m time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m1.0\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\ml-dl-nlp\\lib\\site-packages\\requests\\api.py:73\u001b[0m, in \u001b[0;36mget\u001b[1;34m(url, params, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mget\u001b[39m(url, params\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m     63\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Sends a GET request.\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \n\u001b[0;32m     65\u001b[0m \u001b[38;5;124;03m    :param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     70\u001b[0m \u001b[38;5;124;03m    :rtype: requests.Response\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 73\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m request(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mget\u001b[39m\u001b[38;5;124m\"\u001b[39m, url, params\u001b[38;5;241m=\u001b[39mparams, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\ml-dl-nlp\\lib\\site-packages\\requests\\api.py:59\u001b[0m, in \u001b[0;36mrequest\u001b[1;34m(method, url, **kwargs)\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;66;03m# By using the 'with' statement we are sure the session is closed, thus we\u001b[39;00m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;66;03m# avoid leaving sockets open which can trigger a ResourceWarning in some\u001b[39;00m\n\u001b[0;32m     57\u001b[0m \u001b[38;5;66;03m# cases, and look like a memory leak in others.\u001b[39;00m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m sessions\u001b[38;5;241m.\u001b[39mSession() \u001b[38;5;28;01mas\u001b[39;00m session:\n\u001b[1;32m---> 59\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m session\u001b[38;5;241m.\u001b[39mrequest(method\u001b[38;5;241m=\u001b[39mmethod, url\u001b[38;5;241m=\u001b[39murl, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\ml-dl-nlp\\lib\\site-packages\\requests\\sessions.py:589\u001b[0m, in \u001b[0;36mSession.request\u001b[1;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[0;32m    584\u001b[0m send_kwargs \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    585\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m\"\u001b[39m: timeout,\n\u001b[0;32m    586\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow_redirects\u001b[39m\u001b[38;5;124m\"\u001b[39m: allow_redirects,\n\u001b[0;32m    587\u001b[0m }\n\u001b[0;32m    588\u001b[0m send_kwargs\u001b[38;5;241m.\u001b[39mupdate(settings)\n\u001b[1;32m--> 589\u001b[0m resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msend(prep, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39msend_kwargs)\n\u001b[0;32m    591\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\ml-dl-nlp\\lib\\site-packages\\requests\\sessions.py:703\u001b[0m, in \u001b[0;36mSession.send\u001b[1;34m(self, request, **kwargs)\u001b[0m\n\u001b[0;32m    700\u001b[0m start \u001b[38;5;241m=\u001b[39m preferred_clock()\n\u001b[0;32m    702\u001b[0m \u001b[38;5;66;03m# Send the request\u001b[39;00m\n\u001b[1;32m--> 703\u001b[0m r \u001b[38;5;241m=\u001b[39m adapter\u001b[38;5;241m.\u001b[39msend(request, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    705\u001b[0m \u001b[38;5;66;03m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[0;32m    706\u001b[0m elapsed \u001b[38;5;241m=\u001b[39m preferred_clock() \u001b[38;5;241m-\u001b[39m start\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\ml-dl-nlp\\lib\\site-packages\\requests\\adapters.py:667\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[1;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[0;32m    664\u001b[0m     timeout \u001b[38;5;241m=\u001b[39m TimeoutSauce(connect\u001b[38;5;241m=\u001b[39mtimeout, read\u001b[38;5;241m=\u001b[39mtimeout)\n\u001b[0;32m    666\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 667\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    668\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    669\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    670\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    671\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    672\u001b[0m \u001b[43m        \u001b[49m\u001b[43mredirect\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    673\u001b[0m \u001b[43m        \u001b[49m\u001b[43massert_same_host\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    674\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    675\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    676\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    677\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    678\u001b[0m \u001b[43m        \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    679\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    681\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (ProtocolError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m    682\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(err, request\u001b[38;5;241m=\u001b[39mrequest)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\ml-dl-nlp\\lib\\site-packages\\urllib3\\connectionpool.py:793\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[0;32m    790\u001b[0m response_conn \u001b[38;5;241m=\u001b[39m conn \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m release_conn \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    792\u001b[0m \u001b[38;5;66;03m# Make the request on the HTTPConnection object\u001b[39;00m\n\u001b[1;32m--> 793\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_request(\n\u001b[0;32m    794\u001b[0m     conn,\n\u001b[0;32m    795\u001b[0m     method,\n\u001b[0;32m    796\u001b[0m     url,\n\u001b[0;32m    797\u001b[0m     timeout\u001b[38;5;241m=\u001b[39mtimeout_obj,\n\u001b[0;32m    798\u001b[0m     body\u001b[38;5;241m=\u001b[39mbody,\n\u001b[0;32m    799\u001b[0m     headers\u001b[38;5;241m=\u001b[39mheaders,\n\u001b[0;32m    800\u001b[0m     chunked\u001b[38;5;241m=\u001b[39mchunked,\n\u001b[0;32m    801\u001b[0m     retries\u001b[38;5;241m=\u001b[39mretries,\n\u001b[0;32m    802\u001b[0m     response_conn\u001b[38;5;241m=\u001b[39mresponse_conn,\n\u001b[0;32m    803\u001b[0m     preload_content\u001b[38;5;241m=\u001b[39mpreload_content,\n\u001b[0;32m    804\u001b[0m     decode_content\u001b[38;5;241m=\u001b[39mdecode_content,\n\u001b[0;32m    805\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mresponse_kw,\n\u001b[0;32m    806\u001b[0m )\n\u001b[0;32m    808\u001b[0m \u001b[38;5;66;03m# Everything went great!\u001b[39;00m\n\u001b[0;32m    809\u001b[0m clean_exit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\ml-dl-nlp\\lib\\site-packages\\urllib3\\connectionpool.py:537\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[1;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[0;32m    535\u001b[0m \u001b[38;5;66;03m# Receive the response from the server\u001b[39;00m\n\u001b[0;32m    536\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 537\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    538\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (BaseSSLError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    539\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_raise_timeout(err\u001b[38;5;241m=\u001b[39me, url\u001b[38;5;241m=\u001b[39murl, timeout_value\u001b[38;5;241m=\u001b[39mread_timeout)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\ml-dl-nlp\\lib\\site-packages\\urllib3\\connection.py:466\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    463\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mresponse\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m HTTPResponse\n\u001b[0;32m    465\u001b[0m \u001b[38;5;66;03m# Get the response from http.client.HTTPConnection\u001b[39;00m\n\u001b[1;32m--> 466\u001b[0m httplib_response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    468\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    469\u001b[0m     assert_header_parsing(httplib_response\u001b[38;5;241m.\u001b[39mmsg)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\ml-dl-nlp\\lib\\http\\client.py:1375\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1373\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1374\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1375\u001b[0m         \u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbegin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1376\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m:\n\u001b[0;32m   1377\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\ml-dl-nlp\\lib\\http\\client.py:318\u001b[0m, in \u001b[0;36mHTTPResponse.begin\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    316\u001b[0m \u001b[38;5;66;03m# read until we get a non-100 response\u001b[39;00m\n\u001b[0;32m    317\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m--> 318\u001b[0m     version, status, reason \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_read_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    319\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m status \u001b[38;5;241m!=\u001b[39m CONTINUE:\n\u001b[0;32m    320\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\ml-dl-nlp\\lib\\http\\client.py:279\u001b[0m, in \u001b[0;36mHTTPResponse._read_status\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    278\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_read_status\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m--> 279\u001b[0m     line \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreadline\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_MAXLINE\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miso-8859-1\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    280\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(line) \u001b[38;5;241m>\u001b[39m _MAXLINE:\n\u001b[0;32m    281\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m LineTooLong(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstatus line\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\ml-dl-nlp\\lib\\socket.py:717\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[1;34m(self, b)\u001b[0m\n\u001b[0;32m    715\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m    716\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 717\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    718\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[0;32m    719\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout_occurred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# # ì‹¤íŒ¨ ë¡œê·¸ ê¸°ë°˜ ë°ì´í„° ì¬ìˆ˜ì§‘\n",
    "# import os\n",
    "# import pandas as pd\n",
    "# import requests\n",
    "# import time\n",
    "# from datetime import datetime\n",
    "# from tqdm import tqdm\n",
    "# import ssl\n",
    "# import warnings\n",
    "# import xml.etree.ElementTree as ET\n",
    "# from requests.packages.urllib3.exceptions import InsecureRequestWarning\n",
    "# from dotenv import load_dotenv\n",
    "\n",
    "# # í™˜ê²½ ë° ê²½ê³  ì„¤ì •\n",
    "# load_dotenv()\n",
    "# warnings.filterwarnings('ignore', category=InsecureRequestWarning)\n",
    "# ssl._create_default_https_context = ssl._create_unverified_context\n",
    "\n",
    "# # ìƒìˆ˜\n",
    "# API_KEY = os.getenv(\"DO_API_KEY\")\n",
    "# BASE_URL = 'http://apis.data.go.kr/B552845/katSale/trades'\n",
    "# item_nm = 'ë°°ì¶”'\n",
    "# ITEM_CODES = {f\"{item_nm}\": \"1001\"}\n",
    "# max_retries = 2  # ì¬ì‹œë„ ìµœëŒ€ íšŸìˆ˜ (1íšŒ ì‹œë„ + 0íšŒ ì¬ì‹œë„)\n",
    "\n",
    "# # ë””ë ‰í† ë¦¬ ì¤€ë¹„\n",
    "# os.makedirs(\"logs\", exist_ok=True)\n",
    "# os.makedirs(\"data\", exist_ok=True)\n",
    "# os.makedirs(\"success\", exist_ok=True)\n",
    "\n",
    "# # ë„ë§¤ì‹œì¥ ì½”ë“œ ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "# df_market = pd.read_csv(\"í‘œì¤€ì½”ë“œ/ë„ë§¤ì‹œì¥_ì½”ë“œ.csv\", encoding=\"cp949\", header=None)\n",
    "# df_market[0] = df_market[0].astype(str)\n",
    "\n",
    "# # ì‹¤íŒ¨ ë¡œê·¸ ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "# fail_df = pd.read_csv(f\"{item_nm}/ëˆ„ë½ë‚ ì§œ_{item_nm}.csv\", encoding=\"cp949\")\n",
    "# fail_dates = pd.to_datetime(fail_df['ë‚ ì§œ(YYYY-MM-DD)']).dt.strftime(\"%Y-%m-%d\")\n",
    "\n",
    "# # ë„ë§¤ì‹œì¥ ë¦¬ìŠ¤íŠ¸\n",
    "# market_list = df_market[[0, 1]].values.tolist()  # (ì‹œì¥ì½”ë“œ, ì‹œì¥ëª…)\n",
    "\n",
    "# for item_name, code in ITEM_CODES.items():\n",
    "#     LARGE = code[:2]\n",
    "#     MID = code[2:]\n",
    "#     data_list = []\n",
    "#     cnt =0\n",
    "\n",
    "#     print(f\"\\nğŸ“¦ ì‹¤íŒ¨ í•­ëª© ì¬ì‹œë„ ì‹œì‘: {item_name}\")\n",
    "#     for date_str in tqdm(fail_dates, desc=\"ì¬ì‹œë„ ë‚ ì§œ ì§„í–‰\"):\n",
    "#         for mcode, market_name in market_list:\n",
    "#             retry_count = 0\n",
    "#             market_success = False\n",
    "\n",
    "#             while retry_count < max_retries:\n",
    "#                 page_no = 1\n",
    "#                 cnt += 1\n",
    "#                 try:\n",
    "#                     while True:\n",
    "#                         print(f\"â–¶ï¸ ìš”ì²­ ì‹œë„: {item_name} | ì‹œì¥ì½”ë“œ: {mcode} | ë‚ ì§œ: {date_str} | í˜ì´ì§€: {page_no} | ì¬ì‹œë„: {retry_count + 1}\")\n",
    "\n",
    "#                         params = {\n",
    "#                             'serviceKey': API_KEY,\n",
    "#                             'pageNo': page_no,\n",
    "#                             'numOfRows': 100,\n",
    "#                             'cond[trd_clcln_ymd::EQ]': date_str,\n",
    "#                             'cond[whsl_mrkt_cd::EQ]': mcode,\n",
    "#                             'cond[gds_lclsf_cd::EQ]': LARGE,\n",
    "#                             'cond[gds_mclsf_cd::EQ]': MID\n",
    "#                         }\n",
    "\n",
    "#                         response = requests.get(BASE_URL, params=params, verify=False, timeout=10)\n",
    "#                         content_type = response.headers.get(\"Content-Type\", \"\")\n",
    "#                         time.sleep(1.0)\n",
    "#                         response_preview = response.text[:500].strip()\n",
    "\n",
    "#                         # ì˜¤ë¥˜ ì²´í¬\n",
    "#                         if \"LIMITED_\" in response_preview:\n",
    "#                             fail_reason = \"âŒ API í˜¸ì¶œ ì œí•œ (LIMITED_ ì‘ë‹µ)\"\n",
    "#                         elif \"SERVICE ERROR\" in response_preview:\n",
    "#                             fail_reason = \"âŒ ì„œë¹„ìŠ¤ ì˜¤ë¥˜ (SERVICE ERROR ì‘ë‹µ)\"\n",
    "#                         elif \"ERROR\" in response_preview.upper():\n",
    "#                             fail_reason = \"âŒ ê¸°íƒ€ ì˜¤ë¥˜ í¬í•¨ (ERROR í‚¤ì›Œë“œ í¬í•¨)\"\n",
    "#                         elif \"TOO MANY REQUESTS\" in response_preview.upper():\n",
    "#                             fail_reason = \"âŒ ìš”ì²­ ê³¼ë‹¤ë¡œ ì¸í•œ ì œí•œ (Too Many Requests)\"\n",
    "#                         else:\n",
    "#                             fail_reason = None\n",
    "\n",
    "#                         if fail_reason:\n",
    "#                             print(f\"â›” {fail_reason} - ì¬ì‹œë„ ëŒ€ê¸° ì¤‘ (2ë¶„)\")\n",
    "#                             log_prefix = f\"logs/retry_failed_{item_name}_{mcode}_{date_str}\"\n",
    "#                             with open(f\"{log_prefix}.html\", \"w\", encoding=\"utf-8\") as f:\n",
    "#                                 f.write(response.text)\n",
    "#                             with open(f\"{log_prefix}_info.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "#                                 f.write(f\"[ì˜¤ë¥˜] {fail_reason}\\n{response_preview}\")\n",
    "#                             retry_count += 1\n",
    "#                             if retry_count >= max_retries:\n",
    "#                                 print(f\"â— ìµœëŒ€ ì¬ì‹œë„ {max_retries}íšŒ ì´ˆê³¼ - ì¤‘ë‹¨\")\n",
    "#                                 break\n",
    "#                             time.sleep(60)\n",
    "#                             continue\n",
    "\n",
    "#                         # ì‘ë‹µ íŒŒì‹±\n",
    "#                         if \"application/json\" in content_type:\n",
    "#                             json_data = response.json()\n",
    "#                             body = json_data.get(\"response\", {}).get(\"body\", {})\n",
    "#                             items = body.get(\"items\", {}).get(\"item\", [])\n",
    "#                             total_count = int(body.get(\"totalCount\", 0))\n",
    "\n",
    "#                         elif \"application/xml\" in content_type or response.text.strip().startswith(\"<\"):\n",
    "#                             root = ET.fromstring(response.text)\n",
    "#                             total_count_el = root.find(\".//totalCount\")\n",
    "#                             total_count = int(total_count_el.text) if total_count_el is not None else 0\n",
    "#                             item_els = root.findall(\".//item\")\n",
    "#                             items = [{el.tag: el.text for el in item} for item in item_els]\n",
    "#                         else:\n",
    "#                             raise ValueError(f\"ì•Œ ìˆ˜ ì—†ëŠ” ì‘ë‹µ í˜•ì‹: {content_type}\")\n",
    "\n",
    "#                         if not items:\n",
    "#                             print(\"âš ï¸ ê±°ë˜ ë°ì´í„° ì—†ìŒ\")\n",
    "#                             market_success = True\n",
    "#                             break\n",
    "\n",
    "#                         data_list.extend(items)\n",
    "\n",
    "#                         if cnt % 10000 == 0:\n",
    "#                             print(f\"ğŸ§ª ì¤‘ê°„ ì €ì¥ ì‹œë„: í˜„ì¬ data_list ê¸¸ì´ = {len(data_list)}\")\n",
    "#                             mid_save_path = f\"{item_nm}/ìœ í†µê³µì‚¬_retry_{item_name}_{datetime.now().strftime('%Y%m%d_%H%M%S')}_mid.csv\"\n",
    "#                             pd.DataFrame(data_list).to_csv(mid_save_path, encoding='cp949', index=False)\n",
    "#                             print(f\"ğŸ’¾ ì¤‘ê°„ ì €ì¥ ì™„ë£Œ: {mid_save_path}\")\n",
    "\n",
    "#                         market_success = True\n",
    "#                         if page_no * 100 >= total_count:\n",
    "#                             print(f\"âœ… ë§ˆì§€ë§‰ í˜ì´ì§€ ë„ë‹¬ (totalCount: {total_count})\")\n",
    "#                             break\n",
    "#                         if page_no > 10:\n",
    "#                             print(\"ğŸš¨ í˜ì´ì§€ 10 ì´ˆê³¼ - ë¬´í•œ ë£¨í”„ ë°©ì§€ë¥¼ ìœ„í•´ ì¤‘ë‹¨\")\n",
    "#                             break\n",
    "\n",
    "#                         page_no += 1\n",
    "#                         time.sleep(1.0)\n",
    "\n",
    "#                     if market_success:\n",
    "#                         break\n",
    "#                     else:\n",
    "#                         retry_count += 1\n",
    "#                         time.sleep(2 * retry_count)\n",
    "\n",
    "#                 except Exception as e:\n",
    "#                     retry_count += 1\n",
    "#                     print(f\"â—ì˜ˆì™¸ ë°œìƒ: {e} (ì¬ì‹œë„ {retry_count}/{max_retries})\")\n",
    "#                     fail_log_prefix = f\"logs/retry_failed_{item_name}_{mcode}_{date_str}_try{retry_count}\"\n",
    "#                     if 'response' in locals():\n",
    "#                         with open(f\"{fail_log_prefix}.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "#                             f.write(response.text)\n",
    "#                     with open(f\"{fail_log_prefix}_info.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "#                         f.write(f\"[ì˜ˆì™¸] {str(e)}\\n\")\n",
    "#                     if retry_count >= max_retries:\n",
    "#                         break\n",
    "#                     time.sleep(2 * retry_count)\n",
    "\n",
    "#             if not market_success:\n",
    "#                 fail_log_path = f\"logs/retry_failed_{item_name}_{mcode}_{date_str}.txt\"\n",
    "#                 with open(fail_log_path, \"w\", encoding=\"utf-8\") as f:\n",
    "#                     f.write(f\"âŒ {datetime.now()} - {item_name} {mcode} {date_str} ë°ì´í„° ìˆ˜ì§‘ ì‹¤íŒ¨\\n\")\n",
    "\n",
    "#     # ì €ì¥\n",
    "#     if data_list:\n",
    "#         df = pd.DataFrame(data_list)\n",
    "#         filename = f\"{item_nm}/ìœ í†µê³µì‚¬_retry_{item_name}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv\"\n",
    "#         df.to_csv(filename, encoding='cp949', index=False)\n",
    "#         print(f\"âœ… ì €ì¥ ì™„ë£Œ: {filename}\")\n",
    "#     else:\n",
    "#         print(f\"âš ï¸ {item_name}: ì¬ì‹œë„ì—ì„œë„ ë°ì´í„° ì—†ìŒ\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c88d6fa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-dl-nlp",
   "language": "python",
   "name": "ml-dl-nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
