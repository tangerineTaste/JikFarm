{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2567d0e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "div.container{width:86% !important;}\n",
       "div.cell.code_cell.rendered{width:100%;}\n",
       "div.CodeMirror {font-family:Consolas; font-size:12pt;}\n",
       "div.output {font-size:12pt; font-weight:bold;}\n",
       "div.input {font-family:Consolas; font-size:12pt;}\n",
       "div.prompt {min-width:70px;}\n",
       "div#toc-wrapper{padding-top:120px;}\n",
       "div.text_cell_render ul li{font-size:12pt;padding:5px;}\n",
       "table.dataframe{font-size:12px;}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, HTML\n",
    "display(HTML(\"\"\"\n",
    "<style>\n",
    "div.container{width:86% !important;}\n",
    "div.cell.code_cell.rendered{width:100%;}\n",
    "div.CodeMirror {font-family:Consolas; font-size:12pt;}\n",
    "div.output {font-size:12pt; font-weight:bold;}\n",
    "div.input {font-family:Consolas; font-size:12pt;}\n",
    "div.prompt {min-width:70px;}\n",
    "div#toc-wrapper{padding-top:120px;}\n",
    "div.text_cell_render ul li{font-size:12pt;padding:5px;}\n",
    "table.dataframe{font-size:12px;}\n",
    "</style>\n",
    "\"\"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2486bccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 시작전 설정\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "%matplotlib inline  \n",
    "    # 주피터 노트북을 실행한 브라우저에서 바로 그림을 볼 수 있게 해줌. 안해도 요즘은 나온다\n",
    "%config InlineBackend.figure_format='retina'  \n",
    "    # 그래프를 더 높은 해상도로 그려줌\n",
    "#한글설정\n",
    "plt.rc('font', family='Malgun Gothic') # 윈도우즈\n",
    "#plt.rc('font', family='AppleGothic') # mac\n",
    "plt.rc('axes', unicode_minus=False)  # 축의 - 깨짐 방지\n",
    "# 경고 메세지 안보이게\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c35a19df",
   "metadata": {},
   "source": [
    "# 데이터 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd731b4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 사전설정 # 아이템 및 파일 경로 확인\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "item = '배추'\n",
    "item_code = 1001\n",
    "df_path = f'datasets/작물_lag_월단위_스케일링X_인코딩X/{item}_월차낼게요.csv'\n",
    "external_path = 'datasets/factor_external_weekly_ver_0721.csv'\n",
    "save_path = f'datasets/작물_lag_월단위_스케일링X_인코딩X/{item}_월차_집계가공.csv'  # 중간저장 \n",
    "# 양파 : 1201 # 배추 : 1001 # 상추 : 1005 # 사과 : 0601 # 무 : 1101 # 감자 : 0501 # 대파 : 1202 # 건고추 : 1207\n",
    "# 마늘 : 1209 # 딸기 : 0804  # 방울토마토 : 0806 # 오이 : 0901 # 양배추 : 1004  # 고구마 : 0502  # 배 : 0602"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eb86f25",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 데이터 경로 설정\n",
    "df_path = 'your_original_data_path.csv'\n",
    "external_path = 'your_external_data_path.csv'\n",
    "save_path = 'your_processed_data_path.csv'\n",
    "item_code = 'your_item_code'\n",
    "\n",
    "# 원본 데이터 로드\n",
    "try:\n",
    "    df = pd.read_csv(df_path, encoding='cp949')\n",
    "except FileNotFoundError:\n",
    "    print(f\"오류: {df_path} 파일을 찾을 수 없습니다.\")\n",
    "    exit()\n",
    "\n",
    "# '등급코드' 컬럼 제외\n",
    "df_processed = df.drop(columns=['등급코드'])\n",
    "\n",
    "# 주간 단위로 데이터 그룹화 및 집계\n",
    "group_keys = ['year', 'week', '품종코드', '직팜산지코드']\n",
    "agg_rules = {\n",
    "    '평균단가(원)': 'mean',\n",
    "    '총거래량(kg)': 'sum',\n",
    "    '일평균기온_t-1': 'mean', '일평균기온_t-2': 'mean', '일평균기온_t-3': 'mean',\n",
    "    '강수량(mm)_t-1': 'mean', '강수량(mm)_t-2': 'mean', '강수량(mm)_t-3': 'mean',\n",
    "    '최고기온_t-1': 'mean', '최고기온_t-2': 'mean', '최고기온_t-3': 'mean',\n",
    "    '최저기온_t-1': 'mean', '최저기온_t-2': 'mean', '최저기온_t-3': 'mean',\n",
    "    '1시간최고강수량(mm)_t-1': 'mean', '1시간최고강수량(mm)_t-2': 'mean', '1시간최고강수량(mm)_t-3': 'mean',\n",
    "    '평균상대습도_t-1': 'mean', '평균상대습도_t-2': 'mean', '평균상대습도_t-3': 'mean'\n",
    "}\n",
    "\n",
    "df_agg = df_processed.groupby(group_keys).agg(agg_rules).reset_index()\n",
    "df_agg.drop_duplicates(inplace=True)\n",
    "\n",
    "# 외생변수 데이터 로드\n",
    "df_grow = pd.read_csv(external_path, encoding='utf-8')\n",
    "\n",
    "# 'weekno'를 'year'와 'week'로 분리\n",
    "df_grow['year'] = df_grow['weekno'] // 100\n",
    "df_grow['week'] = df_grow['weekno'] % 100\n",
    "df_grow.drop(columns='weekno', inplace=True)\n",
    "             \n",
    "# 병합을 위한 item_code 추가\n",
    "df_agg['item_code'] = item_code\n",
    "\n",
    "# 병합 전 불필요한 컬럼 삭제\n",
    "df_agg.drop(columns=['holiday_flag', 'holiday_score', 'grow_score'], inplace=True, errors='ignore')\n",
    "\n",
    "# 외생변수 병합\n",
    "df_agg = pd.merge(\n",
    "    df_agg,\n",
    "    df_grow[['year', 'week', 'item_code', 'holiday_flag', 'holiday_score', 'grow_score']],\n",
    "    on=['year', 'week', 'item_code'],\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# 병합 후 'item_code' 삭제\n",
    "df = df_agg.drop(columns='item_code')\n",
    "\n",
    "# 최종 데이터를 CSV로 저장\n",
    "df.to_csv(save_path, index=False)\n",
    "\n",
    "# 최종 데이터 확인\n",
    "print(\"데이터 전처리 및 병합 완료\")\n",
    "print(f\"최종 데이터 크기: {df.shape[0]}행\")\n",
    "print(\"--- 최종 데이터 미리보기 ---\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fee40b4",
   "metadata": {},
   "source": [
    "# 프로펫 + LSTM 모델 - Robust"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff9f5519",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 위 전처리 없이 아래만 따로 시작할때만 설정\n",
    "# 양파 : 1201 # 배추 : 1001 # 상추 : 1005 # 사과 : 0601 # 무 : 1101 # 감자 : 0501 # 대파 : 1202 # 건고추 : 1207\n",
    "# 마늘 : 1209 # 딸기 : 0804  # 방울토마토 : 0806 # 오이 : 0901 # 양배추 : 1004  # 고구마 : 0502  # 배 : 0602\n",
    "ITEM = item\n",
    "mid_save_path = f'datasets/작물_lag_월단위_스케일링X_인코딩X/{item}_월차_모델직전.csv'  # 중간저장 \n",
    "model_path = 'final_model_checkpoints'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "876eaddc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "from prophet import Prophet\n",
    "from sklearn.preprocessing import RobustScaler, StandardScaler, MinMaxScaler\n",
    "from sklearn.metrics import mean_absolute_error, r2_score, mean_squared_error, mean_absolute_percentage_error\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "import joblib\n",
    "\n",
    "# 기본 설정\n",
    "TARGET_COL = '평균단가(원)'\n",
    "TIMESTEPS = 8\n",
    "LSTM_UNITS = 128\n",
    "activation = 'relu'\n",
    "epochs = 100\n",
    "batch_size = 64\n",
    "stop_patience = 40\n",
    "\n",
    "# 데이터 로드\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# 그룹별 시계열 피처 생성\n",
    "group_cols = ['직팜산지코드', '품종코드']\n",
    "ts_feature_names = ['가격변화율', '가격차분']\n",
    "\n",
    "df['가격변화율'] = df.groupby(group_cols)[TARGET_COL].pct_change().shift(1)\n",
    "df['가격차분'] = df.groupby(group_cols)[TARGET_COL].diff().shift(1)\n",
    "\n",
    "df[ts_feature_names] = df.groupby(group_cols)[ts_feature_names].fillna(0)\n",
    "df.replace([np.inf, -np.inf], 0, inplace=True)\n",
    "\n",
    "# 전국 단위로 데이터 집계\n",
    "df['price_volume'] = df['평균단가(원)'] * df['총거래량(kg)']\n",
    "agg_rules = {col: 'mean' for col in ts_feature_names}\n",
    "agg_rules['price_volume'] = 'sum'\n",
    "agg_rules['총거래량(kg)'] = 'sum'\n",
    "\n",
    "df_agg = df.groupby(['year', 'week']).agg(agg_rules).reset_index()\n",
    "df_agg[TARGET_COL] = df_agg['price_volume'] / df_agg['총거래량(kg)']\n",
    "df_agg.drop(columns=['price_volume'], inplace=True)\n",
    "\n",
    "# 중간 저장 (경로 확인)\n",
    "df_agg.to_csv(mid_save_path, index=False)\n",
    "\n",
    "# Prophet 피처 생성\n",
    "df_prophet = df_agg.copy()\n",
    "df_prophet['ds'] = pd.to_datetime(df_agg['year'].astype(str) + df_agg['week'].astype(str) + '0', format='%Y%W%w')\n",
    "df_prophet['y'] = np.log1p(df_agg[TARGET_COL])\n",
    "\n",
    "# Prophet 모델 학습 (훈련 데이터만 사용)\n",
    "train_prophet_df = df_prophet[df_prophet['ds'].dt.year < 2025].copy()\n",
    "regressor_cols = [col for col in agg_rules.keys() if col not in ['price_volume', '총거래량(kg)']]\n",
    "\n",
    "prophet_model = Prophet(yearly_seasonality=True, weekly_seasonality=False, daily_seasonality=False)\n",
    "for col in regressor_cols:\n",
    "    prophet_model.add_regressor(col)\n",
    "prophet_model.fit(train_prophet_df[['ds', 'y'] + regressor_cols])\n",
    "\n",
    "# 전체 기간에 대한 Prophet 예측 및 잔차 계산\n",
    "forecast = prophet_model.predict(df_prophet[['ds'] + regressor_cols])\n",
    "df_prophet['prophet_pred'] = forecast['yhat'].values\n",
    "df_prophet['residual'] = df_prophet['y'] - df_prophet['prophet_pred']\n",
    "\n",
    "# 미래 시점 예측을 위해 Target 변수 shift\n",
    "df_prophet['y_target_-4d'] = df_prophet[TARGET_COL].shift(-4)\n",
    "df_prophet = df_prophet.dropna()\n",
    "\n",
    "# LSTM 학습용 데이터 분리\n",
    "lstm_feature_cols = ['residual'] + regressor_cols\n",
    "lstm_target_col = 'residual'\n",
    "\n",
    "# 훈련/테스트 데이터 분리\n",
    "cutoff_date = pd.to_datetime('2024-40-0', format='%Y-%W-%w')\n",
    "train_final_df = df_prophet[df_prophet['ds'] <= cutoff_date].copy()\n",
    "test_final_df = df_prophet[df_prophet['ds'] > cutoff_date].copy()\n",
    "\n",
    "# 스케일링\n",
    "scaler = RobustScaler()\n",
    "train_final_df[lstm_feature_cols] = scaler.fit_transform(train_final_df[lstm_feature_cols])\n",
    "test_final_df[lstm_feature_cols] = scaler.transform(test_final_df[lstm_feature_cols])\n",
    "\n",
    "# 시퀀스 데이터 생성\n",
    "def create_multivariate_sequences(df, feature_cols, target_col, timesteps):\n",
    "    X, y = [], []\n",
    "    features = df[feature_cols].values\n",
    "    target = df[target_col].values\n",
    "    for i in range(len(df) - timesteps):\n",
    "        X.append(features[i:(i + timesteps)])\n",
    "        y.append(target[i + timesteps])\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "X_train_seq, y_train_seq = create_multivariate_sequences(train_final_df, lstm_feature_cols, lstm_target_col, TIMESTEPS)\n",
    "X_test_seq, y_test_seq = create_multivariate_sequences(test_final_df, lstm_feature_cols, lstm_target_col, TIMESTEPS)\n",
    "\n",
    "# LSTM 모델 구축 및 학습\n",
    "lstm_model = Sequential([\n",
    "    LSTM(units=LSTM_UNITS, activation=activation, input_shape=(X_train_seq.shape[1], X_train_seq.shape[2])),\n",
    "    Dropout(0.2),\n",
    "    Dense(units=1)\n",
    "])\n",
    "lstm_model.compile(optimizer='adam', loss='mse', metrics=['mse'])\n",
    "\n",
    "# 콜백 설정\n",
    "current_time = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "model_nm = f'best_model_LSTM+Prophet_{item}_{current_time}.keras'\n",
    "checkpoint_filepath = os.path.join(model_path, model_nm)\n",
    "checkpoint_cb = ModelCheckpoint(filepath=checkpoint_filepath, monitor='val_loss', mode='min', save_best_only=True, verbose=1)\n",
    "early_stopping_cb = EarlyStopping(monitor='val_loss', patience=stop_patience, restore_best_weights=True, verbose=1)\n",
    "reduce_lr_cb = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=10, min_lr=1e-6, verbose=1)\n",
    "\n",
    "# 모델 학습\n",
    "history = lstm_model.fit(X_train_seq, y_train_seq,\n",
    "                        epochs=epochs,\n",
    "                        batch_size=batch_size,\n",
    "                        validation_data=(X_test_seq, y_test_seq),\n",
    "                        verbose=1,\n",
    "                        callbacks=[checkpoint_cb, early_stopping_cb, reduce_lr_cb]\n",
    "                       )\n",
    "\n",
    "# 모델 및 Scaler 저장\n",
    "# 저장 폴더 생성 (폴더 미존재 시)\n",
    "if not os.path.exists('final_model_checkpoints'):\n",
    "    os.makedirs('final_model_checkpoints')\n",
    "\n",
    "# Prophet 모델 저장\n",
    "joblib.dump(prophet_model, f'final_model_checkpoints/prophet_model_{item}.pkl')\n",
    "\n",
    "# RobustScaler 저장\n",
    "joblib.dump(scaler, f'final_model_checkpoints/robust_scaler_{item}.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07c6e588",
   "metadata": {},
   "source": [
    "# 모델 평가 및 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2af4cd87",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_absolute_error, r2_score, mean_squared_error, mean_absolute_percentage_error\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# 최종 예측 및 평가\n",
    "# 잔차 예측 결과 스케일링 복원\n",
    "residual_pred_scaled = lstm_model.predict(X_test_seq)\n",
    "dummy_array = np.zeros((len(residual_pred_scaled), len(lstm_feature_cols)))\n",
    "dummy_array[:, 0] = residual_pred_scaled.flatten()\n",
    "residual_pred = scaler.inverse_transform(dummy_array)[:, 0]\n",
    "\n",
    "# 최종 예측값 계산 (Prophet 예측값 + LSTM 잔차 예측값)\n",
    "prophet_future_pred = test_final_df['prophet_pred'].values[TIMESTEPS:]\n",
    "final_pred_log = prophet_future_pred + residual_pred\n",
    "\n",
    "# 로그 변환 복원\n",
    "y_original_eval = test_final_df['y_original'].values[TIMESTEPS:]\n",
    "final_pred_eval = np.expm1(final_pred_log)\n",
    "\n",
    "# 모든 평가지표 계산\n",
    "mae = mean_absolute_error(y_original_eval, final_pred_eval)\n",
    "rmse = mean_squared_error(y_original_eval, final_pred_eval, squared=False)\n",
    "mape = mean_absolute_percentage_error(y_original_eval, final_pred_eval) * 100\n",
    "nmae = (mae / np.mean(y_original_eval)) * 100\n",
    "r2 = r2_score(y_original_eval, final_pred_eval)\n",
    "\n",
    "# 평가지표를 포함한 파일명으로 최종 모델 저장\n",
    "current_time = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "final_model_filename = f'LSTM+Prophet_{item}_MAE_{mae:.0f}_R2_{r2:.4f}_{current_time}.keras'\n",
    "final_model_path = os.path.join(model_path, final_model_filename)\n",
    "lstm_model.save(final_model_path)\n",
    "\n",
    "# 결과 출력\n",
    "print(\"Prophet + LSTM 하이브리드 모델 최종 평가 결과\")\n",
    "print(f\"MAE: {mae:.2f}\")\n",
    "print(f\"RMSE: {rmse:.2f}\")\n",
    "print(f\"MAPE: {mape:.2f}%\")\n",
    "print(f\"NMAE: {nmae:.2f}%\")\n",
    "print(f\"R²: {r2:.4f}\")\n",
    "\n",
    "# 시각화\n",
    "results_df = test_final_df.iloc[TIMESTEPS:].copy()\n",
    "results_df['final_pred'] = final_pred_eval\n",
    "results_df = results_df[results_df['year']==2025]\n",
    "\n",
    "plt.figure(figsize=(16, 6))\n",
    "plt.plot(results_df['ds'], results_df['y_original'], label='실제 평균단가', marker='o')\n",
    "plt.plot(results_df['ds'], results_df['final_pred'], label='최종 예측단가', marker='x', linestyle='--')\n",
    "plt.title(f\"{test_final_df['ds'].dt.year.max()}년 주차별 평균단가 예측 결과 ({item})\")\n",
    "plt.xlabel(\"날짜\")\n",
    "plt.ylabel(\"평균단가(원)\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23bd6daf",
   "metadata": {},
   "source": [
    "# 모델 로딩 및 예측값 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29339b20",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import joblib\n",
    "from datetime import datetime, timedelta\n",
    "import os\n",
    "\n",
    "# 기본 설정\n",
    "MODEL_PATH = f'final_model_checkpoints/LSTM+Prophet_{ITEM}_MAE_111_R2_0.7894_20250726_025207.keras'\n",
    "PROPHET_MODEL_PATH = f'final_model_checkpoints/prophet_model_{ITEM}.pkl'\n",
    "SCALER_PATH = f'final_model_checkpoints/robust_scaler_{ITEM}.pkl'\n",
    "DATA_PATH = mid_save_path\n",
    "EXTERNAL_PATH = 'datasets/factor_external_weekly_ver_0721.csv'\n",
    "OUTPUT_DIR = 'forecast_results'\n",
    "TIMESTEPS = 8\n",
    "FORECAST_WEEKS = 4\n",
    "\n",
    "# 모델 및 데이터 로드\n",
    "try:\n",
    "    lstm_model = tf.keras.models.load_model(MODEL_PATH)\n",
    "    prophet_model = joblib.load(PROPHET_MODEL_PATH)\n",
    "    scaler = joblib.load(SCALER_PATH)\n",
    "    historical_df = pd.read_csv(DATA_PATH)\n",
    "    external_df = pd.read_csv(EXTERNAL_PATH)\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"오류: 파일 로드 실패. {e}\")\n",
    "    exit()\n",
    "\n",
    "def format_week_int(weekno):\n",
    "    year = weekno // 100\n",
    "    week = weekno % 100\n",
    "    return year, week\n",
    "\n",
    "# 외생변수 'weekno'를 'year'와 'week'로 분리\n",
    "external_df[['year', 'week']] = external_df['weekno'].apply(\n",
    "    lambda x: pd.Series(format_week_int(x))\n",
    ")\n",
    "external_df.drop(columns='weekno', inplace=True)\n",
    "\n",
    "# 재귀 예측 함수\n",
    "def recursive_forecast(lstm_model, prophet_model, scaler, historical_df, external_df, timesteps, forecast_weeks):\n",
    "    # LSTM 피처 컬럼 (훈련 시점과 동일)\n",
    "    lstm_feature_cols = ['residual'] + ['가격변화율', '가격차분']\n",
    "\n",
    "    # Prophet 잔차 포함 데이터 생성\n",
    "    historical_df['ds'] = pd.to_datetime(historical_df['year'].astype(str) + historical_df['week'].astype(str) + '0', format='%Y%W%w')\n",
    "    prophet_full_pred = prophet_model.predict(historical_df)\n",
    "    historical_df['residual'] = np.log1p(historical_df['평균단가(원)']) - prophet_full_pred['yhat']\n",
    "\n",
    "    # 예측을 위한 초기 시퀀스 데이터 (최근 8주)\n",
    "    last_date = historical_df['ds'].max()\n",
    "    current_sequence = historical_df.tail(timesteps).copy()\n",
    "\n",
    "    # 미래 외생변수는 가장 최근 값으로 유지\n",
    "    last_external_features = current_sequence.tail(1)[['가격변화율', '가격차분', '총거래량(kg)']]\n",
    "\n",
    "    predictions = []\n",
    "\n",
    "    for i in range(forecast_weeks):\n",
    "        # 현재 시퀀스로 LSTM 입력 데이터 생성\n",
    "        lstm_input_features = current_sequence[lstm_feature_cols].values\n",
    "        lstm_input_scaled = scaler.transform(lstm_input_features)\n",
    "        lstm_input_reshaped = lstm_input_scaled.reshape(1, timesteps, len(lstm_feature_cols))\n",
    "\n",
    "        # LSTM으로 다음 1주의 '잔차' 예측\n",
    "        scaled_residual_pred = lstm_model.predict(lstm_input_reshaped, verbose=0)\n",
    "        \n",
    "        # 잔차 예측값 복원\n",
    "        dummy_array = np.zeros((1, len(lstm_feature_cols)))\n",
    "        dummy_array[:, 0] = scaled_residual_pred.flatten()\n",
    "        predicted_residual = scaler.inverse_transform(dummy_array)[:, 0][0]\n",
    "\n",
    "        # Prophet으로 다음 1주의 '기본 추세' 예측\n",
    "        next_date = last_date + timedelta(weeks=i + 1)\n",
    "        future_df = pd.DataFrame({'ds': [next_date]})\n",
    "        \n",
    "        # 미래 외생변수 채우기\n",
    "        for col, val in last_external_features.iloc[0].items():\n",
    "            future_df[col] = val\n",
    "        \n",
    "        prophet_baseline_pred = prophet_model.predict(future_df)['yhat'].iloc[0]\n",
    "\n",
    "        # 최종 가격 예측\n",
    "        final_log_pred = prophet_baseline_pred + predicted_residual\n",
    "        final_price_pred = np.expm1(final_log_pred)\n",
    "        predictions.append({'date': next_date, 'predicted_price': final_price_pred})\n",
    "\n",
    "        # 다음 예측을 위해 시퀀스 업데이트\n",
    "        new_row = pd.DataFrame([{'ds': next_date, 'residual': predicted_residual, **last_external_features.iloc[0].to_dict()}])\n",
    "        current_sequence = pd.concat([current_sequence.iloc[1:], new_row], ignore_index=True)\n",
    "\n",
    "    return pd.DataFrame(predictions)\n",
    "\n",
    "# 예측 실행 및 CSV 저장\n",
    "forecast_results_df = recursive_forecast(\n",
    "    lstm_model, prophet_model, scaler, historical_df, external_df, TIMESTEPS, FORECAST_WEEKS\n",
    ")\n",
    "\n",
    "# CSV 파일로 저장\n",
    "if not os.path.exists(OUTPUT_DIR):\n",
    "    os.makedirs(OUTPUT_DIR)\n",
    "\n",
    "output_filename = os.path.join(OUTPUT_DIR, f'{ITEM}_price_forecast.csv')\n",
    "forecast_results_df.to_csv(output_filename, index=False, encoding='utf-8')\n",
    "\n",
    "# 결과 출력\n",
    "print(f\"향후 {FORECAST_WEEKS}주간 '{ITEM}' 가격 예측 결과\")\n",
    "print(forecast_results_df.to_string(index=False))\n",
    "\n",
    "print(f\"\\n예측 결과를 '{output_filename}' 파일로 저장했습니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5519d0d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dddf8111",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (GPU-jik)",
   "language": "python",
   "name": "myproject-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "293.469px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
